{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3077004-f954-498d-83e4-04fc43f0e863",
   "metadata": {},
   "source": [
    "# STAC to GeoCroissant Conversion\n",
    "<img src=\"../assets/GeoCroissant.jpg\" alt=\"GeoCroissant\" width=\"150\" style=\"float: right; margin-left: 50px;\">\n",
    "This notebook converts metadata from a [STAC Collection](https://stacspec.org/en) into [GeoCroissant](https://github.com/mlcommons/croissant) JSON-LD format.\n",
    "\n",
    "GeoCroissant is a geospatial extension of MLCommons' Croissant metadata standard. This enables ML-ready dataset descriptions including:\n",
    "\n",
    "- Spatial extent (bounding box, geometry)\n",
    "- Temporal coverage\n",
    "- Data files (via `distribution`)\n",
    "- Licensing, creators, and references\n",
    "\n",
    "## STAC Collection to GeoCroissant Mapping\n",
    "| STAC Field         | GeoCroissant Field       |\n",
    "|--------------------|---------------------------|\n",
    "| `title`            | `name`                   |\n",
    "| `description`      | `description`            |\n",
    "| `license`          | `license`                |\n",
    "| `extent.spatial`   | `geocr:BoundingBox`      |\n",
    "| `extent.temporal`  | `dct:temporal`           |\n",
    "| `links`            | `references`             |\n",
    "| `assets`           | `distribution`           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c1c99-c355-453b-8446-84c91ba5f614",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132c418-8962-4172-ae5f-fbb207ccfecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlcroissant in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.0.17)\n",
      "Requirement already satisfied: absl-py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (2.3.0)\n",
      "Requirement already satisfied: etils>=1.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from etils[epath]>=1.7.0->mlcroissant) (1.12.2)\n",
      "Requirement already satisfied: jsonpath-rw in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (1.4.0)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (3.4.2)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (2.1.4)\n",
      "Requirement already satisfied: pandas-stubs in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (2.2.3.250527)\n",
      "Requirement already satisfied: python-dateutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (7.1.4)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (2.32.4)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (1.11.4)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mlcroissant) (4.67.1)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from etils[epath]>=1.7.0->mlcroissant) (2025.5.1)\n",
      "Requirement already satisfied: importlib_resources in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from etils[epath]>=1.7.0->mlcroissant) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from etils[epath]>=1.7.0->mlcroissant) (4.14.0)\n",
      "Requirement already satisfied: zipp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from etils[epath]>=1.7.0->mlcroissant) (3.23.0)\n",
      "Requirement already satisfied: ply in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonpath-rw->mlcroissant) (3.11)\n",
      "Requirement already satisfied: decorator in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonpath-rw->mlcroissant) (5.2.1)\n",
      "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonpath-rw->mlcroissant) (1.17.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->mlcroissant) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->mlcroissant) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->mlcroissant) (2025.2)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas-stubs->mlcroissant) (2025.2.0.20250516)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.7.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rdflib->mlcroissant) (0.7.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rdflib->mlcroissant) (3.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->mlcroissant) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->mlcroissant) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->mlcroissant) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->mlcroissant) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c0d9d-a45f-49f3-89ab-df7ae0102d5b",
   "metadata": {},
   "source": [
    "## Load STAC Collection JSON\n",
    "We load a `stac.json` file which conforms to the STAC Collection spec.\n",
    "This function reads STAC fields and generates GeoCroissant metadata.\n",
    "\n",
    "It includes handling for:\n",
    "- Distribution files and MIME types\n",
    "- Spatial and temporal coverage\n",
    "- Title, license, creator info\n",
    "- Unmapped STAC fields (for logging/debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123d014-35a3-4100-b7e3-8ff935696715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mUnmapped STAC Fields:\u001b[0m\n",
      "- renders: dict\n",
      "- summaries: dict\n",
      "- deprecated: bool\n",
      "- item_assets: dict\n",
      "- stac_version: str\n",
      "- stac_extensions: list\n",
      "\n",
      "GeoCroissant conversion complete. Output saved to 'croissant.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def sanitize_name(name):\n",
    "    return re.sub(r\"[^a-zA-Z0-9_\\-]\", \"-\", name)\n",
    "\n",
    "def ensure_semver(version):\n",
    "    if not version:\n",
    "        return \"1.0.0\"\n",
    "    if version.startswith(\"v\"):\n",
    "        version = version[1:]\n",
    "    parts = version.split(\".\")\n",
    "    if len(parts) == 2:\n",
    "        parts.append(\"0\")\n",
    "    return \".\".join(parts[:3])\n",
    "\n",
    "def stac_to_geocroissant(stac_dict):\n",
    "    dataset_id = stac_dict.get(\"id\")\n",
    "    name = sanitize_name(stac_dict.get(\"title\", dataset_id or \"UnnamedDataset\"))\n",
    "    version = ensure_semver(stac_dict.get(\"version\", \"1.0.0\"))\n",
    "\n",
    "    croissant = {\n",
    "        \"@context\": {\n",
    "            \"@language\": \"en\",\n",
    "            \"@vocab\": \"https://schema.org/\",\n",
    "            \"cr\": \"http://mlcommons.org/croissant/\",\n",
    "            \"geocr\": \"http://mlcommons.org/geocroissant/\",\n",
    "            \"dct\": \"http://purl.org/dc/terms/\",\n",
    "            \"sc\": \"https://schema.org/\",\n",
    "            \"citeAs\": \"cr:citeAs\",\n",
    "            \"column\": \"cr:column\",\n",
    "            \"conformsTo\": \"dct:conformsTo\",\n",
    "            \"data\": {\"@id\": \"cr:data\", \"@type\": \"@json\"},\n",
    "            \"dataBiases\": \"cr:dataBiases\",\n",
    "            \"dataCollection\": \"cr:dataCollection\",\n",
    "            \"dataType\": {\"@id\": \"cr:dataType\", \"@type\": \"@vocab\"},\n",
    "            \"extract\": \"cr:extract\",\n",
    "            \"field\": \"cr:field\",\n",
    "            \"fileProperty\": \"cr:fileProperty\",\n",
    "            \"fileObject\": \"cr:fileObject\",\n",
    "            \"fileSet\": \"cr:fileSet\",\n",
    "            \"format\": \"cr:format\",\n",
    "            \"includes\": \"cr:includes\",\n",
    "            \"isLiveDataset\": \"cr:isLiveDataset\",\n",
    "            \"jsonPath\": \"cr:jsonPath\",\n",
    "            \"key\": \"cr:key\",\n",
    "            \"md5\": {\"@id\": \"cr:md5\", \"@type\": \"sc:Text\"},\n",
    "            \"sha256\": {\"@id\": \"cr:sha256\", \"@type\": \"sc:Text\"},\n",
    "            \"parentField\": \"cr:parentField\",\n",
    "            \"path\": \"cr:path\",\n",
    "            \"personalSensitiveInformation\": \"cr:personalSensitiveInformation\",\n",
    "            \"recordSet\": \"cr:recordSet\",\n",
    "            \"references\": \"cr:references\",\n",
    "            \"regex\": \"cr:regex\",\n",
    "            \"repeated\": \"cr:repeated\",\n",
    "            \"replace\": \"cr:replace\",\n",
    "            \"separator\": \"cr:separator\",\n",
    "            \"source\": \"cr:source\",\n",
    "            \"subField\": \"cr:subField\",\n",
    "            \"transform\": \"cr:transform\"\n",
    "            \n",
    "        },\n",
    "        \"@type\": \"Dataset\",\n",
    "        \"@id\": dataset_id,\n",
    "        \"name\": name,\n",
    "        \"description\": stac_dict.get(\"description\", \"\"),\n",
    "        \"version\": version,\n",
    "        \"license\": stac_dict.get(\"license\", \"CC-BY-4.0\"),\n",
    "        \"conformsTo\": \"http://mlcommons.org/croissant/1.0\"\n",
    "    }\n",
    "\n",
    "    # Citation\n",
    "    if \"sci:citation\" in stac_dict:\n",
    "        croissant[\"citeAs\"] = stac_dict[\"sci:citation\"]\n",
    "        croissant[\"citation\"] = stac_dict[\"sci:citation\"]\n",
    "\n",
    "    # Creator\n",
    "    if stac_dict.get(\"providers\"):\n",
    "        provider = stac_dict[\"providers\"][0]\n",
    "        croissant[\"creator\"] = {\n",
    "            \"@type\": \"Organization\",\n",
    "            \"name\": provider.get(\"name\", \"Unknown\"),\n",
    "            \"url\": provider.get(\"url\", \"\")\n",
    "        }\n",
    "\n",
    "    # Link: self\n",
    "    for link in stac_dict.get(\"links\", []):\n",
    "        if link.get(\"rel\") == \"self\":\n",
    "            croissant[\"url\"] = link.get(\"href\")\n",
    "            break\n",
    "\n",
    "    # Bounding box\n",
    "    spatial = stac_dict.get(\"extent\", {}).get(\"spatial\", {}).get(\"bbox\")\n",
    "    if spatial:\n",
    "        croissant[\"geocr:BoundingBox\"] = spatial[0]\n",
    "\n",
    "    # Temporal extent\n",
    "    temporal = stac_dict.get(\"extent\", {}).get(\"temporal\", {}).get(\"interval\")\n",
    "    if temporal and temporal[0]:\n",
    "        start, end = temporal[0][0], temporal[0][1]\n",
    "        croissant[\"dct:temporal\"] = {\"startDate\": start, \"endDate\": end}\n",
    "        croissant[\"datePublished\"] = start\n",
    "    else:\n",
    "        croissant[\"datePublished\"] = datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "    # Distribution - updated to pass validation\n",
    "    croissant[\"distribution\"] = []\n",
    "    for key, asset in stac_dict.get(\"assets\", {}).items():\n",
    "        file_object = {\n",
    "            \"@type\": \"cr:FileObject\",\n",
    "            \"@id\": key,\n",
    "            \"name\": key,\n",
    "            \"description\": asset.get(\"description\", asset.get(\"title\", \"\")),\n",
    "            \"contentUrl\": asset.get(\"href\"),\n",
    "            \"encodingFormat\": asset.get(\"type\", \"application/octet-stream\"),\n",
    "            \"sha256\": \"https://github.com/mlcommons/croissant/issues/80\",  # 64-char hex\n",
    "            \"md5\": \"https://github.com/mlcommons/croissant/issues/80\"  # 32-char hex\n",
    "        }\n",
    "        \n",
    "        # Use actual checksums if available\n",
    "        if \"checksum:multihash\" in asset:\n",
    "            file_object[\"sha256\"] = asset[\"checksum:multihash\"]\n",
    "        elif \"file:checksum\" in asset:\n",
    "            file_object[\"sha256\"] = asset[\"file:checksum\"]\n",
    "        if \"checksum:md5\" in asset:\n",
    "            file_object[\"md5\"] = asset[\"checksum:md5\"]\n",
    "        \n",
    "        croissant[\"distribution\"].append(file_object)\n",
    "\n",
    "    # Debug: unmapped fields\n",
    "    mapped_keys = {\n",
    "        \"id\", \"type\", \"links\", \"title\", \"assets\", \"extent\",\n",
    "        \"license\", \"version\", \"providers\", \"description\", \"sci:citation\"\n",
    "    }\n",
    "    extra_fields = {k: v for k, v in stac_dict.items() if k not in mapped_keys}\n",
    "    print(\"\\n\\033[1mUnmapped STAC Fields:\\033[0m\")\n",
    "    if extra_fields:\n",
    "        for k, v in extra_fields.items():\n",
    "            print(f\"- {k}: {type(v).__name__}\")\n",
    "    else:\n",
    "        print(\"None ✅\")\n",
    "\n",
    "    return croissant\n",
    "\n",
    "\n",
    "# Load STAC Collection JSON\n",
    "with open(\"stac.json\") as f:\n",
    "    stac_data = json.load(f)\n",
    "\n",
    "# Convert to GeoCroissant\n",
    "croissant_json = stac_to_geocroissant(stac_data)\n",
    "\n",
    "# Save GeoCroissant JSON-LD\n",
    "with open(\"croissant.json\", \"w\") as f:\n",
    "    json.dump(croissant_json, f, indent=2)\n",
    "\n",
    "print(\"\\nGeoCroissant conversion complete. Output saved to 'croissant.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf847654-f5d9-43e2-b214-f69c1aca4c0e",
   "metadata": {},
   "source": [
    "## Print Unmapped STAC Fields\n",
    "Display any fields in the original STAC Collection that weren’t mapped to GeoCroissant fields — useful for debugging or future enhancements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31091253-c953-4bcc-891b-10d6f3bae9e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"@context\": {\n",
      "    \"@language\": \"en\",\n",
      "    \"@vocab\": \"https://schema.org/\",\n",
      "    \"cr\": \"http://mlcommons.org/croissant/\",\n",
      "    \"geocr\": \"http://mlcommons.org/geocroissant/\",\n",
      "    \"dct\": \"http://purl.org/dc/terms/\",\n",
      "    \"sc\": \"https://schema.org/\",\n",
      "    \"citeAs\": \"cr:citeAs\",\n",
      "    \"column\": \"cr:column\",\n",
      "    \"conformsTo\": \"dct:conformsTo\",\n",
      "    \"data\": {\n",
      "      \"@id\": \"cr:data\",\n",
      "      \"@type\": \"@json\"\n",
      "    },\n",
      "    \"dataBiases\": \"cr:dataBiases\",\n",
      "    \"dataCollection\": \"cr:dataCollection\",\n",
      "    \"dataType\": {\n",
      "      \"@id\": \"cr:dataType\",\n",
      "      \"@type\": \"@vocab\"\n",
      "    },\n",
      "    \"extract\": \"cr:extract\",\n",
      "    \"field\": \"cr:field\",\n",
      "    \"fileProperty\": \"cr:fileProperty\",\n",
      "    \"fileObject\": \"cr:fileObject\",\n",
      "    \"fileSet\": \"cr:fileSet\",\n",
      "    \"format\": \"cr:format\",\n",
      "    \"includes\": \"cr:includes\",\n",
      "    \"isLiveDataset\": \"cr:isLiveDataset\",\n",
      "    \"jsonPath\": \"cr:jsonPath\",\n",
      "    \"key\": \"cr:key\",\n",
      "    \"md5\": {\n",
      "      \"@id\": \"cr:md5\",\n",
      "      \"@type\": \"sc:Text\"\n",
      "    },\n",
      "    \"sha256\": {\n",
      "      \"@id\": \"cr:sha256\",\n",
      "      \"@type\": \"sc:Text\"\n",
      "    },\n",
      "    \"parentField\": \"cr:parentField\",\n",
      "    \"path\": \"cr:path\",\n",
      "    \"personalSensitiveInformation\": \"cr:personalSensitiveInformation\",\n",
      "    \"recordSet\": \"cr:recordSet\",\n",
      "    \"references\": \"cr:references\",\n",
      "    \"regex\": \"cr:regex\",\n",
      "    \"repeated\": \"cr:repeated\",\n",
      "    \"replace\": \"cr:replace\",\n",
      "    \"separator\": \"cr:separator\",\n",
      "    \"source\": \"cr:source\",\n",
      "    \"subField\": \"cr:subField\",\n",
      "    \"transform\": \"cr:transform\"\n",
      "  },\n",
      "  \"@type\": \"Dataset\",\n",
      "  \"@id\": \"icesat2-boreal-v2.1-agb\",\n",
      "  \"name\": \"ICESat-2-Boreal-v2-1--Gridded-Aboveground-Biomass-Density\",\n",
      "  \"description\": \"This dataset provides predictions of woody Aboveground Biomass Density (AGBD) and vegetation height for high northern latitude forests at a 30-m spatial resolution. It is designed both for circumpolar boreal-wide mapping and filling the northern spatial data gap from NASA's Global Ecosystem Dynamics Investigation (GEDI) mission. Mapping woody AGBD and height is essential for understanding, monitoring, and managing forest carbon stocks and fluxes. The AGBD and height predictions cover the extent of high latitude boreal forests and shrublands, and extend southward outside the boreal domain to 51.6\\u00b0N. These maps represent conditions in 2020.\\n\\nICESat-2 ATL08 represented the training data for these mapped products, with ATL08\\u2019s maximum height (h_canopy) used to train the height product, and estimates of 30-m AGBD from ATL08 used to train the AGBD product. AGBD and vegetation models were developed using local moving window models, with models produced for a suite of 90 km tiles.\\n\\nPrediction of AGBD involved two modeling steps: (1) regression with ordinary least squares (OLS) to relate field plot measurements of AGBD to NASA's ICESat-2 30-m ATL08 lidar samples, and (2) machine learning modeling with random forest to extend estimates beyond the field plots by relating ICESat-2 AGBD predictions to wall-to-wall gridded covariate stacks from Harmonized Landsat/Sentinel-2 (HLS) and the Copernicus GLO30 DEM. Per-pixel uncertainties are estimated from bootstrapping both models.\\n\\nPrediction of vegetation height used the second of the two steps for AGBD, since what would otherwise be the dependent variable (height) is a direct measurement from ICESat-2 ATL08. Uncertainty was therefore estimated from bootstrapping the random forest model, with no propagation of any uncertainties from the ICESat-2 height measurements.\\n\\nUncertainties were estimated using bootstrapping of training data to produce a suite of models and maps, which were then summarized to produce pixel-level standard error estimates. Models were re-fit for each 90 km tile until the variance of the 90 km AGBD total stabilized (less than 5% change in the variance of tile total AGBD). The pixel-level SD is calculated as the SD of the set of pixel predictions from these iterations.\\n\\nThis dataset features predictions for landcovers that are associated with the full woody structure gradient according to the European Space Agency\\u2019s Worldcover v1.0 2020 dataset. This primarily includes forests, shrubs, and grass extents in which woody vegetation is present. Importantly, predictions were also made for the \\u2018moss/lichen\\u2019 land cover. The decision to include these pixels considered the broad domain of this study, where areas from the far north down to southern portions featured this classification, but represented very different apparent land uses. In northern portions, this classification occurs frequently across tundra extents (eg, the Brooks Range), whereas in the south it appears at sites of recent forest clearing. Non-vegetated land covers (e.g. built up, water, rock, ice) were masked out of our predictions.\\n\\nHLS composites and ICESat-2 data were from 2020 to produce a single-year 2020 map. ICESat-2 data were filtered to include only strong beams, growing seasons (June through September), solar elevations less than 5 degrees, snow free land (snow flag set to 1), and \\\"msw_flag\\\" equal to 0 (clear skies and no observed atmospheric scattering). ICESat-2's ATL08 product was resampled to a 30-m spatial resolution to better match both the field plots and mapped pixels, which involved reprocessing the nominal 100-m segments to 30-m segments. HLS data (both the L30 and S30 products) were used to create a harmonized (HLSH30) greenest pixel composite of growing season multispectral data, which was then used to compute a suite of vegetation indices: NDVI, NDWI, NBR, NBR2, TCW, TCG. These were then used, in combination with a suite of topographic information (elevation, slope, topographic solar radiation index, topographic position index, and a binary slope mask indicating flat pixels) from the Copernicus DEM product, to predict 30-m AGBD per 90-km tile. Estimates of mean AGBD and mean vegetation height with standard deviation are provided in cloud-optimized GeoTIFF (CoG) format. The product consists of a set of raster grids and tabular (CSV) files referenced to a set of 90-km tiles that cover the circumpolar boreal domain and south to 51.6\\u00b0N (Figure 1). Each raster grid is a 2-band file where the first and second band represent the mean and standard deviation pixel values that result from the bootstrapped prediction. The CSV files feature the ICESat-2 ATL08 30 m segment centroids that were used as training data in the prediction of each raster. A polygon map of these data tiles is included as a GeoPackage file and a Shapefile. This product was generated on the NASA-ESA Multi-Mission Algorithm and Analysis Platform (MAAP, https://scimaap.net), an open science platform. All code and input files are publicly available: [https://github.com/lauraduncanson/icesat2_boreal.git](https://repo.ops.maap-project.org/icesat2_boreal/icesat2_boreal.git).\\n\\nFor each product (AGB and height) there are 3902 cloud-optimized GeoTIFFs, 3902 tables in comma-separated values (CSV) format, and 1 geopackage tile index.\",\n",
      "  \"version\": \"2.1.0\",\n",
      "  \"license\": \"CC-BY\",\n",
      "  \"conformsTo\": \"http://mlcommons.org/croissant/1.0\",\n",
      "  \"citeAs\": \"Duncanson, L., P.M. Montesano, A. Neuenschwander, A. Zarringhalam, N. Thomas, A. Mandel, D. Minor, E. Guenther, S. Hancock, T. Feng, A. Barciauskas, G.W. Chang, S. Shah, and B.P. Satorius. Circumpolar boreal aboveground biomass mapping with ICESat-2. (in prep.)\",\n",
      "  \"citation\": \"Duncanson, L., P.M. Montesano, A. Neuenschwander, A. Zarringhalam, N. Thomas, A. Mandel, D. Minor, E. Guenther, S. Hancock, T. Feng, A. Barciauskas, G.W. Chang, S. Shah, and B.P. Satorius. Circumpolar boreal aboveground biomass mapping with ICESat-2. (in prep.)\",\n",
      "  \"creator\": {\n",
      "    \"@type\": \"Organization\",\n",
      "    \"name\": \"MAAP\",\n",
      "    \"url\": \"https://maap-project.org\"\n",
      "  },\n",
      "  \"url\": \"https://stac.maap-project.org/collections/icesat2-boreal-v2.1-agb\",\n",
      "  \"geocr:BoundingBox\": [\n",
      "    -180,\n",
      "    51.6,\n",
      "    180,\n",
      "    78\n",
      "  ],\n",
      "  \"dct:temporal\": {\n",
      "    \"startDate\": \"2020-01-01T00:00:00Z\",\n",
      "    \"endDate\": \"2020-12-31T23:59:59Z\"\n",
      "  },\n",
      "  \"datePublished\": \"2020-01-01T00:00:00Z\",\n",
      "  \"distribution\": [\n",
      "    {\n",
      "      \"@type\": \"cr:FileObject\",\n",
      "      \"@id\": \"tiles\",\n",
      "      \"name\": \"tiles\",\n",
      "      \"description\": \"90 km tile geometries for processing AGB predictions\",\n",
      "      \"contentUrl\": \"s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/boreal_tiles_v004_AGB_H30_2020_ORNLDAAC.gpkg\",\n",
      "      \"encodingFormat\": \"application/geopackage+sqlite3\",\n",
      "      \"sha256\": \"https://github.com/mlcommons/croissant/issues/80\",\n",
      "      \"md5\": \"https://github.com/mlcommons/croissant/issues/80\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load and pretty-print the content of croissant.json\n",
    "with open(\"croissant.json\", \"r\") as f:\n",
    "    croissant_data = json.load(f)\n",
    "\n",
    "# Pretty-print JSON to console\n",
    "print(json.dumps(croissant_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30c12b-7ff3-4666-8330-1a58d170c678",
   "metadata": {},
   "source": [
    "## Convert STAC to GeoCroissant Metadata\n",
    "This function maps key STAC Collection fields into GeoCroissant JSON-LD format, using predefined field correspondences.\n",
    "## Run the Conversion and Output GeoCroissant\n",
    "Use the conversion function to transform the STAC JSON into GeoCroissant and save it as `croissant.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a31b6-8e67-443f-9736-34325ea7ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mUnmapped STAC Fields:\u001b[0m\n",
      "None \n",
      "\n",
      "GeoCroissant conversion complete. Output saved to 'croissant.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "def sanitize_name(name):\n",
    "    return re.sub(r\"[^a-zA-Z0-9_\\-]\", \"-\", name)\n",
    "\n",
    "\n",
    "def ensure_semver(version):\n",
    "    if not version:\n",
    "        return \"1.0.0\"\n",
    "    if version.startswith(\"v\"):\n",
    "        version = version[1:]\n",
    "    parts = version.split(\".\")\n",
    "    if len(parts) == 2:\n",
    "        parts.append(\"0\")\n",
    "    return \".\".join(parts[:3])\n",
    "\n",
    "\n",
    "def stac_to_geocroissant(stac_dict):\n",
    "    dataset_id = stac_dict.get(\"id\")\n",
    "    name = sanitize_name(stac_dict.get(\"title\", dataset_id or \"UnnamedDataset\"))\n",
    "    version = ensure_semver(stac_dict.get(\"version\", \"1.0.0\"))\n",
    "\n",
    "    croissant = {\n",
    "        \"@context\": {\n",
    "            \"@language\": \"en\",\n",
    "            \"@vocab\": \"https://schema.org/\",\n",
    "            \"cr\": \"http://mlcommons.org/croissant/\",\n",
    "            \"geocr\": \"http://mlcommons.org/geocroissant/\",\n",
    "            \"dct\": \"http://purl.org/dc/terms/\",\n",
    "            \"sc\": \"https://schema.org/\",\n",
    "            \"citeAs\": \"cr:citeAs\",\n",
    "            \"column\": \"cr:column\",\n",
    "            \"conformsTo\": \"dct:conformsTo\",\n",
    "            \"data\": {\"@id\": \"cr:data\", \"@type\": \"@json\"},\n",
    "            \"dataBiases\": \"cr:dataBiases\",\n",
    "            \"dataCollection\": \"cr:dataCollection\",\n",
    "            \"dataType\": {\"@id\": \"cr:dataType\", \"@type\": \"@vocab\"},\n",
    "            \"extract\": \"cr:extract\",\n",
    "            \"field\": \"cr:field\",\n",
    "            \"fileProperty\": \"cr:fileProperty\",\n",
    "            \"fileObject\": \"cr:fileObject\",\n",
    "            \"fileSet\": \"cr:fileSet\",\n",
    "            \"format\": \"cr:format\",\n",
    "            \"includes\": \"cr:includes\",\n",
    "            \"isLiveDataset\": \"cr:isLiveDataset\",\n",
    "            \"jsonPath\": \"cr:jsonPath\",\n",
    "            \"key\": \"cr:key\",\n",
    "            \"md5\": {\"@id\": \"cr:md5\", \"@type\": \"sc:Text\"},\n",
    "            \"sha256\": {\"@id\": \"cr:sha256\", \"@type\": \"sc:Text\"},\n",
    "            \"parentField\": \"cr:parentField\",\n",
    "            \"path\": \"cr:path\",\n",
    "            \"personalSensitiveInformation\": \"cr:personalSensitiveInformation\",\n",
    "            \"recordSet\": \"cr:recordSet\",\n",
    "            \"references\": \"cr:references\",\n",
    "            \"regex\": \"cr:regex\",\n",
    "            \"repeated\": \"cr:repeated\",\n",
    "            \"replace\": \"cr:replace\",\n",
    "            \"separator\": \"cr:separator\",\n",
    "            \"source\": \"cr:source\",\n",
    "            \"subField\": \"cr:subField\",\n",
    "            \"transform\": \"cr:transform\"\n",
    "        },\n",
    "        \"@type\": \"Dataset\",\n",
    "        \"@id\": dataset_id,\n",
    "        \"name\": name,\n",
    "        \"description\": stac_dict.get(\"description\", \"\"),\n",
    "        \"version\": version,\n",
    "        \"license\": stac_dict.get(\"license\", \"CC-BY-4.0\"),\n",
    "        \"conformsTo\": \"http://mlcommons.org/croissant/1.0\"\n",
    "    }\n",
    "\n",
    "    if \"sci:citation\" in stac_dict:\n",
    "        croissant[\"citeAs\"] = stac_dict[\"sci:citation\"]\n",
    "        croissant[\"citation\"] = stac_dict[\"sci:citation\"]\n",
    "\n",
    "    if stac_dict.get(\"providers\"):\n",
    "        provider = stac_dict[\"providers\"][0]\n",
    "        croissant[\"creator\"] = {\n",
    "            \"@type\": \"Organization\",\n",
    "            \"name\": provider.get(\"name\", \"Unknown\"),\n",
    "            \"url\": provider.get(\"url\", \"\")\n",
    "        }\n",
    "\n",
    "    # Handle 'self' URL\n",
    "    for link in stac_dict.get(\"links\", []):\n",
    "        if link.get(\"rel\") == \"self\":\n",
    "            croissant[\"url\"] = link.get(\"href\")\n",
    "            break\n",
    "\n",
    "    # Handle other STAC references\n",
    "    references = []\n",
    "    for link in stac_dict.get(\"links\", []):\n",
    "        rel = link.get(\"rel\")\n",
    "        href = link.get(\"href\")\n",
    "        if not href or rel == \"self\":\n",
    "            continue\n",
    "\n",
    "        name_map = {\n",
    "            \"root\": \"STAC root catalog\",\n",
    "            \"parent\": \"STAC parent catalog\",\n",
    "            \"items\": \"STAC item list\",\n",
    "            \"about\": \"GitHub Repository\",\n",
    "            \"predecessor-version\": \"Previous version\",\n",
    "            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\": \"Queryables\"\n",
    "        }\n",
    "\n",
    "        references.append({\n",
    "            \"@type\": \"CreativeWork\",\n",
    "            \"url\": href,\n",
    "            \"name\": name_map.get(rel, rel),\n",
    "            \"encodingFormat\": link.get(\"type\", \"application/json\")\n",
    "        })\n",
    "\n",
    "    if references:\n",
    "        croissant[\"references\"] = references\n",
    "\n",
    "    # Spatial and temporal extent\n",
    "    spatial = stac_dict.get(\"extent\", {}).get(\"spatial\", {}).get(\"bbox\")\n",
    "    if spatial:\n",
    "        croissant[\"geocr:BoundingBox\"] = spatial[0]\n",
    "\n",
    "    temporal = stac_dict.get(\"extent\", {}).get(\"temporal\", {}).get(\"interval\")\n",
    "    if temporal and temporal[0]:\n",
    "        start, end = temporal[0][0], temporal[0][1]\n",
    "        croissant[\"dct:temporal\"] = {\"startDate\": start, \"endDate\": end}\n",
    "        croissant[\"datePublished\"] = start\n",
    "    else:\n",
    "        croissant[\"datePublished\"] = datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "    # Asset-level distribution\n",
    "    croissant[\"distribution\"] = []\n",
    "    for key, asset in stac_dict.get(\"assets\", {}).items():\n",
    "        file_object = {\n",
    "            \"@type\": \"cr:FileObject\",\n",
    "            \"@id\": key,\n",
    "            \"name\": key,\n",
    "            \"description\": asset.get(\"description\", asset.get(\"title\", \"\")),\n",
    "            \"contentUrl\": asset.get(\"href\"),\n",
    "            \"encodingFormat\": asset.get(\"type\", \"application/octet-stream\"),\n",
    "            \"sha256\": \"https://github.com/mlcommons/croissant/issues/80\",\n",
    "            \"md5\": \"https://github.com/mlcommons/croissant/issues/80\"\n",
    "        }\n",
    "\n",
    "        if \"checksum:multihash\" in asset:\n",
    "            file_object[\"sha256\"] = asset[\"checksum:multihash\"]\n",
    "        elif \"file:checksum\" in asset:\n",
    "            file_object[\"sha256\"] = asset[\"file:checksum\"]\n",
    "        if \"checksum:md5\" in asset:\n",
    "            file_object[\"md5\"] = asset[\"checksum:md5\"]\n",
    "\n",
    "        croissant[\"distribution\"].append(file_object)\n",
    "\n",
    "    # item_assets as fileSet templates\n",
    "    if \"item_assets\" in stac_dict:\n",
    "        croissant[\"fileSet\"] = []\n",
    "        for key, asset in stac_dict[\"item_assets\"].items():\n",
    "            file_obj = {\n",
    "                \"@type\": \"cr:FileObject\",\n",
    "                \"@id\": key,\n",
    "                \"name\": key,\n",
    "                \"description\": asset.get(\"description\", asset.get(\"title\", \"\")),\n",
    "                \"encodingFormat\": asset.get(\"type\", \"application/octet-stream\"),\n",
    "                \"sha256\": \"https://github.com/mlcommons/croissant/issues/80\",\n",
    "                \"md5\": \"https://github.com/mlcommons/croissant/issues/80\"\n",
    "            }\n",
    "            file_set = {\n",
    "                \"@type\": \"cr:FileSet\",\n",
    "                \"name\": f\"Template for {key}\",\n",
    "                \"includes\": [file_obj]\n",
    "            }\n",
    "            croissant[\"fileSet\"].append(file_set)\n",
    "\n",
    "    if \"renders\" in stac_dict:\n",
    "        croissant[\"geocr:visualizations\"] = stac_dict[\"renders\"]\n",
    "\n",
    "    if \"summaries\" in stac_dict:\n",
    "        croissant[\"geocr:summaries\"] = stac_dict[\"summaries\"]\n",
    "\n",
    "    if \"stac_extensions\" in stac_dict:\n",
    "        croissant[\"geocr:stac_extensions\"] = stac_dict[\"stac_extensions\"]\n",
    "    if \"stac_version\" in stac_dict:\n",
    "        croissant[\"geocr:stac_version\"] = stac_dict[\"stac_version\"]\n",
    "\n",
    "    if \"deprecated\" in stac_dict:\n",
    "        croissant[\"isLiveDataset\"] = not stac_dict[\"deprecated\"]\n",
    "\n",
    "    # Report unmapped fields\n",
    "    mapped_keys = {\n",
    "        \"id\", \"type\", \"links\", \"title\", \"assets\", \"extent\",\n",
    "        \"license\", \"version\", \"providers\", \"description\", \"sci:citation\",\n",
    "        \"renders\", \"summaries\", \"stac_extensions\", \"stac_version\", \"deprecated\", \"item_assets\"\n",
    "    }\n",
    "    extra_fields = {k: v for k, v in stac_dict.items() if k not in mapped_keys}\n",
    "    print(\"\\n\\033[1mUnmapped STAC Fields:\\033[0m\")\n",
    "    if extra_fields:\n",
    "        for k, v in extra_fields.items():\n",
    "            print(f\"- {k}: {type(v).__name__}\")\n",
    "    else:\n",
    "        print(\"None \")\n",
    "\n",
    "    return croissant\n",
    "\n",
    "\n",
    "# === Main Runner ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Load STAC Collection JSON\n",
    "    with open(\"stac.json\") as f:\n",
    "        stac_data = json.load(f)\n",
    "\n",
    "    # Convert to GeoCroissant\n",
    "    croissant_json = stac_to_geocroissant(stac_data)\n",
    "\n",
    "    # Save GeoCroissant JSON-LD\n",
    "    with open(\"croissant.json\", \"w\") as f:\n",
    "        json.dump(croissant_json, f, indent=2)\n",
    "\n",
    "    print(\"\\nGeoCroissant conversion complete. Output saved to 'croissant.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5825a7c3-5213-4c35-aa56-4b2fc25b7fd8",
   "metadata": {},
   "source": [
    "## Preview croissant.json\n",
    "Use this cell to inspect the structure and values of the converted metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd3b11-7e2d-4057-9356-33b991210120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"@context\": {\n",
      "    \"@language\": \"en\",\n",
      "    \"@vocab\": \"https://schema.org/\",\n",
      "    \"cr\": \"http://mlcommons.org/croissant/\",\n",
      "    \"geocr\": \"http://mlcommons.org/geocroissant/\",\n",
      "    \"dct\": \"http://purl.org/dc/terms/\",\n",
      "    \"sc\": \"https://schema.org/\",\n",
      "    \"citeAs\": \"cr:citeAs\",\n",
      "    \"column\": \"cr:column\",\n",
      "    \"conformsTo\": \"dct:conformsTo\",\n",
      "    \"data\": {\n",
      "      \"@id\": \"cr:data\",\n",
      "      \"@type\": \"@json\"\n",
      "    },\n",
      "    \"dataBiases\": \"cr:dataBiases\",\n",
      "    \"dataCollection\": \"cr:dataCollection\",\n",
      "    \"dataType\": {\n",
      "      \"@id\": \"cr:dataType\",\n",
      "      \"@type\": \"@vocab\"\n",
      "    },\n",
      "    \"extract\": \"cr:extract\",\n",
      "    \"field\": \"cr:field\",\n",
      "    \"fileProperty\": \"cr:fileProperty\",\n",
      "    \"fileObject\": \"cr:fileObject\",\n",
      "    \"fileSet\": \"cr:fileSet\",\n",
      "    \"format\": \"cr:format\",\n",
      "    \"includes\": \"cr:includes\",\n",
      "    \"isLiveDataset\": \"cr:isLiveDataset\",\n",
      "    \"jsonPath\": \"cr:jsonPath\",\n",
      "    \"key\": \"cr:key\",\n",
      "    \"md5\": {\n",
      "      \"@id\": \"cr:md5\",\n",
      "      \"@type\": \"sc:Text\"\n",
      "    },\n",
      "    \"sha256\": {\n",
      "      \"@id\": \"cr:sha256\",\n",
      "      \"@type\": \"sc:Text\"\n",
      "    },\n",
      "    \"parentField\": \"cr:parentField\",\n",
      "    \"path\": \"cr:path\",\n",
      "    \"personalSensitiveInformation\": \"cr:personalSensitiveInformation\",\n",
      "    \"recordSet\": \"cr:recordSet\",\n",
      "    \"references\": \"cr:references\",\n",
      "    \"regex\": \"cr:regex\",\n",
      "    \"repeated\": \"cr:repeated\",\n",
      "    \"replace\": \"cr:replace\",\n",
      "    \"separator\": \"cr:separator\",\n",
      "    \"source\": \"cr:source\",\n",
      "    \"subField\": \"cr:subField\",\n",
      "    \"transform\": \"cr:transform\"\n",
      "  },\n",
      "  \"@type\": \"Dataset\",\n",
      "  \"@id\": \"icesat2-boreal-v2.1-agb\",\n",
      "  \"name\": \"ICESat-2-Boreal-v2-1--Gridded-Aboveground-Biomass-Density\",\n",
      "  \"description\": \"This dataset provides predictions of woody Aboveground Biomass Density (AGBD) and vegetation height for high northern latitude forests at a 30-m spatial resolution. It is designed both for circumpolar boreal-wide mapping and filling the northern spatial data gap from NASA's Global Ecosystem Dynamics Investigation (GEDI) mission. Mapping woody AGBD and height is essential for understanding, monitoring, and managing forest carbon stocks and fluxes. The AGBD and height predictions cover the extent of high latitude boreal forests and shrublands, and extend southward outside the boreal domain to 51.6\\u00b0N. These maps represent conditions in 2020.\\n\\nICESat-2 ATL08 represented the training data for these mapped products, with ATL08\\u2019s maximum height (h_canopy) used to train the height product, and estimates of 30-m AGBD from ATL08 used to train the AGBD product. AGBD and vegetation models were developed using local moving window models, with models produced for a suite of 90 km tiles.\\n\\nPrediction of AGBD involved two modeling steps: (1) regression with ordinary least squares (OLS) to relate field plot measurements of AGBD to NASA's ICESat-2 30-m ATL08 lidar samples, and (2) machine learning modeling with random forest to extend estimates beyond the field plots by relating ICESat-2 AGBD predictions to wall-to-wall gridded covariate stacks from Harmonized Landsat/Sentinel-2 (HLS) and the Copernicus GLO30 DEM. Per-pixel uncertainties are estimated from bootstrapping both models.\\n\\nPrediction of vegetation height used the second of the two steps for AGBD, since what would otherwise be the dependent variable (height) is a direct measurement from ICESat-2 ATL08. Uncertainty was therefore estimated from bootstrapping the random forest model, with no propagation of any uncertainties from the ICESat-2 height measurements.\\n\\nUncertainties were estimated using bootstrapping of training data to produce a suite of models and maps, which were then summarized to produce pixel-level standard error estimates. Models were re-fit for each 90 km tile until the variance of the 90 km AGBD total stabilized (less than 5% change in the variance of tile total AGBD). The pixel-level SD is calculated as the SD of the set of pixel predictions from these iterations.\\n\\nThis dataset features predictions for landcovers that are associated with the full woody structure gradient according to the European Space Agency\\u2019s Worldcover v1.0 2020 dataset. This primarily includes forests, shrubs, and grass extents in which woody vegetation is present. Importantly, predictions were also made for the \\u2018moss/lichen\\u2019 land cover. The decision to include these pixels considered the broad domain of this study, where areas from the far north down to southern portions featured this classification, but represented very different apparent land uses. In northern portions, this classification occurs frequently across tundra extents (eg, the Brooks Range), whereas in the south it appears at sites of recent forest clearing. Non-vegetated land covers (e.g. built up, water, rock, ice) were masked out of our predictions.\\n\\nHLS composites and ICESat-2 data were from 2020 to produce a single-year 2020 map. ICESat-2 data were filtered to include only strong beams, growing seasons (June through September), solar elevations less than 5 degrees, snow free land (snow flag set to 1), and \\\"msw_flag\\\" equal to 0 (clear skies and no observed atmospheric scattering). ICESat-2's ATL08 product was resampled to a 30-m spatial resolution to better match both the field plots and mapped pixels, which involved reprocessing the nominal 100-m segments to 30-m segments. HLS data (both the L30 and S30 products) were used to create a harmonized (HLSH30) greenest pixel composite of growing season multispectral data, which was then used to compute a suite of vegetation indices: NDVI, NDWI, NBR, NBR2, TCW, TCG. These were then used, in combination with a suite of topographic information (elevation, slope, topographic solar radiation index, topographic position index, and a binary slope mask indicating flat pixels) from the Copernicus DEM product, to predict 30-m AGBD per 90-km tile. Estimates of mean AGBD and mean vegetation height with standard deviation are provided in cloud-optimized GeoTIFF (CoG) format. The product consists of a set of raster grids and tabular (CSV) files referenced to a set of 90-km tiles that cover the circumpolar boreal domain and south to 51.6\\u00b0N (Figure 1). Each raster grid is a 2-band file where the first and second band represent the mean and standard deviation pixel values that result from the bootstrapped prediction. The CSV files feature the ICESat-2 ATL08 30 m segment centroids that were used as training data in the prediction of each raster. A polygon map of these data tiles is included as a GeoPackage file and a Shapefile. This product was generated on the NASA-ESA Multi-Mission Algorithm and Analysis Platform (MAAP, https://scimaap.net), an open science platform. All code and input files are publicly available: [https://github.com/lauraduncanson/icesat2_boreal.git](https://repo.ops.maap-project.org/icesat2_boreal/icesat2_boreal.git).\\n\\nFor each product (AGB and height) there are 3902 cloud-optimized GeoTIFFs, 3902 tables in comma-separated values (CSV) format, and 1 geopackage tile index.\",\n",
      "  \"version\": \"2.1.0\",\n",
      "  \"license\": \"CC-BY\",\n",
      "  \"conformsTo\": \"http://mlcommons.org/croissant/1.0\",\n",
      "  \"citeAs\": \"Duncanson, L., P.M. Montesano, A. Neuenschwander, A. Zarringhalam, N. Thomas, A. Mandel, D. Minor, E. Guenther, S. Hancock, T. Feng, A. Barciauskas, G.W. Chang, S. Shah, and B.P. Satorius. Circumpolar boreal aboveground biomass mapping with ICESat-2. (in prep.)\",\n",
      "  \"citation\": \"Duncanson, L., P.M. Montesano, A. Neuenschwander, A. Zarringhalam, N. Thomas, A. Mandel, D. Minor, E. Guenther, S. Hancock, T. Feng, A. Barciauskas, G.W. Chang, S. Shah, and B.P. Satorius. Circumpolar boreal aboveground biomass mapping with ICESat-2. (in prep.)\",\n",
      "  \"creator\": {\n",
      "    \"@type\": \"Organization\",\n",
      "    \"name\": \"MAAP\",\n",
      "    \"url\": \"https://maap-project.org\"\n",
      "  },\n",
      "  \"url\": \"https://stac.maap-project.org/collections/icesat2-boreal-v2.1-agb\",\n",
      "  \"references\": [\n",
      "    {\n",
      "      \"@type\": \"CreativeWork\",\n",
      "      \"url\": \"https://stac.maap-project.org/collections/icesat2-boreal-v2.1-agb/items\",\n",
      "      \"name\": \"STAC item list\",\n",
      "      \"encodingFormat\": \"application/geo+json\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"CreativeWork\",\n",
      "      \"url\": \"https://stac.maap-project.org/\",\n",
      "      \"name\": \"STAC parent catalog\",\n",
      "      \"encodingFormat\": \"application/json\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"CreativeWork\",\n",
      "      \"url\": \"https://stac.maap-project.org/\",\n",
      "      \"name\": \"STAC root catalog\",\n",
      "      \"encodingFormat\": \"application/json\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"CreativeWork\",\n",
      "      \"url\": \"https://github.com/lauraduncanson/icesat2_boreal\",\n",
      "      \"name\": \"GitHub Repository\",\n",
      "      \"encodingFormat\": \"text/html\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"CreativeWork\",\n",
      "      \"url\": \"https://stac.maap-project.org/collections/icesat2-boreal\",\n",
      "      \"name\": \"Previous version\",\n",
      "      \"encodingFormat\": \"application/json\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"CreativeWork\",\n",
      "      \"url\": \"https://stac.maap-project.org/collections/icesat2-boreal-v2.1-agb/queryables\",\n",
      "      \"name\": \"Queryables\",\n",
      "      \"encodingFormat\": \"application/schema+json\"\n",
      "    }\n",
      "  ],\n",
      "  \"geocr:BoundingBox\": [\n",
      "    -180,\n",
      "    51.6,\n",
      "    180,\n",
      "    78\n",
      "  ],\n",
      "  \"dct:temporal\": {\n",
      "    \"startDate\": \"2020-01-01T00:00:00Z\",\n",
      "    \"endDate\": \"2020-12-31T23:59:59Z\"\n",
      "  },\n",
      "  \"datePublished\": \"2020-01-01T00:00:00Z\",\n",
      "  \"distribution\": [\n",
      "    {\n",
      "      \"@type\": \"cr:FileObject\",\n",
      "      \"@id\": \"tiles\",\n",
      "      \"name\": \"tiles\",\n",
      "      \"description\": \"90 km tile geometries for processing AGB predictions\",\n",
      "      \"contentUrl\": \"s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/boreal_tiles_v004_AGB_H30_2020_ORNLDAAC.gpkg\",\n",
      "      \"encodingFormat\": \"application/geopackage+sqlite3\",\n",
      "      \"sha256\": \"https://github.com/mlcommons/croissant/issues/80\",\n",
      "      \"md5\": \"https://github.com/mlcommons/croissant/issues/80\"\n",
      "    }\n",
      "  ],\n",
      "  \"fileSet\": [\n",
      "    {\n",
      "      \"@type\": \"cr:FileSet\",\n",
      "      \"name\": \"Template for cog\",\n",
      "      \"includes\": [\n",
      "        {\n",
      "          \"@type\": \"cr:FileObject\",\n",
      "          \"@id\": \"cog\",\n",
      "          \"name\": \"cog\",\n",
      "          \"description\": \"Gridded predictions of aboveground biomass (Mg/ha)\",\n",
      "          \"encodingFormat\": \"image/tiff; application=geotiff; profile=cloud-optimized\",\n",
      "          \"sha256\": \"https://github.com/mlcommons/croissant/issues/80\",\n",
      "          \"md5\": \"https://github.com/mlcommons/croissant/issues/80\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"cr:FileSet\",\n",
      "      \"name\": \"Template for training_data_csv\",\n",
      "      \"includes\": [\n",
      "        {\n",
      "          \"@type\": \"cr:FileObject\",\n",
      "          \"@id\": \"training_data_csv\",\n",
      "          \"name\": \"training_data_csv\",\n",
      "          \"description\": \"Tabular training data with latitude, longitude, and biomass observations\",\n",
      "          \"encodingFormat\": \"text/csv\",\n",
      "          \"sha256\": \"https://github.com/mlcommons/croissant/issues/80\",\n",
      "          \"md5\": \"https://github.com/mlcommons/croissant/issues/80\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"geocr:visualizations\": {\n",
      "    \"agb_viridis\": {\n",
      "      \"title\": \"Aboveground biomass (Mg/ha)\",\n",
      "      \"assets\": [\n",
      "        \"cog\"\n",
      "      ],\n",
      "      \"rescale\": [\n",
      "        [\n",
      "          0,\n",
      "          125\n",
      "        ]\n",
      "      ],\n",
      "      \"expression\": \"cog_b1\",\n",
      "      \"minmax_zoom\": [\n",
      "        6,\n",
      "        18\n",
      "      ],\n",
      "      \"colormap_name\": \"viridis\"\n",
      "    },\n",
      "    \"agb_gist_earth_r\": {\n",
      "      \"title\": \"Aboveground biomass (Mg/ha)\",\n",
      "      \"assets\": [\n",
      "        \"cog\"\n",
      "      ],\n",
      "      \"rescale\": [\n",
      "        [\n",
      "          0,\n",
      "          400\n",
      "        ]\n",
      "      ],\n",
      "      \"expression\": \"cog_b1\",\n",
      "      \"minmax_zoom\": [\n",
      "        6,\n",
      "        18\n",
      "      ],\n",
      "      \"color_formula\": \"gamma r 1.05\",\n",
      "      \"colormap_name\": \"gist_earth_r\"\n",
      "    }\n",
      "  },\n",
      "  \"geocr:summaries\": {\n",
      "    \"gsd\": {\n",
      "      \"maximum\": 30,\n",
      "      \"minimum\": 30\n",
      "    },\n",
      "    \"mission\": [\n",
      "      \"ABoVE\"\n",
      "    ],\n",
      "    \"platform\": [\n",
      "      \"LANDSAT-8\",\n",
      "      \"LANDSAT-9\",\n",
      "      \"SENTINEL-2A\",\n",
      "      \"SENTINEL-2B\",\n",
      "      \"ICESat-2\"\n",
      "    ],\n",
      "    \"instruments\": [\n",
      "      \"Advanced Topographic Laser Altimeter System\",\n",
      "      \"Operational Land Imager\",\n",
      "      \"Operational Land Imager 2\",\n",
      "      \"Sentinel-2 Multispectral Imager\"\n",
      "    ],\n",
      "    \"processing:level\": [\n",
      "      \"L4\"\n",
      "    ]\n",
      "  },\n",
      "  \"geocr:stac_extensions\": [\n",
      "    \"https://stac-extensions.github.io/version/v1.2.0/schema.json\",\n",
      "    \"https://stac-extensions.github.io/processing/v1.2.0/schema.json\",\n",
      "    \"https://stac-extensions.github.io/render/v2.0.0/schema.json\",\n",
      "    \"https://stac-extensions.github.io/scientific/v1.0.0/schema.json\"\n",
      "  ],\n",
      "  \"geocr:stac_version\": \"1.1.0\",\n",
      "  \"isLiveDataset\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load and pretty-print the content of croissant.json\n",
    "with open(\"croissant.json\", \"r\") as f:\n",
    "    croissant_data = json.load(f)\n",
    "\n",
    "# Pretty-print JSON to console\n",
    "print(json.dumps(croissant_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead80611-0b07-4830-b565-d29e3298e803",
   "metadata": {},
   "source": [
    "# Validate with mlcroissant\n",
    "We use the `mlcroissant` CLI to validate the structure of the generated JSON-LD.\n",
    "```bash\n",
    "!mlcroissant validate --jsonld=croissant.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0ec5ccd-2a51-4eb4-a8ef-c45e5d9688a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0629 17:30:03.355020 138358395765120 rdf.py:80] WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'examples', 'rai'}\n",
      "I0629 17:30:03.372449 138358395765120 validate.py:53] Done.\n"
     ]
    }
   ],
   "source": [
    "!mlcroissant validate --jsonld=croissant.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf5dfee-1427-4f7a-b775-b25b094da32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'examples', 'rai'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset loaded successfully.\n",
      "Validation Report:-\n",
      "\n",
      "No errors found.\n",
      "\n",
      "No warnings found.\n"
     ]
    }
   ],
   "source": [
    "from mlcroissant import Dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = Dataset(\"croissant.json\")\n",
    "\n",
    "# Print validation issues (errors + warnings)\n",
    "print(\"\\nDataset loaded successfully.\")\n",
    "print(\"Validation Report:-\")\n",
    "\n",
    "# Access and report issues correctly from the context\n",
    "issues = dataset.metadata.ctx.issues\n",
    "\n",
    "# Print errors\n",
    "if issues.errors:\n",
    "    print(\"\\nErrors:\")\n",
    "    for error in issues.errors:\n",
    "        print(f\"  - {error}\")\n",
    "else:\n",
    "    print(\"\\nNo errors found.\")\n",
    "\n",
    "# Print warnings\n",
    "if issues.warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for warning in issues.warnings:\n",
    "        print(f\"  - {warning}\")\n",
    "else:\n",
    "    print(\"\\nNo warnings found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666a9ca7-3fa2-4a7d-9377-7f4f44290556",
   "metadata": {},
   "source": [
    "## Print Reference Links\n",
    "This cell prints external references linked via the `references` property in GeoCroissant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d0f189c-cdd7-47f1-8a39-08df03b9e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Referenced STAC Links:\n",
      "  - STAC item list: https://stac.maap-project.org/collections/icesat2-boreal-v2.1-agb/items (application/geo+json)\n",
      "  - STAC parent catalog: https://stac.maap-project.org/ (application/json)\n",
      "  - STAC root catalog: https://stac.maap-project.org/ (application/json)\n",
      "  - GitHub Repository: https://github.com/lauraduncanson/icesat2_boreal (text/html)\n",
      "  - Previous version: https://stac.maap-project.org/collections/icesat2-boreal (application/json)\n",
      "  - Queryables: https://stac.maap-project.org/collections/icesat2-boreal-v2.1-agb/queryables (application/schema+json)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load your croissant.json\n",
    "with open(\"croissant.json\", \"r\") as f:\n",
    "    croissant = json.load(f)\n",
    "\n",
    "# Print all reference links\n",
    "print(\"\\nReferenced STAC Links:\")\n",
    "for ref in croissant.get(\"references\", []):\n",
    "    name = ref.get(\"name\")\n",
    "    url = ref.get(\"url\")\n",
    "    fmt = ref.get(\"encodingFormat\")\n",
    "    print(f\"  - {name}: {url} ({fmt})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8a178-0c7a-43f4-a89a-c936722ef964",
   "metadata": {},
   "source": [
    "## Print STAC Items & Distribution URLs\n",
    "We extract and list all STAC item links and distribution file download URLs from `croissant.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edea2193-6199-47de-8a49-08f4a4b88d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- STAC item list: https://stac.maap-project.org/collections/icesat2-boreal-v2.1-agb/items\n",
      "  - STAC parent catalog: https://stac.maap-project.org/ (application/json)\n",
      "  - STAC root catalog: https://stac.maap-project.org/ (application/json)\n",
      "  - GitHub Repository: https://github.com/lauraduncanson/icesat2_boreal (text/html)\n",
      "  - Previous version: https://stac.maap-project.org/collections/icesat2-boreal (application/json)\n",
      "  - Queryables: https://stac.maap-project.org/collections/icesat2-boreal-v2.1-agb/queryables (application/schema+json)\n",
      "\n",
      "Referenced Distribution Files:\n",
      "  - tiles (application/geopackage+sqlite3): s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/boreal_tiles_v004_AGB_H30_2020_ORNLDAAC.gpkg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"croissant.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# STAC item list from base collection URL\n",
    "url = data.get(\"url\", \"\")\n",
    "if url:\n",
    "    print(f\"- STAC item list: {url.rstrip('/')}/items\")\n",
    "\n",
    "# STAC reference map\n",
    "ref_map = {\n",
    "    \"parent\": \"STAC parent catalog\",\n",
    "    \"root\": \"STAC root catalog\",\n",
    "    \"github\": \"GitHub Repository\",\n",
    "    \"previous\": \"Previous version\",\n",
    "    \"queryables\": \"Queryables\"\n",
    "}\n",
    "\n",
    "for r in data.get(\"references\", []):\n",
    "    for key, label in ref_map.items():\n",
    "        if key in r.get(\"name\", \"\").lower():\n",
    "            print(f\"  - {label}: {r['url']} ({r.get('encodingFormat', 'application/json')})\")\n",
    "\n",
    "# Distributions\n",
    "dists = data.get(\"distribution\", [])\n",
    "if dists:\n",
    "    print(\"\\nReferenced Distribution Files:\")\n",
    "    for d in dists:\n",
    "        print(f\"  - {d.get('name', 'Unnamed')} ({d.get('encodingFormat', 'unknown')}): {d.get('contentUrl', 'No URL')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78dd50f0-02cc-4a5a-9983-70d17d92e51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STAC Items:\n",
      "- boreal_agb_2020_202501211737487322_0039261 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261_train_data.csv\n",
      "- boreal_agb_2020_202411261732638547_0001981 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0001981/boreal_agb_2020_202411261732638547_0001981.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0001981/boreal_agb_2020_202411261732638547_0001981_train_data.csv\n",
      "- boreal_agb_2020_202411261732638346_0003509 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0003509/boreal_agb_2020_202411261732638346_0003509.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0003509/boreal_agb_2020_202411261732638346_0003509_train_data.csv\n",
      "- boreal_agb_2020_202411261732638324_0001831 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0001831/boreal_agb_2020_202411261732638324_0001831.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0001831/boreal_agb_2020_202411261732638324_0001831_train_data.csv\n",
      "- boreal_agb_2020_202411261732638278_0002770 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0002770/boreal_agb_2020_202411261732638278_0002770.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0002770/boreal_agb_2020_202411261732638278_0002770_train_data.csv\n",
      "- boreal_agb_2020_202411261732638262_0000556 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0000556/boreal_agb_2020_202411261732638262_0000556.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0000556/boreal_agb_2020_202411261732638262_0000556_train_data.csv\n",
      "- boreal_agb_2020_202411261732638007_0000873 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0000873/boreal_agb_2020_202411261732638007_0000873.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0000873/boreal_agb_2020_202411261732638007_0000873_train_data.csv\n",
      "- boreal_agb_2020_202411261732637958_0000874 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0000874/boreal_agb_2020_202411261732637958_0000874.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0000874/boreal_agb_2020_202411261732637958_0000874_train_data.csv\n",
      "- boreal_agb_2020_202411261732637725_0003913 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0003913/boreal_agb_2020_202411261732637725_0003913.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0003913/boreal_agb_2020_202411261732637725_0003913_train_data.csv\n",
      "- boreal_agb_2020_202411261732637661_0038382 | 2020-07-01T23:59:59.500000Z\n",
      "   COG: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0038382/boreal_agb_2020_202411261732637661_0038382.tif\n",
      "   TRAINING_DATA_CSV: s3://nasa-maap-data-store/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0038382/boreal_agb_2020_202411261732637661_0038382_train_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Load croissant.json\n",
    "with open(\"croissant.json\", \"r\") as f:\n",
    "    croissant = json.load(f)\n",
    "\n",
    "# Find STAC item list URL from references\n",
    "item_list_url = None\n",
    "for ref in croissant.get(\"references\", []):\n",
    "    if \"item list\" in ref.get(\"name\", \"\").lower():\n",
    "        item_list_url = ref.get(\"url\")\n",
    "        break\n",
    "\n",
    "if item_list_url:\n",
    "    print(\"\\nSTAC Items:\")\n",
    "    stac_items = requests.get(item_list_url).json()\n",
    "    for feature in stac_items.get(\"features\", []):\n",
    "        item_id = feature.get(\"id\")\n",
    "        date = feature.get(\"properties\", {}).get(\"datetime\", \"\")\n",
    "        print(f\"- {item_id} | {date}\")\n",
    "        for asset_key, asset in feature.get(\"assets\", {}).items():\n",
    "            print(f\"   {asset_key.upper()}: {asset['href']}\")\n",
    "else:\n",
    "    print(\"STAC item list URL not found in references.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29afba96-52cf-4442-8a63-7b610cccaab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in HTTP response code on https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261.aux: 403\n",
      "WARNING:rasterio._env:CPLE_AppDefined in HTTP response code on https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261.AUX: 403\n",
      "WARNING:rasterio._env:CPLE_AppDefined in HTTP response code on https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261.tif.aux: 403\n",
      "WARNING:rasterio._env:CPLE_AppDefined in HTTP response code on https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261.tif.AUX: 403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata:\n",
      "{\n",
      "  \"driver\": \"GTiff\",\n",
      "  \"dtype\": \"float32\",\n",
      "  \"nodata\": NaN,\n",
      "  \"width\": 3000,\n",
      "  \"height\": 3000,\n",
      "  \"count\": 2,\n",
      "  \"crs\": \"PROJCS[\\\"unnamed\\\",GEOGCS[\\\"GRS 1980(IUGG, 1980)\\\",DATUM[\\\"unknown\\\",SPHEROID[\\\"GRS80\\\",6378137,298.257222101],TOWGS84[0,0,0,0,0,0,0]],PRIMEM[\\\"Greenwich\\\",0],UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY[\\\"EPSG\\\",\\\"9122\\\"]]],PROJECTION[\\\"Albers_Conic_Equal_Area\\\"],PARAMETER[\\\"latitude_of_center\\\",40],PARAMETER[\\\"longitude_of_center\\\",180],PARAMETER[\\\"standard_parallel_1\\\",50],PARAMETER[\\\"standard_parallel_2\\\",70],PARAMETER[\\\"false_easting\\\",0],PARAMETER[\\\"false_northing\\\",0],UNIT[\\\"metre\\\",1,AUTHORITY[\\\"EPSG\\\",\\\"9001\\\"]],AXIS[\\\"Easting\\\",EAST],AXIS[\\\"Northing\\\",NORTH]]\",\n",
      "  \"transform\": [\n",
      "    30.0,\n",
      "    0.0,\n",
      "    2078521.9999999953,\n",
      "    0.0,\n",
      "    -30.0,\n",
      "    4383304.000000009,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    1.0\n",
      "  ]\n",
      "}\n",
      "\n",
      "CRS: PROJCS[\"unnamed\",GEOGCS[\"GRS 1980(IUGG, 1980)\",DATUM[\"unknown\",SPHEROID[\"GRS80\",6378137,298.257222101],TOWGS84[0,0,0,0,0,0,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",40],PARAMETER[\"longitude_of_center\",180],PARAMETER[\"standard_parallel_1\",50],PARAMETER[\"standard_parallel_2\",70],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n",
      "Shape: 3000x3000, Bands: 2\n",
      "\n",
      "Band 1 Stats:\n",
      "  - Shape         : (3000, 3000)\n",
      "  - Total pixels  : 9000000\n",
      "  - Valid pixels  : 572940\n",
      "  - NaNs (masked) : 8427060\n",
      "  - Min           : 0.523762\n",
      "  - Max           : 3.271828\n",
      "  - Mean          : 0.776952\n",
      "\n",
      "Band 2 Stats:\n",
      "  - Shape         : (3000, 3000)\n",
      "  - Total pixels  : 9000000\n",
      "  - Valid pixels  : 572940\n",
      "  - NaNs (masked) : 8427060\n",
      "  - Min           : 0.076096\n",
      "  - Max           : 1.029612\n",
      "  - Mean          : 0.193747\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# URL of the COG file via /vsicurl\n",
    "cog_url = \"/vsicurl/https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261.tif\"\n",
    "\n",
    "with rasterio.Env(AWS_NO_SIGN_REQUEST=\"YES\"):\n",
    "    with rasterio.open(cog_url) as src:\n",
    "        # ---- Print metadata (JSON safe) ----\n",
    "        meta = src.meta.copy()\n",
    "        if 'crs' in meta and meta['crs'] is not None:\n",
    "            meta['crs'] = meta['crs'].to_string()\n",
    "\n",
    "        print(\"Metadata:\")\n",
    "        print(json.dumps(meta, indent=2))\n",
    "\n",
    "        # ---- Print image summary ----\n",
    "        print(f\"\\nCRS: {src.crs}\")\n",
    "        print(f\"Shape: {src.width}x{src.height}, Bands: {src.count}\")\n",
    "\n",
    "        for i in range(1, src.count + 1):\n",
    "            band = src.read(i, masked=True)  # Returns a MaskedArray\n",
    "            mask = band.mask\n",
    "            data = band.data\n",
    "\n",
    "            total_pixels = band.size\n",
    "            valid_pixels = np.count_nonzero(~mask)\n",
    "            nan_pixels = np.count_nonzero(mask)\n",
    "\n",
    "            print(f\"\\nBand {i} Stats:\")\n",
    "            print(f\"  - Shape         : {band.shape}\")\n",
    "            print(f\"  - Total pixels  : {total_pixels}\")\n",
    "            print(f\"  - Valid pixels  : {valid_pixels}\")\n",
    "            print(f\"  - NaNs (masked) : {nan_pixels}\")\n",
    "\n",
    "            if valid_pixels > 0:\n",
    "                print(f\"  - Min           : {data[~mask].min():.6f}\")\n",
    "                print(f\"  - Max           : {data[~mask].max():.6f}\")\n",
    "                print(f\"  - Mean          : {data[~mask].mean():.6f}\")\n",
    "            else:\n",
    "                print(\"No valid data in this band.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279cab9-96a5-4289-b6e3-adca3225639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.io import MemoryFile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import folium\n",
    "\n",
    "def reproject_to_wgs84(src_url):\n",
    "    with rasterio.open(src_url) as src:\n",
    "        dst_crs = 'EPSG:4326'\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "        memfile = MemoryFile()\n",
    "        with memfile.open(**kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest\n",
    "                )\n",
    "        return memfile.open()\n",
    "\n",
    "def image_to_base64_png(dataset, band_index):\n",
    "    band = dataset.read(band_index)\n",
    "    norm = np.clip((band - np.nanmin(band)) / (np.nanpercentile(band, 98) - np.nanmin(band)), 0, 1)\n",
    "    rgb = np.uint8(norm * 255)\n",
    "    rgb = np.stack([rgb] * 3, axis=-1)\n",
    "    \n",
    "    img = Image.fromarray(rgb)\n",
    "    buffer = io.BytesIO()\n",
    "    img.save(buffer, format=\"PNG\")\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# URL to your raster\n",
    "cog_url = \"https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261.tif\"\n",
    "\n",
    "# Reproject\n",
    "reprojected_ds = reproject_to_wgs84(cog_url)\n",
    "bounds = reprojected_ds.bounds\n",
    "\n",
    "# Create Folium map\n",
    "m = folium.Map(\n",
    "    location=[(bounds.top + bounds.bottom) / 2, (bounds.left + bounds.right) / 2],\n",
    "    zoom_start=6,\n",
    "    tiles='cartodbpositron'\n",
    ")\n",
    "\n",
    "# Add each band as overlay\n",
    "for band_index in range(1, reprojected_ds.count + 1):\n",
    "    img_base64 = image_to_base64_png(reprojected_ds, band_index)\n",
    "    folium.raster_layers.ImageOverlay(\n",
    "        image=f\"data:image/png;base64,{img_base64}\",\n",
    "        bounds=[[bounds.bottom, bounds.left], [bounds.top, bounds.right]],\n",
    "        opacity=0.6,\n",
    "        name=f\"Band {band_index}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562377a-3844-490e-9a60-466bfd53230d",
   "metadata": {},
   "source": [
    "## Raster + Vector + CSV Preview using Folium\n",
    "This optional section demonstrates how to:\n",
    "\n",
    "- Reproject a COG TIFF to EPSG:4326\n",
    "- Display with Folium\n",
    "- Add vector (GeoPackage) and point (CSV) layers\n",
    "\n",
    "Useful for visual QA of spatial coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c12df-178c-4d5e-a71b-075d22bd04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "from folium.plugins import MarkerCluster\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.io import MemoryFile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# --- Function to reproject raster to WGS84 ---\n",
    "def reproject_to_wgs84(src_url):\n",
    "    with rasterio.open(src_url) as src:\n",
    "        dst_crs = 'EPSG:4326'\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "        memfile = MemoryFile()\n",
    "        with memfile.open(**kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest\n",
    "                )\n",
    "        return memfile.open()\n",
    "\n",
    "# --- Convert a raster band to base64 PNG for folium overlay ---\n",
    "def image_to_base64_png(dataset, band_index):\n",
    "    band = dataset.read(band_index)\n",
    "    norm = np.clip((band - np.nanmin(band)) / (np.nanpercentile(band, 98) - np.nanmin(band)), 0, 1)\n",
    "    rgb = np.uint8(norm * 255)\n",
    "    rgb = np.stack([rgb] * 3, axis=-1)\n",
    "    img = Image.fromarray(rgb)\n",
    "    buffer = io.BytesIO()\n",
    "    img.save(buffer, format=\"PNG\")\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# --- Initialize base map ---\n",
    "m = folium.Map(location=[60, -100], zoom_start=4, tiles=\"CartoDB positron\")\n",
    "\n",
    "# --- 1. AGB COG Image Overlay ---\n",
    "cog_url = \"https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261.tif\"\n",
    "reprojected_ds = reproject_to_wgs84(cog_url)\n",
    "bounds = reprojected_ds.bounds\n",
    "img_base64 = image_to_base64_png(reprojected_ds, 1)\n",
    "\n",
    "folium.raster_layers.ImageOverlay(\n",
    "    image=f\"data:image/png;base64,{img_base64}\",\n",
    "    bounds=[[bounds.bottom, bounds.left], [bounds.top, bounds.right]],\n",
    "    opacity=0.6,\n",
    "    name=\"AGB COG Image (Band 1)\"\n",
    ").add_to(m)\n",
    "\n",
    "# --- 2. GPKG Tile Boundaries ---\n",
    "gpkg_url = \"https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/boreal_tiles_v004_AGB_H30_2020_ORNLDAAC.gpkg\"\n",
    "gpkg_path = \"boreal_tiles.gpkg\"\n",
    "with open(gpkg_path, \"wb\") as f:\n",
    "    f.write(requests.get(gpkg_url).content)\n",
    "\n",
    "gdf = gpd.read_file(gpkg_path).to_crs(\"EPSG:4326\")\n",
    "tooltip = folium.GeoJsonTooltip(fields=[\"tile_id\"]) if \"tile_id\" in gdf.columns else None\n",
    "\n",
    "folium.GeoJson(\n",
    "    gdf,\n",
    "    name=\"Tile Boundaries\",\n",
    "    tooltip=tooltip\n",
    ").add_to(m)\n",
    "\n",
    "# --- 3. Training Data Points ---\n",
    "csv_url = \"https://nasa-maap-data-store.s3.amazonaws.com/file-staging/nasa-map/icesat2-boreal-v2.1/agb/0039261/boreal_agb_2020_202501211737487322_0039261_train_data.csv\"\n",
    "csv_path = \"train_data.csv\"\n",
    "with open(csv_path, \"wb\") as f:\n",
    "    f.write(requests.get(csv_url).content)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "marker_cluster = MarkerCluster(name=\"Training Data\").add_to(m)\n",
    "\n",
    "# Fixed lat/lon column names and popup text\n",
    "for _, row in df.iterrows():\n",
    "    lat, lon = row.get(\"lat\"), row.get(\"lon\")\n",
    "    if pd.notna(lat) and pd.notna(lon):\n",
    "        popup_text = f\"AGB: {row.get('AGB', 'NA')} ± {row.get('SE', 'NA')}\"\n",
    "        folium.CircleMarker(\n",
    "            location=[lat, lon],\n",
    "            radius=2,\n",
    "            color=\"blue\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            popup=popup_text\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "# --- Add layer control ---\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# --- Display inline in Jupyter ---\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
