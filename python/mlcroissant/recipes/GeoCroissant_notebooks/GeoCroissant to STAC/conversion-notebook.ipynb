{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd23ba6a-9757-49f3-ad54-8aefe4ebeeab",
   "metadata": {},
   "source": [
    "#  GeoCroissant to STAC Conversion\n",
    "\n",
    "<img src=\"GeoCroissant.jpg\" alt=\"GeoCroissant\" width=\"150\" style=\"float: right; margin-left: 50px;\">\n",
    "\n",
    "\n",
    "This notebook demonstrates how to convert **GeoCroissant metadata** — a geospatial extension of the Croissant metadata format — into a **STAC (SpatioTemporal Asset Catalog) Item**.\n",
    "\n",
    "### GeoCroissant includes:\n",
    "- Spatial information (geometry, bounding boxes)\n",
    "- Temporal coverage\n",
    "- Dataset structure (distributions, record sets)\n",
    "\n",
    "### By converting GeoCroissant to STAC:\n",
    "- Datasets become interoperable with geospatial tools and catalogs.\n",
    "- Metadata is structured using the **STAC specification**, enabling better discovery and analysis of spatial datasets.\n",
    "\n",
    "###  We use Python and `pystac` to:\n",
    "- Parse the GeoCroissant JSON.\n",
    "- Create a valid STAC Item with spatial and temporal context.\n",
    "- Add assets and structured data (e.g., imagery, annotations).\n",
    "- Save and validate the result with `stac-validator`.\n",
    "\n",
    "### Differences: STAC vs GeoCroissant\n",
    "\n",
    "| **STAC Field**             | **GeoCroissant Field**      | **Notes**                                                               |\n",
    "|----------------------------|------------------------------|-------------------------------------------------------------------------|\n",
    "| `id`                       | `@id`                        | Unique identifier for the dataset/item                                 |\n",
    "| `type`                     | `@type`                      | Usually `\"Feature\"` in STAC                                            |\n",
    "| `title`                    | `name`                       | Title of the dataset                                                   |\n",
    "| `description`              | `description`                | Dataset description                                                    |\n",
    "| `datetime`                 | `dct:temporal`               | Temporal coverage (inferred or computed)                               |\n",
    "| `bbox`                     | `geocr:BoundingBox`          | Spatial extent (bounding box)                                          |\n",
    "| `geometry`                 | `geocr:Geometry`             | Full spatial geometry (GeoJSON)                                        |\n",
    "| `assets`                   | `distribution`               | Resources related to the dataset                                       |\n",
    "| `assets[<key>].href`       | `contentUrl`                 | Link to the data asset                                                 |\n",
    "| `assets[<key>].type`       | `encodingFormat`             | Media type of the asset (e.g., `image/png`, `application/parquet`)     |\n",
    "| `properties[\"datetime\"]`   | *N/A*                        | Typically midpoint of the date range                                   |\n",
    "| `properties[\"spatial\"]`    | *N/A*                        | Not standardized in GeoCroissant; often inferred manually              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27708168-859f-412a-9376-a4171eae70d0",
   "metadata": {},
   "source": [
    "#  Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed40588d-dbb7-4cdf-bb63-ded3c4cabc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pystac in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pystac) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.7.0->pystac) (1.17.0)\n",
      "Requirement already satisfied: stac-validator in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: requests>=2.32.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stac-validator) (2.32.3)\n",
      "Requirement already satisfied: jsonschema>=4.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stac-validator) (4.24.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stac-validator) (8.2.1)\n",
      "Requirement already satisfied: referencing>=0.35.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stac-validator) (0.36.2)\n",
      "Requirement already satisfied: pyYAML>=6.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stac-validator) (6.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=4.23.0->stac-validator) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=4.23.0->stac-validator) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=4.23.0->stac-validator) (0.25.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from referencing>=0.35.1->stac-validator) (4.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.3->stac-validator) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.3->stac-validator) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.3->stac-validator) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.3->stac-validator) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install pystac\n",
    "!pip install stac-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e3749-8e64-4329-afd1-0629b5ae6663",
   "metadata": {},
   "source": [
    "# Basic GeoCroissant to STAC Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcaf0f3a-6718-4dcb-8e1e-5d2275490c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"Feature\",\n",
      "  \"stac_version\": \"1.1.0\",\n",
      "  \"stac_extensions\": [],\n",
      "  \"id\": \"10.57967/hf/0956\",\n",
      "  \"geometry\": null,\n",
      "  \"properties\": {\n",
      "    \"start_datetime\": \"2018-01-01T00:00:00Z\",\n",
      "    \"end_datetime\": \"2021-12-31T00:00:00Z\",\n",
      "    \"title\": \"hls_burn_scars\",\n",
      "    \"description\": \"This dataset contains Harmonized Landsat and Sentinel-2 imagery of burn scars and the associated masks for the years 2018-2021 over the contiguous United States. There are 804 512x512 scenes. Its primary purpose is for training geospatial machine learning models.\",\n",
      "    \"keywords\": [\n",
      "      \"English\",\n",
      "      \"cc-by-4.0\",\n",
      "      \"1K - 10K\",\n",
      "      \"Image\",\n",
      "      \"Datasets\",\n",
      "      \"Croissant\",\n",
      "      \"doi:10.57967/hf/0956\",\n",
      "      \"\\ud83c\\uddfa\\ud83c\\uddf8 Region: US\"\n",
      "    ],\n",
      "    \"license\": \"https://choosealicense.com/licenses/cc-by-4.0/\",\n",
      "    \"alternate_names\": [\n",
      "      \"ibm-nasa-geospatial/hls_burn_scars\"\n",
      "    ],\n",
      "    \"creator\": \"IBM-NASA Prithvi Models Family\",\n",
      "    \"dataset_url\": \"https://huggingface.co/datasets/ibm-nasa-geospatial/hls_burn_scars\",\n",
      "    \"datetime\": \"2019-06-30T00:00:00Z\"\n",
      "  },\n",
      "  \"links\": [],\n",
      "  \"assets\": {\n",
      "    \"repo\": {\n",
      "      \"href\": \"https://huggingface.co/datasets/ibm-nasa-geospatial/hls_burn_scars/tree/refs%2Fconvert%2Fparquet\",\n",
      "      \"type\": \"git+https\",\n",
      "      \"title\": \"The Hugging Face git repository.\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pystac import Item, Asset\n",
    "\n",
    "def croissant_to_stac_item(croissant_json):\n",
    "    if isinstance(croissant_json, str):\n",
    "        metadata = json.loads(croissant_json)\n",
    "    else:\n",
    "        metadata = croissant_json\n",
    "\n",
    "    # Metadata fields\n",
    "    item_id = metadata.get(\"identifier\", metadata.get(\"name\", \"unknown-id\"))\n",
    "    title = metadata.get(\"name\", \"\")\n",
    "    description = metadata.get(\"description\", \"\")\n",
    "    license_link = metadata.get(\"license\", \"proprietary\")\n",
    "    keywords = metadata.get(\"keywords\", [])\n",
    "    dataset_url = metadata.get(\"url\", \"\")\n",
    "    alternate_names = metadata.get(\"alternateName\", [])\n",
    "\n",
    "    creator = metadata.get(\"creator\", {})\n",
    "    creator_name = creator.get(\"name\") if isinstance(creator, dict) else None\n",
    "\n",
    "    # Temporal coverage\n",
    "    date_match = re.search(r\"(\\d{4})\\D+(\\d{4})\", description)\n",
    "    if date_match:\n",
    "        start_year, end_year = int(date_match.group(1)), int(date_match.group(2))\n",
    "        start_datetime = datetime(start_year, 1, 1)\n",
    "        end_datetime = datetime(end_year, 12, 31)\n",
    "        midpoint_datetime = datetime((start_year + end_year) // 2, 6, 30)\n",
    "    else:\n",
    "        start_datetime = end_datetime = midpoint_datetime = datetime(2020, 1, 1)\n",
    "\n",
    "\n",
    "    item = Item(\n",
    "        id=item_id,\n",
    "        geometry=None,\n",
    "        bbox=None,\n",
    "        datetime=midpoint_datetime,\n",
    "        properties={\n",
    "            \"start_datetime\": start_datetime.isoformat() + \"Z\",\n",
    "            \"end_datetime\": end_datetime.isoformat() + \"Z\",\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"keywords\": keywords,\n",
    "            \"license\": license_link,\n",
    "            \"alternate_names\": alternate_names,\n",
    "            \"creator\": creator_name,\n",
    "            \"dataset_url\": dataset_url,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for dist in metadata.get(\"distribution\", []):\n",
    "        asset_id = dist.get(\"name\", \"asset\").replace(\" \", \"_\")\n",
    "        href = dist.get(\"contentUrl\")\n",
    "        media_type = dist.get(\"encodingFormat\")\n",
    "        asset_title = dist.get(\"description\", asset_id)\n",
    "\n",
    "        if href:\n",
    "            asset = Asset(\n",
    "                href=href,\n",
    "                media_type=media_type,\n",
    "                title=asset_title\n",
    "            )\n",
    "            item.add_asset(asset_id, asset)\n",
    "\n",
    "\n",
    "    stac_dict = item.to_dict()\n",
    "    print(json.dumps(stac_dict, indent=2))\n",
    "    return item\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"croissant.json\", \"r\") as f:\n",
    "        croissant_data = json.load(f)\n",
    "\n",
    "    croissant_to_stac_item(croissant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3c5a1-1897-4b42-a993-863804e16ec4",
   "metadata": {},
   "source": [
    "# Refined GeoCroissant to STAC Conversion \n",
    "# STAC Item Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "791248a0-83ce-4576-8c3d-c7564b542748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAC item saved to stac_item.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pystac import Item, Asset, MediaType\n",
    "from pystac.extensions.table import TableExtension\n",
    "\n",
    "# License mapping from URL\n",
    "KNOWN_LICENSES = {\n",
    "    \"https://choosealicense.com/licenses/cc-by-4.0/\": \"CC-BY-4.0\",\n",
    "    \"https://opensource.org/licenses/mit\": \"MIT\",\n",
    "    \"https://www.apache.org/licenses/license-2.0\": \"Apache-2.0\",\n",
    "    \"cc-by-4.0\": \"CC-BY-4.0\",\n",
    "}\n",
    "\n",
    "def croissant_to_stac_item(croissant_json, output_path=None):\n",
    "    \"\"\"Convert Croissant metadata to STAC Item.\"\"\"\n",
    "    if isinstance(croissant_json, str):\n",
    "        metadata = json.loads(croissant_json)\n",
    "    else:\n",
    "        metadata = croissant_json\n",
    "\n",
    "    # Extract basic metadata\n",
    "    item_id = metadata.get(\"identifier\", metadata.get(\"name\", \"unknown-id\")).replace(\"/\", \"_\")\n",
    "    title = metadata.get(\"name\", \"\")\n",
    "    description = metadata.get(\"description\", \"\")\n",
    "    license_raw = metadata.get(\"license\", \"proprietary\")\n",
    "    keywords = metadata.get(\"keywords\", [])\n",
    "    dataset_url = metadata.get(\"url\", \"\")\n",
    "    alternate_names = metadata.get(\"alternateName\", [])\n",
    "\n",
    "    # Normalize license\n",
    "    license_key = license_raw.strip().lower()\n",
    "    license_normalized = KNOWN_LICENSES.get(license_key, \n",
    "                                          license_key.upper() if \"cc-by\" in license_key else \"proprietary\")\n",
    "\n",
    "    # Handle creator information\n",
    "    creator = metadata.get(\"creator\", {})\n",
    "    if isinstance(creator, list):\n",
    "        creator = creator[0] if creator else {}\n",
    "    creator_name = creator.get(\"name\", \"Unknown\") if isinstance(creator, dict) else str(creator)\n",
    "    creator_url = creator.get(\"url\", \"\") if isinstance(creator, dict) else \"\"\n",
    "\n",
    "    # Temporal coverage (from description)\n",
    "    start_datetime = datetime(2018, 1, 1)\n",
    "    end_datetime = datetime(2021, 12, 31)\n",
    "    midpoint_datetime = datetime(2019, 6, 30)\n",
    "\n",
    "    # Create STAC Item\n",
    "    item = Item(\n",
    "        id=item_id,\n",
    "        geometry={\n",
    "            \"type\": \"Polygon\",\n",
    "            \"coordinates\": [[\n",
    "                [-125.0, 24.0],  # SW\n",
    "                [-125.0, 50.0],   # NW\n",
    "                [-66.0, 50.0],    # NE\n",
    "                [-66.0, 24.0],    # SE\n",
    "                [-125.0, 24.0]    # SW (close polygon)\n",
    "            ]]\n",
    "        },\n",
    "        bbox=[-125.0, 24.0, -66.0, 50.0],  # CONUS bbox\n",
    "        datetime=midpoint_datetime,\n",
    "        properties={\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"license\": license_normalized,\n",
    "            \"start_datetime\": start_datetime.isoformat() + \"Z\",\n",
    "            \"end_datetime\": end_datetime.isoformat() + \"Z\",\n",
    "            \"keywords\": keywords,\n",
    "            \"msft:region\": \"US\",\n",
    "            \"msft:short_description\": \"HLS burn scars imagery and masks for US (2018-2021)\",\n",
    "            \"providers\": [{\n",
    "                \"name\": creator_name,\n",
    "                \"roles\": [\"producer\"],\n",
    "                \"url\": creator_url\n",
    "            }]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add extensions (only those valid for Items)\n",
    "    item.stac_extensions.extend([\n",
    "        \"https://stac-extensions.github.io/table/v1.2.0/schema.json\",\n",
    "        \"https://schemas.stacspec.org/v1.1.0/item-spec/json-schema/item.json\"\n",
    "    ])\n",
    "\n",
    "    # Add only the actual assets from Croissant distribution\n",
    "    for dist in metadata.get(\"distribution\", []):\n",
    "        href = dist.get(\"contentUrl\")\n",
    "        if not href:\n",
    "            continue\n",
    "            \n",
    "        asset_id = dist.get(\"@id\", dist.get(\"name\", \"asset\")).replace(\" \", \"_\").lower()\n",
    "        media_type = dist.get(\"encodingFormat\", MediaType.JSON)\n",
    "        desc = dist.get(\"description\", asset_id)\n",
    "        \n",
    "        # Determine media type\n",
    "        if \"parquet\" in asset_id or \"parquet\" in media_type:\n",
    "            media_type = MediaType.PARQUET\n",
    "        elif \"git\" in href:\n",
    "            media_type = \"application/git\"\n",
    "\n",
    "        item.add_asset(\n",
    "            asset_id,\n",
    "            Asset(\n",
    "                href=href,\n",
    "                media_type=media_type,\n",
    "                title=desc,\n",
    "                roles=[\"metadata\"] if \"git\" in href else [\"data\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add documentation asset\n",
    "    item.add_asset(\n",
    "        \"documentation\",\n",
    "        Asset(\n",
    "            href=dataset_url,\n",
    "            title=\"Dataset Documentation\",\n",
    "            media_type=MediaType.HTML,\n",
    "            roles=[\"metadata\", \"documentation\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Process record sets to add table schema\n",
    "    for record_set in metadata.get(\"recordSet\", []):\n",
    "        if record_set.get(\"@id\") == \"hls_burn_scars\":\n",
    "            TableExtension.ext(item, add_if_missing=True).columns = [\n",
    "                {\n",
    "                    \"name\": \"image\",\n",
    "                    \"type\": \"binary\",\n",
    "                    \"description\": \"Harmonized Landsat and Sentinel-2 imagery\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"annotation\",\n",
    "                    \"type\": \"binary\",\n",
    "                    \"description\": \"Associated burn scar annotations\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"split\",\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Dataset split (train/validation/test)\"\n",
    "                }\n",
    "            ]\n",
    "\n",
    "    # Output or return result\n",
    "    if output_path:\n",
    "        item.save_object(dest_href=output_path)\n",
    "        print(f\"STAC item saved to {output_path}\")\n",
    "    else:\n",
    "        return item.to_dict()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    with open(\"croissant.json\", \"r\") as f:\n",
    "        croissant_data = json.load(f)\n",
    "\n",
    "    stac_item = croissant_to_stac_item(croissant_data, output_path=\"stac_item.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01735163-e665-40b1-9fee-4960df57c39f",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed8d01c-0c65-4ac0-8155-b235bc8bb845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mThanks for using STAC version 1.1.0!\u001b[0m\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"version\": \"1.1.0\",\n",
      "        \"path\": \"stac_item.json\",\n",
      "        \"schema\": [\n",
      "            \"https://stac-extensions.github.io/table/v1.2.0/schema.json\",\n",
      "            \"https://schemas.stacspec.org/v1.1.0/item-spec/json-schema/item.json\"\n",
      "        ],\n",
      "        \"valid_stac\": true,\n",
      "        \"asset_type\": \"ITEM\",\n",
      "        \"validation_method\": \"default\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!stac-validator stac_item.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
