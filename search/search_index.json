{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u26a1\ufe0f Eclair \u26a1\ufe0f","text":""},{"location":"#helping-ai-agents-access-the-worlds-data","title":"Helping AI Agents access the world's data","text":"<p>Eclair is a set of agentic tools that helps AI assistants (like Gemini and Claude) discover, download, and use datasets to answer questions based on factual data. Such AI models are trained on a lot of data from the internet and other sources, but usually not on the millions of large detailed structured datasets that humanity has gathered. That also means that they can't correctly answer questions about that data, which limits their scientific and analytical potential.</p> <p>With Eclair, AI models can answer those questions by easily finding and accessing millions of datasets available all over the world, analyze this data on the fly to give accurate answers, reason about it and combine it with other data, as well as generate detailed analyses (e.g. notebooks) and custom UIs to explore the data in depth. It's like having your own personal, lightning-fast data scientist.</p> <p></p> <p>Eclair does this by combining three recent technologies:</p> <ul> <li> <p>Model Context Protocol (MCP) - Gives AI models easy access to millions of datasets available online (or your own), and tools to work effectively with that data.</p> </li> <li> <p>Croissant - A metadata standard to help AI models understand what information each dataset contains and how to download and extract that information.</p> </li> <li> <p>AI assistants - That can 'think' about how to answer your questions, find relevant datasets, write code to download and analyze this data, and generate anything from direct textual answers to detailed notebooks, voice summaries, and custom user interfaces.</p> </li> </ul> <p>Most importantly, Eclair aims to create an open, global ecosystem of data sources, agentic tools, and other MCP servers that can be accessed by any AI agent and extended by anyone. You can also run Eclair servers locally, connect it to your own data sources, extend them with more advanced data analysis tools, actively generate data on the fly, or practically anything that you can imagine.</p> <p>Get involved! With Eclair, your AI assistants can discover, analyze, and visualize real data to give you accurate, factual answers. Your contributions help make dataset discovery better for everyone. If you have questions about contributing or improving Eclair, please don't hesitate to ask in GitHub Discussions or open an issue.</p> <p>Fun Fact</p> <p>Like \ud83e\udd50 Croissant, \u00c9clair was born in Paris. It's both a delicious pastry and the French word for \u26a1\ufe0f lightning \u26a1\ufe0f.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get started with Eclair in just a few steps:</p> <p>1. Install Eclair <pre><code>pip install eclair\n</code></pre></p> <p>TODO</p> <p>We'll publish on pypi as soon as the code is hosted on Github. For now, you'll need to install the developer version (see the installation guide).</p> <p>2. Start the Server <pre><code>eclair-server\n</code></pre></p> <p></p> <p>Hosted Eclair</p> <p>We plan to set up a hosted Eclair server soon. For now, you can run it locally.</p> <p>3. Use your favorite AI Agent</p> <p>\ud83e\udd16 You can use Eclair with any model that supports MCP. For instance:</p> <ul> <li>Gemini CLI</li> <li>Claude Code</li> <li>VS Code + Copilot</li> <li>VS Code + Gemini Code Assist</li> </ul> <p>\ud83d\udc69\u200d\ud83d\udcbb You can also use Eclair directly in your code, notebooks, and scripts:</p> <ul> <li>Python API</li> <li>Command-Line Interface </li> </ul>"},{"location":"#available-tools","title":"Available Tools","text":"<p>Eclair currently provides 7 essential tools for dataset discovery and analysis:</p> Tool Description search-datasets Search for datasets using a query string download-dataset Download a dataset with metadata datasets-preview-url Get a download URL for a dataset preview serve-croissant Get the Croissant metadata for a given dataset validate-croissant Validate a Croissant metadata file help Get instructions to use the Eclair tools ping Test that your Eclair server is working <p>Watch this space</p> <p>We plan to extent these tools and add new ones, soon. E.g. a handy 'Dataset card' visualization? Let us know what you would like to see, or feel free to build it yourself.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Built on Croissant: A widely accepted machine-readable metadata format for datasets</li> <li>FastMCP Implementation: Built using the latest FastMCP library and MCP SDK</li> <li>Seamless Integration: Works with developer environments (e.g. VSCode), code assistants (e.g. Copilot and Gemini Code Assist) and command-line or desktop AI agents</li> <li>Portable: Easy to set up your own server and interact via Python code or command-line commands</li> <li>Flexible Design: Can relay to other MCP servers (e.g. Jetty) and run anywhere as a stateless server</li> </ul>"},{"location":"#whats-next","title":"What's Next?","text":"<ul> <li>New to Eclair? Start with the Installation Guide</li> <li>Start using Eclair Check out the Usage Guides</li> <li>Building on Eclair? See the API Documentation</li> <li>Contributing? Read the Development Guide</li> </ul>"},{"location":"#contributors","title":"Contributors","text":"<p>Eclair is developed and maintained by:</p> <ul> <li>Joaquin Vanschoren - OpenML, TU Eindhoven, Google Deepmind (Visiting Faculty)</li> <li>Omar Benjelloun - Google Deepmind </li> <li>Jon Lebenshold - Jetty.io</li> <li>Natasha Noy - Google</li> </ul>"},{"location":"api/python-client/","title":"Python Client SDK","text":"<p>The Eclair Python client provides multiple interfaces to interact with the Eclair dataset server, including base MCP clients and AI-powered assistant clients.</p>"},{"location":"api/python-client/#installation","title":"Installation","text":"<pre><code>pip install eclair\n</code></pre> <p>For AI assistant functionality: <pre><code># For Gemini integration\npip install google-generativeai\n\n# For Claude integration (coming soon)\npip install anthropic\n</code></pre></p>"},{"location":"api/python-client/#client-types","title":"Client Types","text":"<p>Eclair provides three client types:</p> <ol> <li>EclairClient - Base MCP client for direct API access</li> <li>GeminiMCPClient - AI-powered assistant using Gemini</li> <li>ClaudeMCPClient - AI-powered assistant using Claude</li> </ol>"},{"location":"api/python-client/#base-mcp-client-eclairclient","title":"Base MCP Client (EclairClient)","text":"<p>The base client provides direct access to all MCP tools.</p>"},{"location":"api/python-client/#quick-start","title":"Quick Start","text":"<pre><code>from eclair.client import EclairClient\nimport asyncio\n\nasync def main():\n    # Initialize client\n    client = EclairClient(\"http://localhost:8080/mcp\")\n\n    # Test connectivity\n    ping_result = await client.ping()\n    print(ping_result.data.result)  # \"Pong! Eclair MCP Server is running successfully.\"\n\n    # Search for datasets\n    results = await client.search_datasets(\"fashion mnist\")\n    print(f\"Search completed\")\n\n    # Get help\n    help_info = await client.get_help()\n    print(\"Help information retrieved\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"api/python-client/#api-reference-eclairclient","title":"API Reference - EclairClient","text":""},{"location":"api/python-client/#constructor","title":"Constructor","text":"<pre><code>EclairClient(server_url: str = \"http://localhost:8080/mcp\")\n</code></pre>"},{"location":"api/python-client/#methods","title":"Methods","text":"<p>All methods return <code>CallToolResult</code> objects with structured data.</p>"},{"location":"api/python-client/#ping","title":"ping()","text":"<p>Test server connectivity. <pre><code>result = await client.ping()\nprint(result.data.result)  # Server status message\n</code></pre></p>"},{"location":"api/python-client/#search_datasetsquery-str","title":"search_datasets(query: str)","text":"<p>Search for datasets. <pre><code>result = await client.search_datasets(\"fashion mnist\")\ndatasets = result.structured_content['result']  # List of datasets\n</code></pre></p>"},{"location":"api/python-client/#download_datasetcollection-str-dataset-str","title":"download_dataset(collection: str, dataset: str)","text":"<p>Get download information for a dataset. <pre><code>result = await client.download_dataset(\"Han-Xiao\", \"Fashion-MNIST\")\ndownload_info = result.structured_content['result']\n</code></pre></p>"},{"location":"api/python-client/#datasets_preview_urlcollection-str-dataset-str","title":"datasets_preview_url(collection: str, dataset: str)","text":"<p>Get preview download URL. <pre><code>result = await client.datasets_preview_url(\"Han-Xiao\", \"Fashion-MNIST\")\nurl = result.structured_content['result']['url']\n</code></pre></p>"},{"location":"api/python-client/#serve_croissantcollection-str-dataset-str","title":"serve_croissant(collection: str, dataset: str)","text":"<p>Get Croissant metadata. <pre><code>result = await client.serve_croissant(\"Han-Xiao\", \"Fashion-MNIST\")\nmetadata = result.structured_content['result']\n</code></pre></p>"},{"location":"api/python-client/#validate_croissantmetadata_json-dict","title":"validate_croissant(metadata_json: dict)","text":"<p>Validate Croissant metadata. <pre><code>result = await client.validate_croissant(metadata_dict)\nvalidation = result.structured_content['result']\n</code></pre></p>"},{"location":"api/python-client/#get_help","title":"get_help()","text":"<p>Get help information. <pre><code>result = await client.get_help()\nhelp_text = result.data.result\n</code></pre></p>"},{"location":"api/python-client/#gemini-ai-assistant-client","title":"Gemini AI Assistant Client","text":"<p>The <code>GeminiMCPClient</code> combines MCP tools with Gemini AI for intelligent dataset discovery and analysis.</p>"},{"location":"api/python-client/#setup","title":"Setup","text":"<pre><code># Set your Gemini API key\nexport GEMINI_API_KEY=\"your-api-key-here\"\n</code></pre> <p>Or create a <code>.env</code> file: <pre><code>GEMINI_API_KEY=your-api-key-here\n</code></pre></p>"},{"location":"api/python-client/#quick-start_1","title":"Quick Start","text":"<pre><code>from eclair.client.gemini import GeminiMCPClient\nimport asyncio\n\nasync def main():\n    # Initialize with AI capabilities\n    client = GeminiMCPClient()\n    await client.initialize()\n\n    # Ask AI assistant to find and analyze datasets\n    response = await client.ask_gemini_with_tools(\n        \"Find fashion-related datasets and recommend the best one for image classification\"\n    )\n    print(response)\n\n    await client.close()\n\nasyncio.run(main())\n</code></pre>"},{"location":"api/python-client/#api-reference-geminimcpclient","title":"API Reference - GeminiMCPClient","text":""},{"location":"api/python-client/#constructor_1","title":"Constructor","text":"<pre><code>GeminiMCPClient(\n    mcp_server_url: str = \"http://localhost:8080/mcp\",\n    gemini_api_key: Optional[str] = None\n)\n</code></pre>"},{"location":"api/python-client/#ai-methods","title":"AI Methods","text":""},{"location":"api/python-client/#ask_gemini_with_toolsprompt-str-temperature-optionalfloat-none","title":"ask_gemini_with_tools(prompt: str, temperature: Optional[float] = None)","text":"<p>Use Gemini AI with MCP tools for intelligent responses. <pre><code>response = await client.ask_gemini_with_tools(\n    \"Compare MNIST variants and suggest the best for my computer vision project\",\n    temperature=0.3\n)\n</code></pre></p>"},{"location":"api/python-client/#direct-mcp-methods","title":"Direct MCP Methods","text":"<p>All base MCP methods are also available: <pre><code># Direct tool access\ndatasets = await client.search_datasets(\"mnist\")\nmetadata = await client.serve_croissant(\"Han-Xiao\", \"Fashion-MNIST\")\nping = await client.ping()\n</code></pre></p>"},{"location":"api/python-client/#configuration","title":"Configuration","text":"<p>The client loads configuration from <code>config.json</code>:</p> <pre><code>{\n  \"gemini\": {\n    \"model\": \"gemini-2.0-flash-exp\",\n    \"temperature\": 0.3\n  }\n}\n</code></pre>"},{"location":"api/python-client/#claude-ai-assistant-client","title":"Claude AI Assistant Client","text":"<p>Similar to Gemini but using Claude AI (implementation in progress).</p>"},{"location":"api/python-client/#setup_1","title":"Setup","text":"<pre><code># Set your Claude API key\nexport CLAUDE_API_KEY=\"your-api-key-here\"\n</code></pre>"},{"location":"api/python-client/#usage","title":"Usage","text":"<pre><code>from eclair.client.claude import ClaudeMCPClient\nimport asyncio\n\nasync def main():\n    try:\n        client = ClaudeMCPClient()\n        await client.initialize()\n\n        # Direct MCP access works\n        result = await client.search_datasets(\"image classification\")\n        print(\"Search completed\")\n\n        # AI features coming soon\n        # response = await client.ask_claude_with_tools(\"Find datasets...\")\n\n        await client.close()\n    except ImportError as e:\n        print(f\"Claude client requires: pip install anthropic\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"api/python-client/#complete-examples","title":"Complete Examples","text":""},{"location":"api/python-client/#1-basic-dataset-discovery","title":"1. Basic Dataset Discovery","text":"<pre><code>from eclair.client import EclairClient\nimport asyncio\nimport json\n\nasync def basic_discovery():\n    client = EclairClient()\n\n    # Search for datasets\n    result = await client.search_datasets(\"fashion mnist\")\n    datasets = result.structured_content['result']\n\n    print(f\"Found {len(datasets)} datasets\")\n    for dataset in datasets:\n        doc = dataset['document']\n        print(f\"- {doc['entity_name']} ({doc['collection_name']})\")\n\nasyncio.run(basic_discovery())\n</code></pre>"},{"location":"api/python-client/#2-ai-powered-dataset-analysis","title":"2. AI-Powered Dataset Analysis","text":"<pre><code>from eclair.client.gemini import GeminiMCPClient\nimport asyncio\n\nasync def ai_analysis():\n    client = GeminiMCPClient()\n    await client.initialize()\n\n    # Let AI find and analyze datasets\n    response = await client.ask_gemini_with_tools(\"\"\"\n    I need datasets for a computer vision project about clothing classification.\n    Find relevant datasets and analyze their characteristics.\n    Recommend the best option with reasoning.\n    \"\"\")\n\n    print(response)\n    await client.close()\n\nasyncio.run(ai_analysis())\n</code></pre>"},{"location":"api/python-client/#3-dataset-preview-and-download","title":"3. Dataset Preview and Download","text":"<pre><code>from eclair.client import EclairClient\nimport asyncio\nimport pandas as pd\nimport requests\nimport io\n\nasync def preview_and_download():\n    client = EclairClient()\n\n    # Get preview URL\n    result = await client.datasets_preview_url(\"Han-Xiao\", \"Fashion-MNIST\")\n    preview_url = result.structured_content['result']['url']\n\n    # Download and view preview\n    response = requests.get(preview_url)\n    if response.status_code == 200:\n        df = pd.read_parquet(io.BytesIO(response.content))\n        print(\"Dataset preview:\")\n        print(df.head())\n        print(f\"\nDataset shape: {df.shape}\")\n\n    # Get download information\n    download_result = await client.download_dataset(\"Han-Xiao\", \"Fashion-MNIST\")\n    print(\"\nDownload information:\")\n    print(download_result.structured_content['result'])\n\nasyncio.run(preview_and_download())\n</code></pre>"},{"location":"api/python-client/#4-metadata-validation","title":"4. Metadata Validation","text":"<pre><code>from eclair.client import EclairClient\nimport asyncio\nimport json\n\nasync def validate_metadata():\n    client = EclairClient()\n\n    # Get Croissant metadata\n    result = await client.serve_croissant(\"Han-Xiao\", \"Fashion-MNIST\")\n    metadata = result.structured_content['result']\n\n    # Validate the metadata\n    validation_result = await client.validate_croissant(metadata)\n    validation = validation_result.structured_content['result']\n\n    print(\"Metadata validation:\")\n    print(json.dumps(validation, indent=2))\n\nasyncio.run(validate_metadata())\n</code></pre>"},{"location":"api/python-client/#error-handling","title":"Error Handling","text":"<pre><code>from eclair.client import EclairClient\nimport asyncio\n\nasync def with_error_handling():\n    client = EclairClient()\n\n    try:\n        result = await client.search_datasets(\"test query\")\n        if result.is_error:\n            print(f\"Tool error: {result.content[0].text}\")\n        else:\n            print(\"Search successful\")\n    except Exception as e:\n        print(f\"Connection error: {e}\")\n\nasyncio.run(with_error_handling())\n</code></pre>"},{"location":"api/tools/","title":"API Reference","text":"<p>Eclair provides several APIs and tools for dataset discovery and management. This reference covers all available interfaces including MCP tools, REST API, and Python SDK.</p>"},{"location":"api/tools/#model-context-protocol-mcp-tools","title":"Model Context Protocol (MCP) Tools","text":"<p>Eclair implements the Model Context Protocol, providing standardized tools for AI agents to discover and work with datasets.</p>"},{"location":"api/tools/#available-tools","title":"Available Tools","text":"Tool Name Description Parameters <code>search-datasets</code> Search for datasets using natural language <code>query</code> (required) <code>download-dataset</code> Download a dataset to local storage <code>collection</code>, <code>dataset</code> (both required) <code>datasets-preview-url</code> Get preview URL for dataset samples <code>collection</code>, <code>dataset</code> (both required) <code>serve-croissant</code> Get Croissant metadata for a dataset <code>collection</code>, <code>dataset</code> (both required) <code>validate-croissant</code> Validate Croissant metadata <code>metadata_json</code> (required) <code>help</code> Get help information No parameters <code>ping</code> Test server connectivity No parameters"},{"location":"api/tools/#tool-schemas","title":"Tool Schemas","text":""},{"location":"api/tools/#search-datasets","title":"search-datasets","text":"<p>Search for datasets using natural language queries.</p> <pre><code>{\n  \"name\": \"search-datasets\",\n  \"description\": \"Search for datasets using a query string\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"query\": {\n        \"type\": \"string\",\n        \"title\": \"Query\",\n        \"description\": \"Search query for finding datasets\"\n      }\n    },\n    \"required\": [\"query\"]\n  }\n}\n</code></pre> <p>Example Usage: <pre><code>{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"search-datasets\", \n    \"arguments\": {\n      \"query\": \"Fashion-MNIST\"\n    }\n  }\n}\n</code></pre></p> <p>Response (Sample): <pre><code>{\n  \"result\": [\n    {\n      \"document\": {\n        \"collection_name\": \"Han-Xiao\",\n        \"entity_name\": \"Fashion-MNIST\", \n        \"entity_type\": \"dataset\",\n        \"full_name\": \"dataset/Han-Xiao/Fashion-MNIST\",\n        \"metadata\": {\n          \"__type\": \"sc:Dataset\",\n          \"conformsTo\": \"http://mlcommons.org/croissant/1.0\",\n          \"name\": \"Fashion-MNIST\",\n          \"description\": \"Fashion-MNIST is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples...\",\n          \"url\": \"https://www.openml.org/search?type=data&amp;id=40996\",\n          \"license\": \"Public\"\n        }\n      },\n      \"highlight\": {\n        \"metadata\": {\n          \"description\": {\n            \"matched_tokens\": [\"Fashion-MNIST\"], \n            \"snippet\": \"&lt;mark&gt;Fashion-MNIST&lt;/mark&gt; is a dataset of Zalando's article images\"\n          }\n        }\n      },\n      \"text_match\": 1157451471441100800,\n      \"text_match_info\": {\n        \"best_field_score\": \"2211897868288\",\n        \"best_field_weight\": 15,\n        \"fields_matched\": 2,\n        \"score\": \"1157451471441100922\",\n        \"tokens_matched\": 1\n      }\n    }\n  ]\n}\n</code></pre></p>"},{"location":"api/tools/#download-dataset","title":"download-dataset","text":"<p>Download a dataset to local storage.</p> <pre><code>{\n  \"name\": \"download-dataset\",\n  \"description\": \"Download a dataset\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"collection\": {\n        \"type\": \"string\",\n        \"title\": \"Collection\",\n        \"description\": \"Dataset collection name\"\n      },\n      \"dataset\": {\n        \"type\": \"string\", \n        \"title\": \"Dataset\",\n        \"description\": \"Dataset identifier\"\n      }\n    },\n    \"required\": [\"collection\", \"dataset\"]\n  }\n}\n</code></pre> <p>Example Usage: <pre><code>{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"download-dataset\",\n    \"arguments\": {\n      \"collection\": \"Han-Xiao\",\n      \"dataset\": \"Fashion-MNIST\"\n    }\n  }\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"result\": {\n    \"metadata\": {\n      \"url\": \"https://www.openml.org/search?type=data&amp;id=40996\",\n      \"name\": \"Fashion-MNIST\",\n      \"@type\": \"sc:Dataset\",\n      \"sameAs\": \"https://github.com/zalandoresearch/fashion-mnist\",\n      \"creator\": {\n        \"url\": \"https://huggingface.co/Han-Xiao\",\n        \"name\": \"Han-Xiao\",\n        \"@type\": \"sc:Organization\"\n      },\n      \"license\": \"Public\",\n      \"conformsTo\": \"http://mlcommons.org/croissant/1.0\",\n      \"description\": \"Fashion-MNIST is a dataset of Zalando's article images...\"\n    },\n    \"asset_origin\": \"openml\",\n    \"data_path\": \"Han-Xiao/Fashion-MNIST\",\n    \"instructions\": \"# Install if necessary\\n# !pip install datasets pandas\\n\\nfrom datasets import load_dataset\\nimport pandas as pd\\n\\n# 1. Load Fashion-MNIST dataset from OpenML\\ndataset = load_dataset(\\\"Han-Xiao/Fashion-MNIST\\\")\\n\\n# The dataset has different splits (train, test)\\nprint(dataset)\\n\\n# 2. Take a look at a few examples\\nprint(\\\"\\\\nFirst few training examples:\\\")\\nprint(dataset[\\\"train\\\"].select(range(5)))\\n\\n# 3. Convert to a pandas DataFrame for easier exploration\\ndf_train = pd.DataFrame(dataset[\\\"train\\\"])\\n\\nprint(\\\"\\\\nPandas DataFrame Head:\\\")\\nprint(df_train.head())\\n\\n# 4. Simple exploration\\nprint(\\\"\\\\nBasic info:\\\")\\nprint(df_train.info())\"\n  }\n}\n</code></pre></p>"},{"location":"api/tools/#datasets-preview-url","title":"datasets-preview-url","text":"<p>Get a URL for previewing dataset samples.</p> <pre><code>{\n  \"name\": \"datasets-preview-url\",\n  \"description\": \"Get a download url for a dataset preview\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"collection\": {\n        \"type\": \"string\",\n        \"title\": \"Collection\"\n      },\n      \"dataset\": {\n        \"type\": \"string\",\n        \"title\": \"Dataset\" \n      }\n    },\n    \"required\": [\"collection\", \"dataset\"]\n  }\n}\n</code></pre> <p>Example Usage: <pre><code>{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"datasets-preview-url\",\n    \"arguments\": {\n      \"collection\": \"Han-Xiao\",\n      \"dataset\": \"Fashion-MNIST\"\n    }\n  }\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"result\": \"https://dock.jetty.io/api/v1/datasets/Han-Xiao/Fashion-MNIST/preview\"\n}\n</code></pre></p>"},{"location":"api/tools/#serve-croissant","title":"serve-croissant","text":"<p>Get Croissant metadata for a dataset.</p> <pre><code>{\n  \"name\": \"serve-croissant\",\n  \"description\": \"Get the Croissant dataset metadata\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"collection\": {\n        \"type\": \"string\",\n        \"title\": \"Collection\"\n      },\n      \"dataset\": {\n        \"type\": \"string\",\n        \"title\": \"Dataset\"\n      }\n    },\n    \"required\": [\"collection\", \"dataset\"]  \n  }\n}\n</code></pre> <p>Example Usage: <pre><code>{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"serve-croissant\",\n    \"arguments\": {\n      \"collection\": \"Han-Xiao\",\n      \"dataset\": \"Fashion-MNIST\"\n    }\n  }\n}\n</code></pre></p> <p>Response (Sample): <pre><code>{\n  \"result\": {\n    \"url\": \"https://www.openml.org/search?type=data&amp;id=40996\",\n    \"name\": \"Fashion-MNIST\",\n    \"@type\": \"sc:Dataset\",\n    \"sameAs\": \"https://github.com/zalandoresearch/fashion-mnist\",\n    \"creator\": {\n      \"url\": \"https://huggingface.co/Han-Xiao\",\n      \"name\": \"Han-Xiao\",\n      \"@type\": \"sc:Organization\"\n    },\n    \"license\": \"Public\",\n    \"@context\": {\n      \"cr\": \"http://mlcommons.org/croissant/\",\n      \"sc\": \"https://schema.org/\",\n      \"@vocab\": \"https://schema.org/\"\n    },\n    \"keywords\": [\n      \"image-classification\",\n      \"multi-class-image-classification\",\n      \"expert-generated\",\n      \"English\",\n      \"Public\",\n      \"10K - 100K\",\n      \"Fashion-MNIST\"\n    ],\n    \"conformsTo\": \"http://mlcommons.org/croissant/1.0\",\n    \"description\": \"Fashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of 60,000 examples and a test set of 10,000 examples...\",\n    \"recordSet\": [\n      {\n        \"@id\": \"fashion_mnist\",\n        \"name\": \"Fashion-MNIST\",\n        \"@type\": \"cr:RecordSet\",\n        \"field\": [\n          {\n            \"@id\": \"fashion_mnist/image\",\n            \"name\": \"fashion_mnist/image\",\n            \"@type\": \"cr:Field\",\n            \"dataType\": \"sc:ImageObject\",\n            \"description\": \"28x28 grayscale image of fashion item.\"\n          },\n          {\n            \"@id\": \"fashion_mnist/label\",\n            \"name\": \"fashion_mnist/label\", \n            \"@type\": \"cr:Field\",\n            \"dataType\": \"sc:Integer\",\n            \"description\": \"Fashion item class label (0-9).\\nLabels:\\n0: T-shirt/top, 1: Trouser, 2: Pullover, 3: Dress, 4: Coat, 5: Sandal, 6: Shirt, 7: Sneaker, 8: Bag, 9: Ankle boot\"\n          }\n        ]\n      }\n    ],\n    \"distribution\": [\n      {\n        \"@id\": \"openml_repo\",\n        \"name\": \"openml_repo\",\n        \"@type\": \"cr:FileObject\",\n        \"contentUrl\": \"https://www.openml.org/search?type=data&amp;id=40996\",\n        \"encodingFormat\": \"openml+arff\"\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"api/tools/#validate-croissant","title":"validate-croissant","text":"<p>Validate Croissant metadata for compliance.</p> <pre><code>{\n  \"name\": \"validate-croissant\", \n  \"description\": \"Validate a Croissant metadata file\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"metadata_json\": {\n        \"type\": \"object\",\n        \"title\": \"Metadata Json\",\n        \"additionalProperties\": true\n      }\n    },\n    \"required\": [\"metadata_json\"]\n  }\n}\n</code></pre> <p>Example Usage: <pre><code>{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"validate-croissant\",\n    \"arguments\": {\n      \"metadata_json\": {\n        \"conformsTo\": \"http://mlcommons.org/croissant/1.0\",\n        \"contributor\": {\n          \"name\": [\"Jock A. Blackard\", \"Dr. Denis J. Dean\", \"Dr. Charles W. Anderson\"]\n        },\n        \"dateCreated\": \"2014-04-23T13:14:37\",\n        \"description\": \"**Covertype**\\nPredicting forest cover type from cartographic variables only (no remotely sensed data)...\",\n        \"distribution\": [\n          {\n            \"contentUrl\": \"https://data.openml.org/datasets/0000/0180/dataset_180.pq\",\n            \"description\": \"Data file belonging to the dataset.\",\n            \"encodingFormat\": \"application/x-parquet\",\n            \"md5\": \"c741394174287c04331718c76be0336e\",\n            \"name\": \"data-file\"\n          }\n        ],\n        \"inLanguage\": \"en\",\n        \"isAccessibleForFree\": true,\n        \"keywords\": [\"Data Science\", \"Ecology\", \"Machine Learning\", \"study_10\", \"uci\"],\n        \"license\": \"Public\",\n        \"name\": \"covertype\",\n        \"recordSet\": [\n          {\n            \"data\": [\n              {\"enumerations/class/value\": \"Aspen\"},\n              {\"enumerations/class/value\": \"Cottonwood_Willow\"},\n              {\"enumerations/class/value\": \"Douglas_fir\"},\n              {\"enumerations/class/value\": \"Krummholz\"},\n              {\"enumerations/class/value\": \"Lodgepole_Pine\"},\n              {\"enumerations/class/value\": \"Ponderosa_Pine\"},\n              {\"enumerations/class/value\": \"Spruce_Fir\"}\n            ],\n            \"dataType\": \"sc:Enumeration\",\n            \"description\": \"Possible values for class\",\n            \"field\": [\n              {\n                \"dataType\": \"sc:Text\",\n                \"description\": \"The value of class.\",\n                \"name\": \"value\"\n              }\n            ],\n            \"name\": \"class\"\n          }\n        ],\n        \"url\": \"https://www.openml.org/d/180\",\n        \"version\": 1\n      }\n    }\n  }\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"result\": {\n    \"valid\": true,\n    \"results\": [\n      {\n        \"test\": \"JSON Format Validation\",\n        \"passed\": true,\n        \"message\": \"The string is valid JSON.\",\n        \"status\": \"pass\"\n      },\n      {\n        \"test\": \"Croissant Schema Validation\",\n        \"passed\": true,\n        \"message\": \"The dataset passes Croissant validation.\",\n        \"status\": \"pass\"\n      },\n      {\n        \"test\": \"Records Generation Test\",\n        \"passed\": true,\n        \"message\": \"Record set 'enumerations/class' passed validation.\",\n        \"status\": \"pass\"\n      }\n    ]\n  }\n}\n</code></pre></p> <p>Note: The validation tool now successfully validates proper Croissant 1.0 metadata. This example uses the OpenML Covertype dataset with complete metadata structure including distribution, recordSet, and field definitions.</p>"},{"location":"api/tools/#validation-with-incomplete-metadata","title":"Validation with Incomplete Metadata","text":"<p>Some datasets may have schema-compliant but functionally incomplete metadata:</p> <pre><code>{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"validate-croissant\",\n    \"arguments\": {\n      \"metadata_json\": {\n        \"conformsTo\": \"http://mlcommons.org/croissant/1.0\",\n        \"name\": \"Fashion-MNIST\",\n        \"description\": \"Fashion-MNIST dataset...\",\n        \"recordSet\": [\n          {\n            \"name\": \"data-file-description\",\n            \"description\": \"The fields are omitted, because this dataset has too many.\"\n          }\n        ],\n        \"distribution\": [\n          {\n            \"contentUrl\": \"https://data.openml.org/datasets/0004/40996/dataset_40996.pq\",\n            \"encodingFormat\": \"application/x-parquet\",\n            \"name\": \"data-file\"\n          }\n        ]\n      }\n    }\n  }\n}\n</code></pre> <p>Response: <pre><code>{\n  \"result\": {\n    \"valid\": false,\n    \"results\": [\n      {\n        \"test\": \"JSON Format Validation\",\n        \"passed\": true,\n        \"message\": \"The string is valid JSON.\",\n        \"status\": \"pass\"\n      },\n      {\n        \"test\": \"Croissant Schema Validation\", \n        \"passed\": true,\n        \"message\": \"The dataset passes Croissant validation.\",\n        \"status\": \"pass\"\n      },\n      {\n        \"test\": \"Records Generation Test\",\n        \"passed\": false,\n        \"message\": \"Record set failed due to generation error: TypeError: object of type 'NoneType' has no len()\",\n        \"status\": \"warning\"\n      }\n    ]\n  }\n}\n</code></pre></p> <p>This shows that metadata can be schema-compliant but generation-incomplete due to missing field definitions.</p>"},{"location":"api/tools/#help","title":"help","text":"<p>Get comprehensive help information.</p> <pre><code>{\n  \"name\": \"help\",\n  \"description\": \"Get help for the Eclair Dataset MCP server\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {}\n  }\n}\n</code></pre> <p>Example Usage: <pre><code>{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"help\",\n    \"arguments\": {}\n  }\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"result\": \"# Eclair Dataset MCP Server\\n\\nEclair provides access to a curated collection of datasets for machine learning and data science.\\n\\n## Available Tools\\n\\n### search-datasets\\nSearch for datasets using natural language queries.\\n\\nParameters:\\n- query (string, required): Search query to find relevant datasets\\n\\nExample:\\n```\\nmcp_client.call(\\\"search-datasets\\\", {\\\"query\\\": \\\"computer vision\\\"})\\n```\\n\\n### datasets-preview-url\\nGet a preview URL for a specific dataset.\\n\\nParameters:\\n- collection (string, required): Collection name (e.g., \\\"Han-Xiao\\\")\\n- dataset (string, required): Dataset name (e.g., \\\"Fashion-MNIST\\\")\\n\\nExample:\\n```\\nmcp_client.call(\\\"datasets-preview-url\\\", {\\\"collection\\\": \\\"Han-Xiao\\\", \\\"dataset\\\": \\\"Fashion-MNIST\\\"})\\n```\\n\\n### serve-croissant\\nRetrieve Croissant metadata for a dataset.\\n\\nParameters:\\n- collection (string, required): Collection name\\n- dataset (string, required): Dataset name\\n\\nExample:\\n```\\nmcp_client.call(\\\"serve-croissant\\\", {\\\"collection\\\": \\\"Han-Xiao\\\", \\\"dataset\\\": \\\"Fashion-MNIST\\\"})\\n```\\n\\n### validate-croissant\\nValidate Croissant metadata for compliance.\\n\\nParameters:\\n- metadata_json (object, required): Croissant metadata to validate\\n\\nExample:\\n```\\nmcp_client.call(\\\"validate-croissant\\\", {\\\"metadata_json\\\": croissant_metadata})\\n```\\n\\n### download-dataset\\nDownload a dataset with metadata and usage instructions.\\n\\nParameters:\\n- collection (string, required): Collection name\\n- dataset (string, required): Dataset name\\n\\nExample:\\n```\\nmcp_client.call(\\\"download-dataset\\\", {\\\"collection\\\": \\\"Han-Xiao\\\", \\\"dataset\\\": \\\"Fashion-MNIST\\\"})\\n```\\n\\n### ping\\nTest server connectivity.\\n\\nParameters: None\\n\\nExample:\\n```\\nmcp_client.call(\\\"ping\\\", {})\\n```\\n\\n## Getting Started\\n\\n1. Search for datasets: `search-datasets`\\n2. Preview dataset: `datasets-preview-url`  \\n3. Get metadata: `serve-croissant`\\n4. Download dataset: `download-dataset`\\n\\n## Support\\n\\nFor more information, visit: https://github.com/jvanscho/eclair\"\n}\n</code></pre></p>"},{"location":"api/tools/#ping","title":"ping","text":"<p>Test server connectivity and health.</p> <pre><code>{\n  \"name\": \"ping\",\n  \"description\": \"Test that the Eclair server is working\", \n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {}\n  }\n}\n</code></pre> <p>Example Usage: <pre><code>{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"ping\",\n    \"arguments\": {}\n  }\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Pong! Eclair MCP Server is running successfully.\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"development/","title":"Development","text":"<p>This section covers everything you need to know to contribute to Eclair, set up a development environment, and extend the platform with new features.</p>"},{"location":"development/#quick-start-for-contributors","title":"Quick Start for Contributors","text":""},{"location":"development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>Git</li> <li>Virtual environment tool (venv, conda, etc.)</li> </ul>"},{"location":"development/#setup-development-environment","title":"Setup Development Environment","text":"<ol> <li> <p>Clone the Repository <pre><code>git clone https://github.com/mlcommons/croissant.git\ncd croissant/eclair\n</code></pre></p> </li> <li> <p>Create Virtual Environment <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install Development Dependencies <pre><code>pip install -r requirements.txt\npip install -r requirements-dev.txt\npip install -e .\n</code></pre></p> </li> <li> <p>Run Tests (Optional) Running the tests will also startup an Eclair server. Hence you don't need to start it beforehand.    <pre><code>pytest\n</code></pre></p> </li> <li> <p>Start Eclair Server <pre><code>eclair-server\n</code></pre></p> </li> </ol>"},{"location":"development/#project-structure","title":"Project Structure","text":"<pre><code>eclair/\n\u251c\u2500\u2500 src/eclair/                 # Main package\n\u2502   \u251c\u2500\u2500 client/                # Client libraries\n\u2502   \u2502   \u251c\u2500\u2500 cli.py            # Command line interface\n\u2502   \u2502   \u251c\u2500\u2500 client.py         # Python client\n\u2502   \u2502   \u2514\u2500\u2500 gemini/           # Gemini integration\n\u2502   \u2514\u2500\u2500 server/               # Server implementation\n\u2502       \u251c\u2500\u2500 server.py         # Main server\n\u2502       \u251c\u2500\u2500 tools.py          # MCP tools\n\u2502       \u2514\u2500\u2500 validation.py     # Data validation\n\u251c\u2500\u2500 tests/                    # Test suite\n\u251c\u2500\u2500 docs/                     # Documentation\n\u251c\u2500\u2500 config.json               # Configuration\n\u251c\u2500\u2500 mkdocs.yml                # Documentation building\n\u251c\u2500\u2500 requirements.txt          # Production dependencies\n\u251c\u2500\u2500 requirements-dev.txt      # Development dependencies\n\u2514\u2500\u2500 pyproject.toml            # Package configuration\n</code></pre>"},{"location":"development/#testing","title":"Testing","text":"<p>We use pytest with comprehensive test coverage:</p> <pre><code># tests/test_client.py\nimport pytest\nfrom eclair.client import EclairClient\n\n@pytest.fixture\ndef client():\n    return EclairClient(\"http://localhost:8080\")\n\ndef test_search_datasets(client):\n    \"\"\"Test dataset search functionality.\"\"\"\n    results = client.search_datasets(\"test query\")\n    assert isinstance(results, list)\n\ndef test_download_dataset(client):\n    \"\"\"Test dataset download.\"\"\"\n    path = client.download_dataset(\"test_collection\", \"test_dataset\")\n    assert isinstance(path, str)\n    assert path.endswith(\"test_dataset\")\n</code></pre> <p>Run tests with coverage:</p> <pre><code># Run all tests\npytest\n\n# With coverage report\npytest --cov=src/eclair --cov-report=html\n\n# Run specific test file\npytest tests/test_client.py\n\n# Run with verbose output\npytest -v\n</code></pre>"},{"location":"development/#documentation","title":"Documentation","text":"<p>Documentation is built with MkDocs and Material theme:</p> <pre><code># Install docs dependencies\npip install mkdocs mkdocs-material\n\n# Serve docs locally\nmkdocs serve\n\n# Build docs\nmkdocs build\n\n# Deploy to GitHub Pages\nmkdocs gh-deploy\n</code></pre>"},{"location":"development/#adding-new-features","title":"Adding New Features","text":""},{"location":"development/#adding-a-new-mcp-tool","title":"Adding a New MCP Tool","text":"<ol> <li> <p>Define Tool Schema <pre><code># src/eclair/server/tools.py\ndef get_tool_schema(self, tool_name: str) -&gt; Dict[str, Any]:\n    schemas = {\n        \"my-new-tool\": {\n            \"name\": \"my-new-tool\",\n            \"description\": \"Description of what this tool does\",\n            \"inputSchema\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"param1\": {\n                        \"type\": \"string\",\n                        \"description\": \"Description of parameter\"\n                    }\n                },\n                \"required\": [\"param1\"]\n            }\n        }\n    }\n    return schemas.get(tool_name)\n</code></pre></p> </li> <li> <p>Implement Tool Function <pre><code>async def my_new_tool(self, param1: str) -&gt; Dict[str, Any]:\n    \"\"\"Implementation of the new tool.\"\"\"\n    try:\n        # Tool logic here\n        result = await self._process_data(param1)\n\n        return {\n            \"success\": True,\n            \"result\": result\n        }\n    except Exception as e:\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }\n</code></pre></p> </li> <li> <p>Register Tool <pre><code>def __init__(self):\n    self.tools = {\n        \"search-datasets\": self.search_datasets,\n        \"download-dataset\": self.download_dataset,\n        \"my-new-tool\": self.my_new_tool,  # Add here\n    }\n</code></pre></p> </li> <li> <p>Add Client Method <pre><code># src/eclair/client/client.py\ndef my_new_tool(self, param1: str) -&gt; Dict[str, Any]:\n    \"\"\"Client method for new tool.\"\"\"\n    return self._call_tool(\"my-new-tool\", {\"param1\": param1})\n</code></pre></p> </li> <li> <p>Write Tests <pre><code># tests/test_new_tool.py\ndef test_my_new_tool(client):\n    \"\"\"Test the new tool.\"\"\"\n    result = client.my_new_tool(\"test_value\")\n    assert result[\"success\"] is True\n    assert \"result\" in result\n</code></pre></p> </li> <li> <p>Update Documentation <pre><code>&lt;!-- docs/api/tools.md --&gt;\n### my-new-tool\n\nDescription of the new tool.\n\n**Parameters:**\n- `param1` (string): Description\n\n**Example:**\n```python\nresult = client.my_new_tool(\"example\")\n</code></pre></p> </li> </ol>"},{"location":"development/#testing-strategy","title":"Testing Strategy","text":""},{"location":"development/#unit-tests","title":"Unit Tests","text":"<p>Test individual components in isolation:</p> <pre><code># tests/unit/test_tools.py\nimport pytest\nfrom unittest.mock import AsyncMock, patch\nfrom eclair.server.tools import EclairTools\n\n@pytest.fixture\ndef tools():\n    return EclairTools()\n\n@pytest.mark.asyncio\nasync def test_search_datasets_unit(tools):\n    \"\"\"Unit test for search functionality.\"\"\"\n    with patch('eclair.server.tools.search_engine') as mock_search:\n        mock_search.search.return_value = [{\"name\": \"test\", \"collection\": \"test\"}]\n\n        result = await tools.search_datasets(\"test query\")\n\n        assert len(result) == 1\n        assert result[0][\"name\"] == \"test\"\n        mock_search.search.assert_called_once_with(\"test query\")\n</code></pre>"},{"location":"development/#integration-tests","title":"Integration Tests","text":"<p>Test component interactions:</p> <pre><code># tests/integration/test_server.py\nimport pytest\nimport httpx\nfrom eclair.server.server import app\n\n@pytest.fixture\ndef client():\n    return httpx.AsyncClient(app=app, base_url=\"http://test\")\n\n@pytest.mark.asyncio\nasync def test_search_endpoint_integration(client):\n    \"\"\"Integration test for search endpoint.\"\"\"\n    response = await client.post(\"/mcp\", json={\n        \"method\": \"tools/call\",\n        \"params\": {\n            \"name\": \"search-datasets\",\n            \"arguments\": {\"query\": \"test\"}\n        }\n    })\n\n    assert response.status_code == 200\n    data = response.json()\n    assert \"content\" in data\n</code></pre>"},{"location":"development/#end-to-end-tests","title":"End-to-End Tests","text":"<p>Test complete workflows:</p> <pre><code># tests/e2e/test_workflow.py\nimport pytest\nfrom eclair.client import EclairClient\n\n@pytest.mark.e2e\ndef test_complete_workflow():\n    \"\"\"End-to-end test of search, download, analyze workflow.\"\"\"\n    client = EclairClient()\n\n    # Search for datasets\n    results = client.search_datasets(\"test datasets\")\n    assert len(results) &gt; 0\n\n    # Download first dataset\n    first_dataset = results[0]\n    path = client.download_dataset(\n        first_dataset[\"collection\"],\n        first_dataset[\"name\"]\n    )\n    assert path is not None\n\n    # Get metadata\n    metadata = client.get_dataset_metadata(\n        first_dataset[\"collection\"],\n        first_dataset[\"name\"]\n    )\n    assert \"name\" in metadata\n</code></pre>"},{"location":"development/#performance-tests","title":"Performance Tests","text":"<p>Test performance characteristics:</p> <pre><code># tests/performance/test_load.py\nimport pytest\nimport asyncio\nimport time\nfrom eclair.client import AsyncEclairClient\n\n@pytest.mark.performance\n@pytest.mark.asyncio\nasync def test_concurrent_searches():\n    \"\"\"Test performance under concurrent load.\"\"\"\n    client = AsyncEclairClient()\n\n    start_time = time.time()\n\n    # Run 10 concurrent searches\n    tasks = [\n        client.search_datasets(f\"query {i}\")\n        for i in range(10)\n    ]\n\n    results = await asyncio.gather(*tasks)\n\n    end_time = time.time()\n    total_time = end_time - start_time\n\n    # Should complete within reasonable time\n    assert total_time &lt; 5.0\n    assert all(len(result) &gt;= 0 for result in results)\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will help you install Eclair and get it running on your system. Eclair supports multiple installation methods depending on your needs.</p>"},{"location":"getting-started/installation/#quick-install","title":"Quick Install","text":"<p>The fastest way to install Eclair is pip. Eclair works with Python 3.10 or higher.</p> <pre><code>pip install eclair\n</code></pre> <p>Package Availability</p> <p>The Eclair package will be published to PyPI soon. In the meantime, use the development installation method below.</p>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>For the latest features or if you want to contribute to Eclair:</p> <p>Clone the Repository</p> <pre><code>git clone https://github.com/mlcommons/croissant.git\ncd eclair\n</code></pre> <p>Install Dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Install in Development Mode</p> <pre><code>pip install -e .\n</code></pre> <p>Install Development Tools (Optional). For development with additional tools like testing and linting:</p> <pre><code>pip install -e .[dev]\n</code></pre> <p>You should now be able to run the Eclair server:</p> <pre><code>eclair-server\n</code></pre>"},{"location":"getting-started/installation/#quick-start-script","title":"Quick Start Script","text":"<p>Eclair includes a convenient setup script:</p> <pre><code>./start.sh\n</code></pre> <p>This script will:</p> <ul> <li>Install all required dependencies</li> <li>Set up the development environment  </li> <li>Start the Eclair server automatically</li> </ul> <p></p>"},{"location":"getting-started/installation/#configuration","title":"Configuration","text":"<p>Eclair's behavior can be customized through configuration files and environment variables.</p>"},{"location":"getting-started/installation/#configuration-file","title":"Configuration File","text":"<p>Eclair uses <code>config.json</code> in the project root for its main configuration. This file controls server settings, upstream connections, and AI model preferences.</p> <p>This is the default configuration.</p> <pre><code>{\n  \"name\": \"Eclair Dataset MCP Server\",\n  \"description\": \"MCP server to help AI models work with datasets, built on Croissant\",\n  \"server\": {\n    \"host\": \"0.0.0.0\",\n    \"port\": 8080,\n    \"transport\": \"streamable-http\"\n  },\n  \"upstream_server\": {\n    \"url\": \"https://mcp.jetty.io/mcp\",\n    \"timeout\": 5000\n  },\n  \"gemini\": {\n    \"model\": \"gemini-2.5-pro\",\n    \"temperature\": 0.3\n  },\n  \"claude\": {\n    \"model\": \"claude-3-5-sonnet-20241022\",\n    \"temperature\": 0.3,\n    \"max_tokens\": 4096\n  }\n}\n</code></pre>"},{"location":"getting-started/installation/#mcp-server-settings","title":"MCP Server settings","text":"<p>Available Transport Methods:</p> <ul> <li><code>streamable-http</code> - HTTP streaming (recommended)</li> <li><code>sse</code> - Server-sent events (deprecated)</li> <li><code>stdio</code> - Standard input/output (for local usage)</li> </ul>"},{"location":"getting-started/installation/#upstream-server","title":"Upstream Server","text":"<p>Configuration for connecting to upstream MCP servers.</p> <pre><code>{\n  \"upstream_server\": {\n    \"url\": \"https://mcp.jetty.io/mcp\",  // Upstream server URL\n    \"timeout\": 5000,                    // Connection timeout (ms)\n  }\n}\n</code></pre> <p>Compatible MCP servers</p> <p>At the moment, Eclair has only been tested to work with Jetty.io, and is quite dependent on it. Over time, we hope to standardize the Eclair tools and allow multiple upstream MCP servers.</p>"},{"location":"getting-started/installation/#ai-agent-configuration","title":"AI Agent Configuration","text":"<p>Different AI agents require specific configuration:</p>"},{"location":"getting-started/installation/#gemini-cli-configuration","title":"Gemini CLI Configuration","text":"<p>Create <code>~/.gemini/settings.json</code>: <pre><code>{\n  \"mcpServers\": {\n    \"eclair\": {\n      \"httpUrl\": \"http://localhost:8080/mcp\",\n      \"timeout\": 5000\n    }\n  },\n  \"selectedAuthType\": \"gemini-api-key\"\n}\n</code></pre></p> <p>For step by step instructions, see the Gemini CLI user guide.</p>"},{"location":"getting-started/installation/#claude-code-configuration","title":"Claude Code Configuration","text":"<p>Register the server: <pre><code>claude mcp add --transport http Eclair http://0.0.0.0:8080/mcp\n</code></pre></p> <p>For step by step instructions, see the Claude Code user guide.</p>"},{"location":"getting-started/installation/#vs-code-mcp-configuration","title":"VS Code MCP Configuration","text":"<p>Add to VS Code MCP settings: <pre><code>{\n  \"mcpServers\": {\n    \"eclair\": {\n      \"command\": \"eclair-server\",\n      \"args\": [\"--transport\", \"stdio\"]\n    }\n  }\n}\n</code></pre></p> <p>For step by step instructions, see the IDE user guide.</p>"},{"location":"getting-started/running-server/","title":"Running the Server","text":"<p>Once you have Eclair installed, you need to run the server to enable AI agents to access datasets. This guide covers different ways to start and manage the Eclair server.</p>"},{"location":"getting-started/running-server/#quick-start","title":"Quick Start","text":"<p>The simplest way to run Eclair:</p> <pre><code>eclair-server\n</code></pre> <p>This starts the server with default settings:</p> <ul> <li>Host: 0.0.0.0 (accessible from any network interface)</li> <li>Port: 8080</li> <li>Transport: streamable-http</li> </ul> <p>You should see output similar to: <pre><code>\u26a1\ufe0f Starting Eclair Server...\n\ud83c\udf10 Server running at http://0.0.0.0:8080/mcp\n\ud83d\udd27 Transport: streamable-http\n\u2705 Server ready for connections!\n</code></pre></p>"},{"location":"getting-started/running-server/#command-line-options","title":"Command Line Options","text":"<p>Customize the server with command-line arguments:</p> <pre><code>eclair-server --host 127.0.0.1 --port 9000 --transport sse\n</code></pre>"},{"location":"getting-started/running-server/#available-options","title":"Available Options","text":"Option Short Description Default <code>--host</code> <code>-h</code> Host to bind to <code>0.0.0.0</code> <code>--port</code> <code>-p</code> Port to listen on <code>8080</code> <code>--transport</code> <code>-t</code> Transport method <code>streamable-http</code> <code>--config</code> <code>-c</code> Config file path <code>config.json</code> <code>--verbose</code> <code>-v</code> Enable verbose logging <code>False</code> <code>--help</code> Show help message"},{"location":"getting-started/running-server/#manual-server-execution","title":"Manual Server Execution","text":"<p>You can also run the server directly from the Python module:</p> <pre><code>python server/server.py --host 0.0.0.0 --port 8080 --transport streamable-http\n</code></pre> <p>Or from within the source directory: <pre><code>cd /path/to/eclair\npython -m src.eclair.server.server\n</code></pre></p>"},{"location":"getting-started/running-server/#configuration-based-startup","title":"Configuration-Based Startup","text":"<p>For consistent deployments, use a configuration file:</p> <pre><code>eclair-server --config /path/to/config.json\n</code></pre> <p>The server will read all settings from the config file. See Configuration for details.</p>"},{"location":"getting-started/running-server/#process-management","title":"Process Management","text":""},{"location":"getting-started/running-server/#running-in-background","title":"Running in Background","text":"<p>On macOS/Linux: <pre><code># Start in background\nnohup eclair-server &gt; eclair.log 2&gt;&amp;1 &amp;\n\n# Check if running\nps aux | grep eclair-server\n\n# Stop server\npkill -f eclair-server\n</code></pre></p>"},{"location":"getting-started/running-server/#common-error-messages","title":"Common Error Messages","text":"<p>\"Address already in use\"</p> <ul> <li>Port 8080 is busy, maybe by another Eclair server. Use <code>--port</code> to specify a different port or shut down the other service on port 8080.</li> </ul> <p>\"Connection refused\"</p> <ul> <li>Check firewall settings</li> <li>Verify server is running</li> <li>Confirm correct host/port</li> </ul>"},{"location":"usage/cli/","title":"Command Line Interface (CLI)","text":"<p>Eclair provides a powerful command-line interface for dataset discovery, downloading, and management. The CLI is perfect for automation, scripting, and quick dataset operations.</p>"},{"location":"usage/cli/#installation","title":"Installation","text":"<p>The CLI is included with the Eclair package:</p> <pre><code>pip install eclair\n</code></pre> <p>Or for development:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"usage/cli/#basic-usage","title":"Basic Usage","text":"<p>The main CLI command is <code>eclair-client</code>:</p> <pre><code>eclair-client --help\n</code></pre> <pre><code>Usage: eclair-client [-h] [--server-url SERVER_URL] --tool TOOL [--query QUERY] [--collection COLLECTION] [--dataset DATASET] [--use-gemini] [--use-claude]\n\nEclair MCP Client\n\noptions:\n  -h, --help            show this help message and exit\n  --server-url SERVER_URL, -S SERVER_URL\n                        MCP server URL\n  --tool TOOL, -T TOOL  Tool to call\n  --query QUERY, -Q QUERY\n                        Query string for search-datasets\n  --collection COLLECTION, -C COLLECTION\n                        Dataset collection\n  --dataset DATASET, -D DATASET\n                        Dataset name\n  --use-gemini, -G      Use Gemini client\n  --use-claude, -L      Use Claude client\n</code></pre>"},{"location":"usage/cli/#examples","title":"Examples","text":"<pre><code># Test server connectivity\neclair-client --tool ping\n\n# Search for datasets\neclair-client --tool search-datasets --query \"mnist\"\n\n# Get croissant meta-data\neclair-client --tool search-datasets --query \"mnist\"\n</code></pre> <p>The reponses will be identical to the respective tools use in the Python API. Check the Python docs for more detailes examples.</p>"},{"location":"usage/cli/#using-ai-models","title":"Using AI models","text":"<p>You can also use Eclair with AI models directly from the command line. For this, you also need to set your AI model's API key and system prompt. For instance, for Gemini, do the following (replace XXX with your API key):</p> <pre><code>echo \"GEMINI_API_KEY=XXX\" &gt;&gt; .env\necho \"GEMINI_SYSTEM_MD=\"src/eclair/client/gemini/gemini.md\" &gt;&gt; .env\n</code></pre> <p>This also works with AI model integrations, e.g. with the <code>use-gemini</code> argument: <pre><code># Use with Gemini\neclair-client --use-gemini --tool ask --query \"Find datasets for image segmentation\"\n\n# Short form\neclair-client -G -T ask -Q \"Find datasets for image segmentation\"\n</code></pre></p> <p>TODO: The CLI interface currently doesn't keep a conversation state between commands. Use the IDE integrations and AI agents below for longer conversations with memory.</p>"},{"location":"usage/cli/#cli-reference-summary","title":"CLI Reference Summary","text":"Method Purpose Returns <code>ping()</code> Test server connectivity \"pong\" if server is responsive <code>search-datasets --query QUERY</code> Search for datasets List of matching datasets <code>download-dataset --collection COLLECTION --dataset DATASET</code> Download a dataset Success/failure status <code>serve-croissant --collection COLLECTION --dataset DATASET</code> Get dataset metadata Croissant JSON metadata <code>datasets-preview-url --collection COLLECTION --dataset DATASET</code> Get dataset preview URL URL string for preview <code>help</code> Get server help information Help text and usage info <p>Overview of argments and shortcuts:</p> Long Form Short Form Description <code>--server-url</code> <code>-S</code> MCP server URL <code>--tool</code> <code>-T</code> Tool to call <code>--query</code> <code>-Q</code> Query string for search-datasets <code>--collection</code> <code>-C</code> Dataset collection <code>--dataset</code> <code>-D</code> Dataset name <code>--use-gemini</code> <code>-G</code> Use Gemini client <code>--use-claude</code> <code>-L</code> Use Claude client"},{"location":"usage/cli/#example","title":"Example","text":"<p>Command: <pre><code>eclair-client -GT ask -Q \"look for interesting datasets for image segmentation and order by size\"\n</code></pre></p> Click to expand the AI response <pre><code>Of course! I'd be happy to help you find interesting datasets for image segmentation. Let's get started right away.\n\nFirst, I'll search for datasets related to \"image segmentation\" on the eclair server. Then, I'll analyze their metadata to determine their size and present them to you in descending order.\n\nExcellent! The search returned a great list of potential datasets. Now, I will retrieve the Croissant metadata for each of these to find their sizes and other relevant details. This might take a moment as I need to query each one individually.\n\nFantastic! I've successfully retrieved the metadata and extracted the sizes for each dataset. Here is the list of image segmentation datasets, ordered from largest to smallest:\n\n1.  **`segments/sam-1b`**\n    *   **Size**: 12.3 TB\n    *   **Description**: The Segment Anything 1-Billion mask dataset (SA-1B). A massive, high-quality dataset with over 1 billion masks on 11 million images, designed for developing foundational models in computer vision.\n\n2.  **`google/cityscapes`**\n    *   **Size**: ~11.2 GB (11.0 GB + 241.0 MB)\n    *   **Description**: A large-scale dataset focusing on semantic understanding of urban street scenes from 50 different cities. It's a standard benchmark for autonomous driving applications.\n\n3.  **`segments/sidewalk-semantic`**\n    *   **Size**: 1.8 GB\n    *   **Description**: A collection of images focused on urban sidewalks with detailed semantic segmentation. Crucial for applications like autonomous robot navigation and accessibility tools.\n\n4.  **`scene_parse_150`**\n    *   **Size**: 1.0 GB\n    *   **Description**: A benchmark for scene parsing, providing densely annotated images with pixel-level labels for a wide range of objects and scenes.\n\n5.  **`augmented-traffic-signs`**\n    *   **Size**: 1.0 GB\n    *   **Description**: Contains 1000 images of traffic signs (1280x720) with segmentation masks, split into training and test sets.\n\n6.  **`facebook/ade20k`**\n    *   **Size**: 887.0 MB\n    *   **Description**: A large-scale scene parsing benchmark with a diverse set of images and dense annotations for objects and their parts.\n\n7.  **`nielsr/ade20k-panoptic`**\n    *   **Size**: 887.0 MB\n    *   **Description**: A panoptic version of the ADE20K dataset, providing annotations for both semantic \"stuff\" (like sky, road) and instance \"things\" (like individual cars, people).\n\n8.  **`kvasir-v2`**\n    *   **Size**: 495.0 MB\n    *   **Description**: A diverse dataset of medical images from the gastrointestinal tract, annotated by experts for developing computer-aided diagnosis systems.\n\n9.  **`kvasir-instrument`**\n    *   **Size**: 80.0 MB\n    *   **Description**: A dataset of images from colonoscopy procedures, with segmentation masks for various medical instruments. Useful for computer-assisted surgery applications.\n\n10. **`fashion-mnist`**\n    *   **Size**: 31.0 MB\n    *   **Description**: A dataset of 70,000 28x28 grayscale images of clothing items. While primarily for classification, it can be used for simple segmentation tasks.\n\nThis list should give you a great starting point! The `sam-1b` dataset is exceptionally large and state-of-the-art, while `cityscapes` and `ade20k` are very popular and well-established benchmarks.\n</code></pre> <p>Eclair can be integrated in many more ways. Let us know your ideas!</p>"},{"location":"usage/overview/","title":"Usage Overview","text":"<p>Eclair is designed to be flexible and accessible through multiple interfaces, each suited for different workflows and use cases. This section covers all the ways you can use Eclair to discover, analyze, and work with datasets. </p> <p>Below are usage guides for an initial set of AI agents and interfaces, but in principle any agent that supports MCP can leverage Eclair. Feel free to update this documentation with additional guides!</p>"},{"location":"usage/overview/#ai-agents-with-cli","title":"\ud83e\udd16 AI Agents with CLI","text":"<ul> <li>Gemini CLI - Command-line AI assistant powered by Google's Gemini models</li> <li>Claude Code - Command-line AI assistant powered by Anthropic's Claude models</li> </ul>"},{"location":"usage/overview/#ide-integration","title":"\ud83d\udd27 IDE Integration","text":"<p>Seamless integration into your development environment:</p> <ul> <li>VS Code + Copilot - GitHub Copilot enhanced with Eclair </li> <li>VS Code + Gemini Code Assist - Google's Gemini Code Assist enhanced with Eclair's capabilities</li> </ul> <p>Of course, you can also use Eclair with other IDEs such as Cursor.</p>"},{"location":"usage/overview/#python-api","title":"\ud83d\udc0d Python API","text":"<p>Programmatic access for automation and integration:</p> <ul> <li>Python API - Provides access to all Eclair tools via a Python API</li> <li>Three client types: <code>EclairClient</code> (base MCP), <code>GeminiMCPClient</code> (AI-powered), <code>ClaudeMCPClient</code> (AI-powered)</li> <li>Perfect for Jupyter notebooks, data pipelines, and automated workflows</li> </ul>"},{"location":"usage/overview/#command-line-interface","title":"\u26a1 Command Line Interface","text":"<p>Quick dataset operations from the terminal:</p> <ul> <li>CLI Reference - Complete command-line interface to all Eclair tools</li> <li>Also supports AI-powered commands (in natural language) as in the Python API</li> <li>Ideal for scripting, automation, and quick dataset queries</li> </ul>"},{"location":"usage/python-api/","title":"Python API Reference","text":"<p>Eclair provides a comprehensive Python API for programmatic access to dataset discovery, downloading, and metadata validation. This is perfect for automation, batch processing, and integration into data pipelines.</p>"},{"location":"usage/python-api/#installation","title":"Installation","text":"<p>Install Eclair with Python API support:</p> <pre><code>pip install eclair\n</code></pre> <p>Alternatively, install the development version from source code:</p> <pre><code>git clone https://github.com/mlcommons/croissant.git\ncd croissant/eclair\npip install -e .\n</code></pre>"},{"location":"usage/python-api/#quick-start","title":"Quick Start","text":"<p>The code below creates an Eclair python client, searches for datasets, retrieves metadata,  and retrieves download instructions.</p> <p>All methods are async and return <code>CallToolResult</code> objects. Access the data through the  <code>structured_content['result']</code> property.</p> <pre><code>import asyncio\nfrom eclair.client import EclairClient\n\nasync def main():\n    # Create client instance\n    client = EclairClient()\n\n    # Test connectivity\n    result = await client.ping()\n    print(f\"Server status: {result.structured_content['result']}\")\n\n    # Search for datasets\n    datasets = await client.search_datasets(\"computer vision\")\n    print(f\"Found {len(datasets.structured_content['result'])} datasets\")\n\n    # Get dataset metadata (Croissant format)\n    metadata_result = await client.serve_croissant(\"ylecun\", \"mnist\")\n    metadata = metadata_result.structured_content['result']\n    print(f\"Data description: {metadata.get('description', 'N/A')[:200]}...\")\n\n    # Download dataset information\n    download_result = await client.download_dataset(\"ylecun\", \"mnist\")\n    download_info = download_result.structured_content['result']\n    print(download_info['instructions'][:300])\n\n# Run the async function\nasyncio.run(main())\n</code></pre> Click to expand the output <pre><code>Server status: Pong! Eclair MCP Server is running successfully.\nFound 40 datasets\n\nData description: Dataset Card for MNIST\nThe MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits...\n\n# Install if necessary\n# !pip install datasets pandas\nfrom datasets import load_dataset\n\n# 1. Load this dataset from Hugging Face\ndataset = load_dataset(\"ylecun/mnist\")\n...\n</code></pre>"},{"location":"usage/python-api/#api-reference-summary","title":"API Reference Summary","text":"Method Purpose Returns <code>ping()</code> Test server connectivity \"pong\" if server is responsive <code>search_datasets(query)</code> Search for datasets List of matching datasets <code>download_dataset(collection, dataset)</code> Download a dataset Success/failure status <code>serve_croissant(collection, dataset)</code> Get dataset metadata Croissant JSON metadata <code>validate_croissant(metadata)</code> Validate metadata format Validation results with errors <code>datasets_preview_url(collection, dataset)</code> Get dataset preview URL URL string for preview <code>get_help()</code> Get server help information Help text and usage info <p>All methods are async and return <code>CallToolResult</code> objects. Access the actual data via <code>.structured_content['result']</code>.</p>"},{"location":"usage/python-api/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from eclair.client import EclairClient\n\n# Uses default server URL (http://localhost:8080/mcp)\nclient = EclairClient()\n\n# Alternatively, connect to a local or remote server\nclient = EclairClient(\"http://192.168.1.100:8080/mcp\")\n</code></pre>"},{"location":"usage/python-api/#search-datasets","title":"Search Datasets","text":"<p>Search for datasets using natural language queries:</p> <pre><code>async def search_example():\n    client = EclairClient()\n\n    # Search with various types of queries\n    cv_results = await client.search_datasets(\"computer vision\")\n    nlp_results = await client.search_datasets(\"natural language processing\")\n    mnist_results = await client.search_datasets(\"handwritten digits\")\n\n    # Access the results\n    datasets = cv_results.structured_content['result']\n    for dataset in datasets[:3]:  # Show first 3 results\n        dataset = dataset['document']\n        print(f\"Collection: {dataset['collection_name']}\")\n        print(f\"Dataset: {dataset['entity_name']}\")\n        print(f\"URL: {dataset['metadata']['url']}\")\n        print(\"---\")\n\nasyncio.run(search_example())\n</code></pre> Click to expand the output <pre><code>Collection: mbateman\nDataset: github-issues\nURL: https://huggingface.co/datasets/mbateman/github-issues\n---\nCollection: djghosh\nDataset: wds_vtab-dtd_test\nURL: https://huggingface.co/datasets/djghosh/wds_vtab-dtd_test\n---\nCollection: cansa\nDataset: Describable-Textures-Dataset-DTD\nURL: https://huggingface.co/datasets/cansa/Describable-Textures-Dataset-DTD\n---\n</code></pre>"},{"location":"usage/python-api/#download-dataset","title":"Download Dataset","text":"<p>Download datasets to your local machine:</p> <pre><code>async def download_example():\n    client = EclairClient()\n\n    # Download Fashion-MNIST dataset\n    result = await client.download_dataset(\"ylecun\", \"mnist\")\n    print(result.structured_content)\n\nasyncio.run(download_example())\n</code></pre> Click to expand the output <pre><code>{'result': \n    {'metadata': \n        {'url': 'https://huggingface.co/datasets/ylecun/mnist',\n         'name': 'mnist', \n         '@type': 'sc:Dataset', \n         'sameAs': 'http://yann.lecun.com/exdb/mnist/', \n         'license': 'https://choosealicense.com/licenses/mit/', \n         ...\n</code></pre>"},{"location":"usage/python-api/#get-dataset-metadata-croissant-format","title":"Get Dataset Metadata (Croissant Format)","text":"<p>Retrieve dataset metadata in Croissant JSON format:</p> <pre><code>async def metadata_example():\n    client = EclairClient()\n\n    # Get MNIST metadata\n    result = await client.serve_croissant(\"ylecun\", \"mnist\")\n    metadata = result.structured_content['result']\n\n    # Display key information\n    print(f\"Description: {metadata.get('description', 'N/A')}\")\n    print(f\"License: {metadata.get('license', 'N/A')}\")\n\n    # Show distribution information\n    if 'distribution' in metadata:\n        for dist in metadata['distribution']:\n            print(f\"File: {dist.get('name', 'N/A')}\")\n            print(f\"Format: {dist.get('encodingFormat', 'N/A')}\")\n            print(f\"URL: {dist.get('contentUrl', 'N/A')}\")\n\nasyncio.run(metadata_example())\n</code></pre> Click to expand the output <pre><code>Description: Dataset Card for MNIST\nThe MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class...\nLicense: https://choosealicense.com/licenses/mit/\nFile: repo\nFormat: git+https\nURL: https://huggingface.co/datasets/ylecun/mnist/tree/refs%2Fconvert%2Fparquet\n</code></pre>"},{"location":"usage/python-api/#validate-croissant-metadata","title":"Validate Croissant Metadata","text":"<p>Validate Croissant JSON metadata for correctness:</p> <pre><code>async def validation_example():\n    client = EclairClient()\n\n    # Example metadata to validate\n    sample_metadata = {\n        \"@id\": \"test-dataset\",\n        \"name\": \"Test Dataset\",\n        \"description\": \"A sample dataset for testing\",\n        \"license\": \"CC0-1.0\"\n    }\n\n    # Validate the metadata\n    result = await client.validate_croissant(sample_metadata)\n    validation_result = result.structured_content['result']\n\n    if validation_result.get('valid', False):\n        print(\"\u2705 Metadata is valid!\")\n    else:\n        print(\"\u274c Metadata validation failed:\")\n        for error in validation_result.get('errors', []):\n            print(f\"  - {error}\")\n\nasyncio.run(validation_example())\n</code></pre>"},{"location":"usage/python-api/#get-dataset-preview-url","title":"Get Dataset Preview URL","text":"<p>Get a preview URL for exploring dataset contents.</p> <p>Experimental</p> <p>This feature is experimental and will not work for all datasets.</p> <pre><code>async def preview_example():\n    client = EclairClient()\n\n    # Get preview URL for Fashion-MNIST\n    result = await client.datasets_preview_url(\"ylecun\", \"fashion-mnist\")\n    preview_url = result.structured_content['result']\n\n    print(f\"Dataset preview available at: {preview_url}\")\n\n    # You can then open this URL in a browser or use requests to fetch content\n\nasyncio.run(preview_example())\n</code></pre>"},{"location":"usage/python-api/#check-server-status","title":"Check Server Status","text":"<p>Test connectivity and server health:</p> <pre><code>async def health_check():\n    client = EclairClient()\n\n    # Ping the server\n    result = await client.ping()\n    status = result.structured_content['result']\n\n    if status == \"pong\":\n        print(\"\u2705 Eclair server is running and responsive\")\n    else:\n        print(\"\u274c Server connectivity issue\")\n\nasyncio.run(health_check())\n</code></pre>"},{"location":"usage/python-api/#get-help-information","title":"Get Help Information","text":"<p>Retrieve help and usage information:</p> <pre><code>async def help_example():\n    client = EclairClient()\n\n    # Get help information\n    result = await client.get_help()\n    help_content = result.structured_content['result']\n\n    print(\"Eclair Server Help:\")\n    print(help_content)\n\nasyncio.run(help_example())\n</code></pre>"},{"location":"usage/python-api/#basic-examples","title":"Basic Examples","text":""},{"location":"usage/python-api/#dataset-search","title":"Dataset Search","text":"<p>This example shows how to run the search-datasets tool in Python. Other tools are called similarly. <pre><code>import asyncio\nimport json\nfrom eclair.client import EclairClient\n\nasync def main():\n    # Create a python client\n    # Include the URL where your server is running\n    client = EclairClient(\"http://localhost:8080/mcp\")\n\n    # Run the `search-datasets` tool  \n    datasets = await client.search_datasets(\"mnist\")\n\n    # Parse results\n    for i, ds in enumerate(datasets.content, 1):\n        doc = json.loads(ds.text)['document']\n        print(f\"{i}. {doc['collection_name']}/{doc['entity_name']}\")\n\nasyncio.run(main())\n</code></pre></p> Click to expand the output <pre><code>1. ylecun/mnist\n2. VedantPadwal/mnist\n3. ChristianOrr/mnist\n4. severo/mnist\n5. barkermrl/mnist-c\n6. louisraedisch/AlphaNum\n7. RomanShp/MNIST-ResNet-Demo-Data\n8. Fraser/mnist-text-small\n9. MagedSaeed/MADBase\n...\n</code></pre>"},{"location":"usage/python-api/#data-workflows","title":"Data workflows","text":"<p>In the same way you can combine tools for more complex workflows, such as searching for datasets, checking the meta-data, and downloading it. <pre><code>async def dataset_workflow():\n    client = EclairClient(\"http://localhost:8080/mcp\")\n\n    # Search for MNIST datasets\n    response = await client.search_datasets(\"mnist\")\n    datasets = response.content\n    print(f\"Found {len(datasets)} MNIST-like datasets\")\n\n    # Get Croissant metadata for a specific dataset\n    response = await client.serve_croissant(\"ylecun\", \"mnist\")\n    metadata = response.content[0].text\n    print(\"Dataset metadata:\", metadata,'...')\n\n    # Get download information\n    response = await client.download_dataset(\"ylecun\", \"mnist\")\n    download_info = json.loads(response.content[0].text)\n    print(\"Download details:\", list(download_info.keys()))\n    print(\"Download instructions:\", download_info[\"instructions\"])\n\n    # Get preview URL if available\n    response = await client.datasets_preview_url(\"ylecun\", \"mnist\")\n    preview_url = response.content[0].text\n    print(f\"Preview URL: {preview_url}\")\n\nasyncio.run(dataset_workflow())\n</code></pre> Output below. This gives you an overview of relevant datasets, detailed metadata for each, download instructions (including code), and a link to preview a sample of the dataset.</p> Click to expand the output <pre><code>Found 23 MNIST-like datasets\n</code></pre> <pre><code>Dataset metadata: {\n  \"url\": \"https://huggingface.co/datasets/ylecun/mnist\",\n  \"name\": \"mnist\",\n  \"@type\": \"sc:Dataset ...\n</code></pre> <pre><code>Download details: ['metadata', 'asset_origin', 'data_path', 'instructions']\nDownload instructions: \n</code></pre> <pre><code># Install if necessary\n# !pip install datasets pandas\n\nfrom datasets import load_dataset\nimport pandas as pd\n\n# 1. Load a sample dataset from Hugging Face\ndataset = load_dataset(\"ylecun/mnist\")\n\n# 2. Convert to a pandas DataFrame for easier exploration\ndf_train = pd.DataFrame(dataset[\"train\"])\n\nprint(\"\\nPandas DataFrame Head:\")\nprint(df_train.head())\n</code></pre> <pre><code>Preview URL: https://dock.jetty.io/api/v1/datasets/ylecun/mnist/preview\n</code></pre>"},{"location":"usage/python-api/#dataset-validation","title":"Dataset Validation","text":"<p>This is how you can use the Croissant validation tool:\" <pre><code>import asyncio\nimport json\nfrom eclair.client import EclairClient\n\nasync def validate_dataset():\n    client = EclairClient(\"http://localhost:8080/mcp\")\n\n    # First get some metadata to validate from OpenML\n    response = await client.serve_croissant(\"Albert-Bifet\", \"covertype\")\n    croissant = response.content[0].text\n    print(croissant)\n\n    # Validate the Croissant metadata\n    validation_result = await client.validate_croissant(croissant)\n    print(\"Validation result:\")\n    print(json.dumps(json.loads(validation_result.content[0].text), indent=2))\n\nasyncio.run(validate_dataset())\n</code></pre></p> <p>Output: The metadata is valid Croissant and we can automatically load the dataset.</p> Click to expand the output <pre><code>{\n  \"valid\": true,\n  \"results\": [\n    {\n      \"test\": \"JSON Format Validation\",\n      \"passed\": true,\n      \"message\": \"The string is valid JSON.\",\n      \"status\": \"pass\"\n    },\n    {\n      \"test\": \"Croissant Schema Validation\",\n      \"passed\": true,\n      \"message\": \"The dataset passes Croissant validation.\",\n      \"status\": \"pass\"\n    },\n    {\n      \"test\": \"Records Generation Test\",\n      \"passed\": true,\n      \"message\": \"Record set 'enumerations/class' passed validation.\n      \"status\": \"pass\"\n    }\n  ]\n}\n</code></pre>"},{"location":"usage/python-api/#using-ai-models","title":"Using AI models","text":"<p>MCP tools are especially powerful if we give them to AI models, so we can ask complex questions in natural language. Eclair offers a number of clients to facilitate this, such as <code>GeminiMCPClient</code>, and you can easily create new clients using FastMCP.</p> <p>To use AI models in combination with Eclair, you also need to set your AI model's API key and system prompt. For instance, for Gemini, do the following (replace XXX with your API key):</p> <pre><code>echo \"GEMINI_API_KEY=XXX\" &gt;&gt; .env\necho \"GEMINI_SYSTEM_MD=\"src/eclair/client/gemini/gemini.md\" &gt;&gt; .env\n</code></pre>"},{"location":"usage/python-api/#basic-questions","title":"Basic questions","text":"<p>First, a simple request to find interesting datasets. The AI model decides automatically which Eclair tools to use.</p> <pre><code>from eclair.client.gemini import GeminiMCPClient\nimport asyncio\n\nasync def ai_assistant():\n    client = GeminiMCPClient()\n    await client.initialize()\n\n    # Let Gemini understand and execute complex requests\n    response = await client.ask_gemini_with_tools(\n        \"Find me datasets on tree covertype in national forests in the USA\"\n        \"and tell me which one has the best information on tree coverage at different elevations.\"\n    )\n    print(response)\n\nasyncio.run(ai_assistant())\n</code></pre> Click to expand the AI response  Of course. I have analyzed the search results for datasets on tree covertype in US national forests.  While the request was for multiple datasets, my search returned one highly relevant and comprehensive dataset that is well-known for this type of analysis. Here is a breakdown of my findings and my recommendation.  ### Dataset Found:  **1. Covertype Dataset**  *   **Summary:** This is a classic dataset used for predicting forest cover type from cartographic variables. The data was collected from four wilderness areas within the **Roosevelt National Forest** in northern Colorado. Each data point represents a 30x30 meter cell. *   **Source:** The data originates from the US Forest Service (USFS) and the US Geological Survey (USGS). *   **Key Features:**     *   **Elevation:** Measured in meters.     *   **Aspect:** The direction of the slope, in degrees.     *   **Slope:** The steepness of the slope, in degrees.     *   **Distance to Hydrology/Roadways/Fire Points:** Horizontal and vertical distances to various landmarks.     *   **Wilderness Area:** 4 binary columns indicating which of the four wilderness areas the cell belongs to.     *   **Soil Type:** 40 binary columns for different soil types.     *   **Cover\\_Type:** The target variable, an integer from 1 to 7 representing the dominant tree species (e.g., Spruce/Fir, Lodgepole Pine, Ponderosa Pine).  ---  ### Recommendation:  Based on your specific interest in analyzing tree coverage at different elevations, the **Covertype dataset is an excellent choice**.  Here\u2019s why it has the best information for your needs among the results: 1.  **Direct Elevation Data:** The dataset includes a quantitative `Elevation` feature, measured in meters. This allows you to directly correlate specific elevations with different tree cover types. 2.  **Rich Contextual Information:** The description explicitly states that the four wilderness areas included in the study have different mean elevations and, as a result, different dominant tree species. 3.  **Granularity:** The data is provided at a 30x30 meter cell resolution, which is granular enough to perform detailed analysis on how cover types change with elevation, slope, and aspect.  This dataset is perfectly suited for tasks like creating elevation bands (e.g., low, medium, high) and then analyzing the distribution of the 7 different `Cover_Type` classes within each band. I would strongly recommend starting your analysis with this dataset."},{"location":"usage/python-api/#deeper-questions","title":"Deeper questions","text":"<p>You can also create complex request, or let the AI model itself figure out how to answer a complex question given the available tools.</p> <pre><code>async def smart_dataset_workflow():\n    client = GeminiMCPClient()\n    await client.initialize()\n\n    # Complex dataset analysis and recommendation\n    recommendation = await client.ask_gemini_with_tools(\"\"\"\n        I need to build a model for recognizing handwritten digits. \n        Please:\n        1. Find suitable datasets for this task\n        2. Get metadata including their sizes, formats, and quality\n        3. Provide code to download this data\n    \"\"\")\n\n    print(recommendation)\n</code></pre> Click to expand the AI response  Of course. I have analyzed the search results for datasets suitable for building a handwritten digit recognition model. Here is a summary of the findings, my recommendations, and the code to get you started.  ### 1. Suitable Datasets  Based on the search, the most suitable and widely-used dataset for your task is the **MNIST (Modified National Institute of Standards and Technology) dataset**. Several versions of this dataset were found, with the most authoritative and easiest to use being:  *   **`ylecun/mnist`**: Hosted on the Hugging Face Hub. This is the original MNIST dataset provided by one of its creators, Yann LeCun. It's the recommended choice due to its ease of access via the `datasets` library. *   **`Yann-LeCun/mnist_784`**: Hosted on OpenML. This is the same classic dataset, accessible through libraries like Scikit-learn.  These datasets are the standard benchmark for digit recognition and are perfect for your project.  ### 2. Metadata and Analysis  Here is a breakdown of the recommended datasets.  | Dataset Name | `ylecun/mnist` (Hugging Face) | `Yann-LeCun/mnist_784` (OpenML) | | :--- | :--- | :--- | | **Description** | The classic dataset of 70,000 handwritten digits (0-9). | The same classic dataset, with each image flattened into 784 features. | | **Size** | - **Total Images**: 70,000- **Training Set**: 60,000 images- **Test Set**: 10,000 images | - **Total Images**: 70,000- **Training Set**: 60,000 examples- **Test Set**: 10,000 examples | | **Format** | - **Images**: 28x28 grayscale `PIL.Image` objects.- **Labels**: Integers from 0 to 9. | - **Data**: 70,000 rows x 784 columns (flattened 28x28 images).- **Labels**: String representations of digits '0' through '9'. | | **Quality** | High. This is the canonical, pre-processed dataset that has been used to benchmark thousands of machine learning models. The images are size-normalized and centered. | High. Same data source and quality as the Hugging Face version. It is a well-structured and clean dataset. | | **Best For** | Projects using modern deep learning frameworks like PyTorch or TensorFlow, as the Hugging Face `datasets` library integrates seamlessly with them. | Projects using traditional machine learning or Scikit-learn, where a simple feature matrix (`X`) and target vector (`y`) are preferred. |  ---  #### Other Datasets Found (Less Suitable)  *   **`Kaggle/SignMNIST`**: This dataset is for **American Sign Language letters**, not handwritten digits. While it's inspired by MNIST, it's for a different task. *   **`Isabelle-Guyon/gina_agnostic`**: This is a more complex, modified version of MNIST created for a specific machine learning challenge (distinguishing odd vs. even numbers from pairs of digits). It is not suitable for standard 10-class digit recognition. *   **`MagedSaeed/MADBase`**: This dataset contains **Arabic handwritten digits**, which is a different character set from the standard 0-9 digits you likely intend to recognize.  ---  ### 3. Code to Download the Data  #### Using the Hugging Face `datasets` library  This is the best option if you plan to use deep learning frameworks.  First, install the library: <pre><code>pip install datasets\n</code></pre>  Then, use this Python code to download and inspect the data: <pre><code>from datasets import load_dataset\n\n# Load the MNIST dataset from the Hugging Face Hub\nmnist_dataset = load_dataset(\"ylecun/mnist\")\n\n# You can easily access the training and testing splits\ntrain_data = mnist_dataset[\"train\"]\ntest_data = mnist_dataset[\"test\"]\n\n# Let's look at a single example\nexample = train_data[0]\nimage = example['image']\nlabel = example['label']\n\nprint(f\"\\nExample label: {label}\")\nprint(f\"Image size: {image.size}\")\nprint(f\"Image mode: {image.mode}\")\n\n# To display the image (requires matplotlib and Pillow)\n# pip install matplotlib Pillow\nimport matplotlib.pyplot as plt\n\nplt.imshow(image, cmap='gray')\nplt.title(f\"Label: {label}\")\nplt.show()\n</code></pre>  ### Using OpenML and Scikit-learn  This is a great option if you are using Scikit-learn for your modeling.  First, ensure you have Scikit-learn installed: <pre><code>pip install scikit-learn\n</code></pre>  Then, use this code to download the `mnist_784` dataset from OpenML: <pre><code>from sklearn.datasets import fetch_openml\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Fetch the dataset from OpenML.\n# as_frame=False returns NumPy arrays instead of a Pandas DataFrame\nmnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n\n# The data is in a dictionary-like object\n# 'data' contains the flattened images (features)\n# 'target' contains the labels\nX = mnist.data\ny = mnist.target\n\nprint(f\"Data shape (X): {X.shape}\")   # (70000, 784)\nprint(f\"Target shape (y): {y.shape}\") # (70000,)\nprint(f\"Data type: {X.dtype}\")        # float64\nprint(f\"Target type: {y.dtype}\")      # object (strings)\n\n# Note: The labels are strings, so you might want to convert them to integers\ny = y.astype(np.uint8)\nprint(f\"Target type after conversion: {y.dtype}\") # uint8\n\n# Split the data into training and test sets as is standard for MNIST\nX_train, X_test = X[:60000], X[60000:]\ny_train, y_test = y[:60000], y[60000:]\n\nprint(f\"\\nTraining data shape: {X_train.shape}\")\nprint(f\"Test data shape: {X_test.shape}\")\n\n# To visualize an image, you need to reshape it from 784 to 28x28\nfirst_image = X_train[0]\nfirst_image_reshaped = first_image.reshape(28, 28)\nfirst_label = y_train[0]\n\nplt.imshow(first_image_reshaped, cmap='gray')\nplt.title(f\"Label: {first_label}\")\nplt.show()\n</code></pre>"},{"location":"usage/python-api/#jupyter-notebook-usage","title":"Jupyter Notebook Usage","text":"<pre><code># In a Jupyter notebook cell\nimport nest_asyncio\nnest_asyncio.apply()  # Required for Jupyter async support\n\nfrom eclair.client import EclairClient\n\n# Now you can use await directly in cells\nclient = EclairClient(server_url=\"http://localhost:3000\")\nresult = await client.search_datasets(\"image classification\")\ndatasets = result.structured_content['result']\n\n# Display results in a nice format\nfrom IPython.display import display, HTML\nhtml_output = \"&lt;h3&gt;Available Datasets&lt;/h3&gt;&lt;ul&gt;\"\nfor dataset in datasets[:5]:\n    html_output += f\"&lt;li&gt;&lt;strong&gt;{dataset['collection']}/{dataset['dataset']}&lt;/strong&gt;&lt;br&gt;\"\n    html_output += f\"&lt;a href='{dataset['url']}' target='_blank'&gt;{dataset['url']}&lt;/a&gt;&lt;/li&gt;\"\nhtml_output += \"&lt;/ul&gt;\"\ndisplay(HTML(html_output))\n</code></pre>"},{"location":"usage/ai-agents/claude-code/","title":"Claude Code Integration","text":"<p>Claude Code by Anthropic is a powerful desktop application that brings Claude's advanced AI capabilities to your development workflow. When integrated with Eclair, Claude becomes a data-aware assistant that can discover, analyze, and work with real datasets.</p>"},{"location":"usage/ai-agents/claude-code/#prerequisites","title":"Prerequisites","text":"<p>Before setting up Claude Code with Eclair:</p> <ul> <li>\u2705 Eclair server is installed and running</li> <li>\u2705 Node.js is installed on your system</li> <li>\u2705 Anthropic account with Claude access</li> </ul>"},{"location":"usage/ai-agents/claude-code/#installation","title":"Installation","text":""},{"location":"usage/ai-agents/claude-code/#1-install-claude-code","title":"1. Install Claude Code","text":"<pre><code>npm install -g @anthropic-ai/claude-code\n</code></pre>"},{"location":"usage/ai-agents/claude-code/#2-initial-setup","title":"2. Initial Setup","text":"<p>If this is your first time using Claude Code:</p> <pre><code>claude\n</code></pre> <p>Follow the prompts to link your Anthropic account, then exit with Ctrl-C.</p>"},{"location":"usage/ai-agents/claude-code/#configuration","title":"Configuration","text":""},{"location":"usage/ai-agents/claude-code/#1-register-eclair-mcp-server","title":"1. Register Eclair MCP Server","text":"<p>Add Eclair as an MCP server to Claude Code:</p> <pre><code>claude mcp add --transport http Eclair http://0.0.0.0:8080/mcp\n</code></pre> <p>This command: - Registers Eclair as an MCP server named \"Eclair\" - Uses HTTP transport to communicate with the server - Connects to your local Eclair instance</p>"},{"location":"usage/ai-agents/claude-code/#2-copy-system-prompt","title":"2. Copy System Prompt","text":"<p>Claude works best with a system prompt that explains Eclair's capabilities:</p> <pre><code>cp src/eclair/client/claude/claude.md ./CLAUDE.md\n</code></pre> <p>This file helps Claude understand how to: - Use Eclair tools effectively - Interpret dataset metadata - Generate appropriate analysis code - Handle data download and processing</p>"},{"location":"usage/ai-agents/claude-code/#3-verify-configuration","title":"3. Verify Configuration","text":"<p>Check that Eclair is properly registered:</p> <pre><code>claude mcp list\n</code></pre> <p>You should see Eclair in the list of available MCP servers.</p>"},{"location":"usage/ai-agents/claude-code/#starting-claude-code","title":"Starting Claude Code","text":""},{"location":"usage/ai-agents/claude-code/#1-ensure-eclair-server-is-running","title":"1. Ensure Eclair Server is Running","text":"<pre><code># Check server status\ncurl http://localhost:8080/mcp/health\n\n# Start if not running\neclair-server\n</code></pre>"},{"location":"usage/ai-agents/claude-code/#2-start-claude-code","title":"2. Start Claude Code","text":"<pre><code>claude\n</code></pre> <p>You should see the Claude interface with: - Connection to registered MCP servers - Ready prompt for your requests</p> <p></p>"},{"location":"usage/ai-agents/claude-code/#3-test-eclair-connection","title":"3. Test Eclair Connection","text":"<p>Verify the connection by running:</p> <pre><code>eclair ping\n</code></pre> <p>You should receive a successful ping response from the Eclair server.</p>"},{"location":"usage/ai-agents/claude-code/#usage-examples","title":"Usage Examples","text":""},{"location":"usage/ai-agents/claude-code/#fashion-dataset-analysis","title":"Fashion Dataset Analysis","text":"<p>Let's walk through the same example as with Gemini CLI:</p> <pre><code>&gt; Find a fashion-related dataset and visualize some data examples\n</code></pre> <p>Step 1: Permission Request Claude will use Eclair to find relevant datasets: </p> <p>Step 2: Dataset Selection Claude presents dataset options and gets your selection: </p> <p>Step 3: Data Analysis and Visualization Claude generates comprehensive analysis code:  </p> <p>Step 4: Summary Report Claude provides a data scientist-quality summary: </p>"},{"location":"usage/ai-agents/claude-code/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/ai-agents/claude-code/#common-issues","title":"Common Issues","text":"<p>\"MCP server not responding\"</p> <ul> <li>Check Eclair server status: <code>eclair-server --status</code></li> <li>Restart the server: <code>eclair-server</code></li> <li>Verify network connectivity</li> </ul> <p>\"Permission denied for MCP operations\"</p> <ul> <li>Claude asks for permission before using MCP tools</li> <li>Grant permission when prompted</li> <li>Check MCP server registration: <code>claude mcp list</code></li> </ul> <p>\"Dataset download failed\"</p> <ul> <li>Check internet connectivity</li> <li>Verify dataset still exists at source</li> <li>Try alternative datasets</li> <li>Check for authentication requirements</li> </ul> <p>\"Claude Code won't start\"</p> <ul> <li>Ensure Node.js is properly installed</li> <li>Check Claude Code installation: <code>claude --version</code></li> <li>Try reinstalling: <code>npm uninstall -g @anthropic-ai/claude-code &amp;&amp; npm install -g @anthropic-ai/claude-code</code></li> </ul>"},{"location":"usage/ai-agents/claude-code/#debug-information","title":"Debug Information","text":"<p>Get detailed debug information:</p> <pre><code># Check MCP server status\nclaude mcp status\n\n# View detailed logs\nclaude --verbose\n\n# Test specific MCP server\nclaude mcp test Eclair\n</code></pre>"},{"location":"usage/ai-agents/claude-code/#configuration-issues","title":"Configuration Issues","text":"<p>Verify your setup:</p> <pre><code># List registered MCP servers\nclaude mcp list\n\n# Check Eclair connection\ncurl http://0.0.0.0:8080/mcp\n\n# Remove and re-add if needed\nclaude mcp remove Eclair\nclaude mcp add --transport http Eclair http://0.0.0.0:8080/mcp\n</code></pre>"},{"location":"usage/ai-agents/gemini-cli/","title":"Gemini CLI Integration","text":"<p>The Gemini CLI provides a powerful command-line interface for interacting with Google's Gemini models. When combined with Eclair, it becomes a data-aware AI assistant that can discover, download, and analyze real datasets.</p>"},{"location":"usage/ai-agents/gemini-cli/#prerequisites","title":"Prerequisites","text":"<p>Before setting up Gemini CLI with Eclair:</p> <ul> <li>\u2705 Eclair server is installed and running</li> <li>\u2705 Gemini API access</li> </ul>"},{"location":"usage/ai-agents/gemini-cli/#installation","title":"Installation","text":""},{"location":"usage/ai-agents/gemini-cli/#1-install-gemini-cli","title":"1. Install Gemini CLI","text":"<pre><code>npm install -g @google/gemini-cli\n</code></pre>"},{"location":"usage/ai-agents/gemini-cli/#2-install-nodejs-if-needed","title":"2. Install Node.js (if needed)","text":"<p>Visit nodejs.org or use a package manager:</p> <pre><code># macOS with Homebrew\nbrew install node\n\n# Ubuntu/Debian\nsudo apt install nodejs npm\n\n# Windows with Chocolatey\nchoco install nodejs\n</code></pre>"},{"location":"usage/ai-agents/gemini-cli/#configuration","title":"Configuration","text":""},{"location":"usage/ai-agents/gemini-cli/#1-set-up-api-key","title":"1. Set Up API Key","text":"<p>Get your Gemini API key from Google AI Studio and set it in an environment file:</p> <pre><code>echo \"GEMINI_API_KEY=your_actual_api_key_here\" &gt;&gt; .env\n</code></pre> <p>Keep Your API Key Secret</p> <p>Never commit your API key to version control. Always use environment variables or secure key management.</p>"},{"location":"usage/ai-agents/gemini-cli/#2-configure-mcp-server","title":"2. Configure MCP Server","text":"<p>Create the Gemini CLI configuration file at <code>~/.gemini/settings.json</code>:</p> <pre><code>mkdir -p ~/.gemini\ncat &gt; ~/.gemini/settings.json &lt;&lt; 'EOF'\n{\n  \"mcpServers\": {\n    \"eclair\": {\n      \"httpUrl\": \"http://localhost:8080/mcp\",\n      \"timeout\": 5000\n    }\n  },\n  \"selectedAuthType\": \"gemini-api-key\"\n}\nEOF\n</code></pre>"},{"location":"usage/ai-agents/gemini-cli/#3-copy-system-prompt","title":"3. Copy System Prompt","text":"<p>The system prompt helps Gemini understand how to work with Eclair tools:</p> <pre><code>cp src/eclair/client/gemini/gemini.md ./GEMINI.md\n</code></pre>"},{"location":"usage/ai-agents/gemini-cli/#starting-gemini-cli","title":"Starting Gemini CLI","text":""},{"location":"usage/ai-agents/gemini-cli/#1-ensure-eclair-server-is-running","title":"1. Ensure Eclair Server is Running","text":"<pre><code># Check if server is running\ncurl http://localhost:8080/mcp/health\n\n# If not running, start it\neclair-server\n</code></pre>"},{"location":"usage/ai-agents/gemini-cli/#2-start-gemini-cli","title":"2. Start Gemini CLI","text":"<pre><code>gemini\n</code></pre> <p>You should see:</p> <ul> <li>\ud83d\udd76\ufe0f Red sunglasses icon (indicates system prompt is loaded)</li> <li>\"Using: 1 MCP server\" message</li> </ul> <p></p>"},{"location":"usage/ai-agents/gemini-cli/#3-verify-mcp-connection","title":"3. Verify MCP Connection","text":"<p>Type <code>\\mcp</code> in the prompt to see available Eclair tools:</p> <pre><code>&gt; \\mcp\n</code></pre> <p>You should see all Eclair tools listed.</p> <p>You're all set! Gemini CLI can now discover and analyze real datasets through Eclair.</p>"},{"location":"usage/ai-agents/gemini-cli/#usage-examples","title":"Usage Examples","text":""},{"location":"usage/ai-agents/gemini-cli/#fashion-dataset-analysis","title":"Fashion Dataset Analysis","text":"<pre><code>&gt; Find a fashion-related dataset and visualize some data examples\n</code></pre> <p>This triggers a complete workflow:</p> <ol> <li> <p>Dataset Discovery: Gemini uses Eclair to find fashion datasets. It will ask for permission to use the Eclair tools.    </p> </li> <li> <p>Dataset Selection: Gemini presents options and gets your preference    </p> </li> <li> <p>Data Download: Uses Eclair (Croissant) metadata to download the dataset correctly    </p> </li> <li> <p>Code Generation: Creates Python code for analysis and visualization    </p> </li> <li> <p>Visualization Results: Shows actual data visualizations    </p> </li> </ol>"},{"location":"usage/ai-agents/gemini-cli/#advanced-analysis-requests","title":"Advanced Analysis Requests","text":"<pre><code>&gt; What is a good model to predict the type of clothing? Evaluate a few of them.\n</code></pre> <p>Gemini can continue the analysis by:</p> <ul> <li>Building machine learning models</li> <li>Comparing different algorithms</li> <li>Evaluating performance metrics</li> <li>Creating detailed reports</li> </ul> <p></p>"},{"location":"usage/ai-agents/gemini-cli/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/ai-agents/gemini-cli/#common-issues","title":"Common Issues","text":"<p>\"No MCP servers available\"</p> <ul> <li>Check that Eclair server is running: <code>curl http://localhost:8080/mcp</code></li> <li>Note: the Eclair server actually binds to <code>http://0.0.0.0:8080/mcp</code></li> <li>Verify the <code>~/.gemini/settings.json</code> configuration</li> <li>Restart Gemini CLI</li> </ul> <p>\"API key not found\"</p> <ul> <li>Ensure <code>.env</code> file contains <code>GEMINI_API_KEY=your_key</code></li> <li>Check that the file is in your current directory</li> <li>Verify the API key is valid</li> </ul> <p>\"Connection timeout\"</p> <ul> <li>Increase timeout in <code>~/.gemini/settings.json</code></li> <li>Check network connectivity</li> <li>Verify Eclair server is responding</li> </ul>"},{"location":"usage/ai-agents/gemini-cli/#configuration-verification","title":"Configuration Verification","text":"<p>Check your setup:</p> <pre><code># Verify configuration file\ncat ~/.gemini/settings.json\n\n# Test Eclair connection\neclair-client --tool ping\n\n# Check environment variables\necho $GEMINI_API_KEY\n</code></pre>"},{"location":"usage/ide/vscode-copilot/","title":"VS Code + GitHub Copilot Integration","text":"<p>Visual Studio Code with GitHub Copilot provides an excellent environment for interactive dataset exploration using Eclair. This integration brings AI-powered dataset discovery and analysis directly into your development workflow.</p>"},{"location":"usage/ide/vscode-copilot/#prerequisites","title":"Prerequisites","text":"<p>Before setting up VS Code with Copilot and Eclair:</p> <ul> <li>\u2705 Eclair server is installed and running</li> <li>\u2705 Visual Studio Code is installed</li> <li>\u2705 GitHub Copilot subscription (individual, business, or enterprise)</li> <li>\u2705 MCP extension for VS Code</li> </ul>"},{"location":"usage/ide/vscode-copilot/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"usage/ide/vscode-copilot/#1-install-required-extensions","title":"1. Install Required Extensions","text":"<p>Install these VS Code extensions if you don't already have them (but you probably do)</p> <ol> <li>GitHub Copilot - The AI pair programmer</li> <li>MCP Extension - For Model Context Protocol support</li> </ol> <pre><code># Install via command line\ncode --install-extension GitHub.copilot\ncode --install-extension mcp.mcp-vscode\n</code></pre> <p>Or install through VS Code Extensions marketplace.</p>"},{"location":"usage/ide/vscode-copilot/#2-configure-mcp-server","title":"2. Configure MCP Server","text":"<p>Register Eclair as an MCP server in VS Code:</p> <ol> <li>Open VS Code</li> <li>Press <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code> on Mac)</li> <li>Type <code>&gt;mcp</code> and select \"MCP: Add Server\"</li> <li>Choose HTTP as the transport type</li> <li>Enter URL: <code>http://0.0.0.0:8080/mcp</code></li> <li>Set ID: <code>Eclair</code></li> <li>Choose Global or Workspace scope</li> </ol> <p>VS Code may open an <code>mcp.json</code> file to confirm the configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"Eclair\": {\n      \"httpUrl\": \"http://0.0.0.0:8080/mcp\",\n      \"timeout\": 5000\n    }\n  }\n}\n</code></pre>"},{"location":"usage/ide/vscode-copilot/#3-start-the-mcp-server","title":"3. Start the MCP Server","text":"<ol> <li>Go to Extensions view (sidebar box icon)</li> <li>Scroll down to MCP servers section</li> <li>Find Eclair and click the gear icon</li> <li>Select \"Start Server\"</li> </ol>"},{"location":"usage/ide/vscode-copilot/#4-activate-agentic-mode","title":"4. Activate Agentic mode","text":"<ol> <li>Open Copilot Chat panel</li> <li>Select \"Agent\" instead of \"Ask\"</li> <li>Choose your preferred AI model</li> <li>You should see <code>mcp.json</code> added to the context</li> </ol> <p>VS Code + Copilot + Eclair is ready! You now have AI-powered dataset discovery and analysis directly in your IDE.</p>"},{"location":"usage/ide/vscode-copilot/#usage-examples","title":"Usage Examples","text":""},{"location":"usage/ide/vscode-copilot/#fashion-dataset-tutorial","title":"Fashion Dataset Tutorial","text":"<p>Prompt: <pre><code>Find a fashion-related dataset and visualize some data examples\n</code></pre></p> <p>Step 1: Search for Fashion Datasets</p> <p>Copilot identifies that it can use Eclair tools and asks for permission: </p> <p>Step 2: Dataset Discovery Results Copilot returns a comprehensive list of fashion-related datasets: </p> <p>Step 3: Download and Analysis Request Ask Copilot to download and visualize the data: <pre><code>Download the Fashion-MNIST dataset and create visualizations\n</code></pre></p> <p>Copilot uses Eclair's <code>download-dataset</code> tool and generates a Jupyter notebook:  </p> <p>Step 4: Generated Notebook Copilot creates a complete Jupyter notebook with proper code: </p> <p>Step 5: Visualization Results When run, the notebook produces the requested visualizations: </p> <p>Step 6: Summary and Next Steps Copilot concludes with a summary and suggestions: </p>"},{"location":"usage/ide/vscode-copilot/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/ide/vscode-copilot/#common-issues","title":"Common Issues","text":"<p>\"MCP server not found\"</p> <ul> <li>Verify Eclair server is running: <code>curl http://localhost:8080/mcp</code></li> <li>Check MCP extension is installed and enabled</li> <li>Restart VS Code</li> </ul> <p>\"Permission denied for MCP operations\"</p> <ul> <li>Grant permission when Copilot requests it</li> <li>Check that MCP server is properly registered</li> <li>Verify server URL in <code>mcp.json</code></li> </ul> <p>\"No datasets found\"</p> <ul> <li>Check internet connectivity</li> <li>Try broader search terms</li> <li>Verify Eclair server has access to upstream sources</li> </ul> <p>Copilot not using Eclair tools</p> <ul> <li>Ensure <code>mcp.json</code> appears in chat context</li> <li>Try more explicit requests: \"Use Eclair to find datasets about...\"</li> <li>Restart the MCP server from Extensions panel</li> </ul>"},{"location":"usage/ide/vscode-copilot/#debug-steps","title":"Debug Steps","text":"<ol> <li> <p>Check MCP Configuration:    <pre><code># Verify config file\ncat .vscode/mcp.json\n# or check global config\n</code></pre></p> </li> <li> <p>Test Eclair Connection:    <pre><code>curl http://0.0.0.0:8080/mcp/health\n</code></pre></p> </li> <li> <p>Restart Components:</p> </li> <li>Restart VS Code</li> <li>Restart Eclair server</li> <li>Disable/enable MCP extension</li> </ol>"},{"location":"usage/ide/vscode-copilot/#configuration-verification","title":"Configuration Verification","text":"<p>Check that everything is properly set up:</p> <ol> <li>Extensions: Ensure GitHub Copilot and MCP extensions are active</li> <li>MCP Server: Verify Eclair appears in Extensions &gt; MCP servers</li> <li>Connection: Confirm server status shows as \"Running\"</li> <li>Chat Context: Check that <code>mcp.json</code> appears in Copilot chat context</li> </ol>"},{"location":"usage/ide/vscode-gemini/","title":"VS Code + Gemini Code Assist Integration","text":"<p>Google's Gemini Code Assist for VS Code provides powerful AI-powered coding assistance. When combined with Eclair, it becomes a data-aware development environment that can discover, download, and analyze datasets directly within your IDE.</p>"},{"location":"usage/ide/vscode-gemini/#prerequisites","title":"Prerequisites","text":"<p>Before setting up VS Code with Gemini Code Assist and Eclair:</p> <ul> <li>\u2705 Eclair server is installed and running</li> <li>\u2705 Visual Studio Code is installed</li> <li>\u2705 Google Cloud account with Gemini API access</li> <li>\u2705 Gemini API key</li> </ul>"},{"location":"usage/ide/vscode-gemini/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"usage/ide/vscode-gemini/#1-install-gemini-code-assist-extension","title":"1. Install Gemini Code Assist Extension","text":"<p>Install the Gemini Code Assist extension from the VS Code marketplace:</p> <pre><code># Install via command line\ncode --install-extension Google.geminicodeassist\n</code></pre> <p>Or search for \"Gemini Code Assist\" in the VS Code Extensions panel.</p>"},{"location":"usage/ide/vscode-gemini/#2-enable-agentic-mode","title":"2. Enable Agentic Mode","text":"<p>To use MCP servers with Gemini Code Assist, you need to enable Agentic mode:</p> <ol> <li>Open VS Code</li> <li>Press <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code> on Mac)  </li> <li>Type <code>&gt; Open User Settings JSON</code></li> <li>Add this configuration:</li> </ol> <pre><code>{\n   \"geminicodeassist.updateChannel\": \"Insiders\"\n}\n</code></pre> <ol> <li>Restart VS Code</li> </ol>"},{"location":"usage/ide/vscode-gemini/#3-configure-api-key","title":"3. Configure API Key","text":"<p>Set your Gemini API key in an <code>.env</code> file in your project directory:</p> <pre><code>echo \"GEMINI_API_KEY=your_actual_api_key_here\" &gt;&gt; .env\n</code></pre> <p>Keep Your API Key Secure</p> <p>Never commit API keys to version control. Use environment files or secure key management.</p>"},{"location":"usage/ide/vscode-gemini/#4-configure-mcp-server","title":"4. Configure MCP Server","text":"<p>Create the Gemini configuration file at <code>~/.gemini/settings.json</code>:</p> <pre><code>mkdir -p ~/.gemini\ncat &gt; ~/.gemini/settings.json &lt;&lt; 'EOF'\n{\n  \"mcpServers\": {\n    \"eclair\": {\n      \"httpUrl\": \"http://localhost:8080/mcp\",\n      \"timeout\": 5000\n    }\n  },\n  \"selectedAuthType\": \"gemini-api-key\"\n}\nEOF\n</code></pre>"},{"location":"usage/ide/vscode-gemini/#5-copy-system-prompt","title":"5. Copy System Prompt","text":"<p>Copy the system prompt to help Gemini understand Eclair's capabilities:</p> <pre><code>cp src/eclair/client/gemini/gemini.md ./GEMINI.md\n</code></pre>"},{"location":"usage/ide/vscode-gemini/#6-activate-gemini-sidebar","title":"6. Activate Gemini Sidebar","text":"<ol> <li>Restart VS Code</li> <li>Open the Gemini Sidebar (sparkle \u2728 icon)</li> <li>Set Gemini to Agentic mode</li> <li>Verify MCP server connection by typing <code>/mcp</code></li> </ol> <p>Gemini Code Assist + Eclair is ready! You now have powerful AI-assisted dataset discovery and analysis directly in VS Code.</p>"},{"location":"usage/ide/vscode-gemini/#usage-examples","title":"Usage Examples","text":""},{"location":"usage/ide/vscode-gemini/#fashion-dataset-analysis-example","title":"Fashion Dataset Analysis Example","text":"<pre><code>Find a fashion-related dataset and visualize some data examples\n</code></pre> <p>Step 1: Automatic Tool Usage Gemini immediately uses Eclair's <code>search-datasets</code> tool: </p> <p>Step 2: Notebook Generation Gemini creates a complete Jupyter notebook with:</p> <ul> <li>Proper data loading code using Eclair's instructions</li> <li>Comprehensive data analysis</li> <li>Multiple visualization types</li> </ul> <p></p> <p>Step 3: Visualization Results The generated notebook produces the requested visualizations: </p>"},{"location":"usage/ide/vscode-gemini/#further-examples","title":"Further examples","text":"<p>Try these capabilities as well </p>"},{"location":"usage/ide/vscode-gemini/#1-intelligent-dataset-discovery","title":"1. Intelligent Dataset Discovery","text":"<p>Gemini understands context and can find datasets based on: - Domain (computer vision, NLP, time series, etc.) - Size requirements - Data format preferences - Specific use cases</p>"},{"location":"usage/ide/vscode-gemini/#2-automatic-code-generation","title":"2. Automatic Code Generation","text":"<p>Based on Eclair's metadata, Gemini generates: - Data loading scripts with proper error handling - Preprocessing pipelines - Visualization code - Analysis workflows - Complete Jupyter notebooks</p>"},{"location":"usage/ide/vscode-gemini/#3-interactive-development","title":"3. Interactive Development","text":"<ul> <li>Ask follow-up questions about datasets</li> <li>Request modifications to generated code</li> <li>Get explanations for data analysis steps</li> <li>Iterate on visualizations and analysis</li> </ul>"},{"location":"usage/ide/vscode-gemini/#4-context-awareness","title":"4. Context Awareness","text":"<p>Gemini maintains context about: - Previously discussed datasets - Your project requirements - Code that's already been generated - Analysis results</p>"},{"location":"usage/ide/vscode-gemini/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/ide/vscode-gemini/#common-issues","title":"Common Issues","text":"<p>\"MCP servers not loaded\"</p> <ul> <li>Ensure <code>~/.gemini/settings.json</code> is properly configured</li> <li>Verify Eclair server is running: <code>curl http://localhost:8080/mcp</code></li> <li>Restart VS Code and check Agentic mode is enabled</li> </ul> <p>\"API key not found\"</p> <ul> <li>Check <code>.env</code> file contains <code>GEMINI_API_KEY=your_key</code></li> <li>Verify the API key is valid and has proper permissions</li> <li>Ensure the <code>.env</code> file is in your project root</li> </ul> <p>\"Dataset access denied\"</p> <ul> <li>Some datasets require authentication</li> <li>Check dataset license and access requirements</li> <li>Try alternative datasets with open access</li> </ul> <p>\"Code execution errors\"</p> <ul> <li>Install required dependencies: <code>pip install datasets pandas matplotlib</code></li> <li>Check Python environment is properly configured</li> <li>Verify dataset URLs are still valid</li> </ul>"},{"location":"usage/ide/vscode-gemini/#debug-steps","title":"Debug Steps","text":"<ol> <li> <p>Verify Eclair Connection:    <pre><code>curl http://localhost:8080/mcp/health\neclair-client --tool ping\n</code></pre></p> </li> <li> <p>Check Configuration Files:    <pre><code>cat ~/.gemini/settings.json\ncat .env\nls -la GEMINI.md\n</code></pre></p> </li> <li> <p>Test MCP Integration:    In Gemini Code Assist, type <code>/mcp</code> to verify tools are loaded</p> </li> </ol>"},{"location":"usage/ide/vscode-gemini/#configuration-issues","title":"Configuration Issues","text":"<p>If MCP servers aren't loading:</p> <ol> <li> <p>Check Settings Format:    <pre><code>{\n  \"mcpServers\": {\n    \"eclair\": {\n      \"httpUrl\": \"http://localhost:8080/mcp\",\n      \"timeout\": 5000\n    }\n  },\n  \"selectedAuthType\": \"gemini-api-key\"\n}\n</code></pre></p> </li> <li> <p>Verify Server Status: Eclair server must be running before starting VS Code</p> </li> </ol>"}]}