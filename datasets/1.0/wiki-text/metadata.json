{
  "@context": {
    "@language": "en",
    "@vocab": "https://schema.org/",
    "citeAs": "cr:citeAs",
    "column": "cr:column",
    "conformsTo": "dct:conformsTo",
    "cr": "http://mlcommons.org/croissant/",
    "data": {
      "@id": "cr:data",
      "@type": "@json"
    },
    "dataBiases": "cr:dataBiases",
    "dataCollection": "cr:dataCollection",
    "dataType": {
      "@id": "cr:dataType",
      "@type": "@vocab"
    },
    "dct": "http://purl.org/dc/terms/",
    "extract": "cr:extract",
    "field": "cr:field",
    "fileProperty": "cr:fileProperty",
    "fileObject": "cr:fileObject",
    "fileSet": "cr:fileSet",
    "format": "cr:format",
    "includes": "cr:includes",
    "isEnumeration": "cr:isEnumeration",
    "isLiveDataset": "cr:isLiveDataset",
    "jsonPath": "cr:jsonPath",
    "key": "cr:key",
    "md5": "cr:md5",
    "parentField": "cr:parentField",
    "path": "cr:path",
    "personalSensitiveInformation": "cr:personalSensitiveInformation",
    "recordSet": "cr:recordSet",
    "references": "cr:references",
    "regex": "cr:regex",
    "repeated": "cr:repeated",
    "replace": "cr:replace",
    "sc": "https://schema.org/",
    "separator": "cr:separator",
    "source": "cr:source",
    "subField": "cr:subField",
    "transform": "cr:transform",
    "wd": "https://www.wikidata.org/wiki/"
  },
  "@type": "sc:Dataset",
  "name": "WikiText-103",
  "conformsTo": "http://mlcommons.org/croissant/1.0",
  "description": "The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike License.\n\nCompared to the preprocessed version of Penn Treebank (PTB), WikiText-2 is over 2 times larger and WikiText-103 is over 110 times larger. The WikiText dataset also features a far larger vocabulary and retains the original case, punctuation and numbers - all of which are removed in PTB. As it is composed of full articles, the dataset is well suited for models that can take advantage of long term dependencies.",
  "citeAs": "@article{merity2016pointer, title={Pointer sentinel mixture models}, author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard}, journal={arXiv preprint arXiv:1609.07843}, year={2016} }",
  "license": "cc-by-sa-3.0",
  "url": "https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/",
  "distribution": [
    {
      "@type": "cr:FileObject",
      "name": "wikitext-103-v1.zip",
      "contentUrl": "https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip",
      "encodingFormat": "application/zip",
      "sha256": "242ba0f20b329cfdf1ccc61e9e9e5b59becf189db7f7a81cd2a0e2fc31539590"
    },
    {
      "@type": "cr:FileSet",
      "name": "token-files",
      "containedIn": "wikitext-103-v1.zip",
      "encodingFormat": "image/jpeg",
      "includes": "wikitext-103/*.tokens"
    },
    {
      "@type": "cr:FileObject",
      "name": "splits.csv",
      "contentUrl": "data/splits.csv",
      "encodingFormat": "text/csv",
      "sha256": "dec55b82438aba979670b0eabd99b1d8cc9d385cef028314feccba1cc68af33b"
    }
  ],
  "recordSet": [
    {
      "@type": "cr:RecordSet",
      "name": "split_enums",
      "description": "Maps split names to semantic values.",
      "key": "name",
      "field": [
        {
          "@type": "cr:Field",
          "name": "name",
          "description": "One of: train, valid, test.",
          "dataType": "sc:Text",
          "source": {
            "fileObject": "splits.csv",
            "extract": {
              "column": "name"
            }
          }
        },
        {
          "@type": "cr:Field",
          "name": "url",
          "description": "Corresponding mlcommons.org definition URL",
          "dataType": [
            "sc:URL",
            "wd:Q3985153"
          ],
          "source": {
            "fileObject": "splits.csv",
            "extract": {
              "column": "url"
            }
          }
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "name": "words",
      "description": "The words of the token files, including their split.",
      "field": [
        {
          "@type": "cr:Field",
          "name": "word",
          "description": "A word.",
          "dataType": "sc:Text",
          "repeated": "true",
          "source": {
            "fileSet": "token-files",
            "extract": {
              "fileProperty": "content"
            },
            "transform": [
              {
                "replace": "\\n/<eos>"
              },
              {
                "separator": " "
              }
            ]
          }
        },
        {
          "@type": "cr:Field",
          "name": "split",
          "description": "The train, valid or test split.",
          "dataType": [
            "sc:Text",
            "wd:Q3985153"
          ],
          "references": {
            "field": "split_enums/name"
          },
          "source": {
            "fileSet": "token-files",
            "extract": {
              "fileProperty": "fullpath"
            },
            "transform": {
              "regex": "^wiki\\.(train|valid|test)\\.tokens$"
            }
          }
        }
      ]
    }
  ]
}
